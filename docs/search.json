[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\nIntroduction to single-cell RNA-seq\n\n\n\nAudience\nComputational skills required\nDuration\n\n\n\n\nBiologists\nIntroduction to R\n3-session online workshop (~7.5 hours of trainer-led time)\n\n\n\n\nDescription\nThis repository has teaching materials for a hands-on Introduction to single-cell RNA-seq workshop. This workshop will instruct participants on how to design a single-cell RNA-seq experiment, and how to efficiently manage and analyze the data starting from count matrices. This will be a hands-on workshop in which we will focus on using the Seurat package using R/RStudio. Working knowledge of R is required or completion of the Introduction to R workshop.\nNote for Trainers: Please note that the schedule linked below assumes that learners will spend between 3-4 hours on reading through, and completing exercises from selected lessons between classes. The online component of the workshop focuses on more exercises and discussion/Q & A.\n\n\n\n\n\n\nNote\n\n\n\nThese materials were developed for a trainer-led workshop, but are also amenable to self-guided learning.\n\n\n\n\nLearning Objectives\n\nDescribe best practices for designing a single-cell RNA-seq experiment\nDescribe steps in a single-cell RNA-seq analysis workflow\nUse Seurat and associated tools to perform analysis of single-cell expression data, including data filtering, QC, integration, clustering, and marker identification\nUnderstand practical considerations for performing scRNA-seq, rather than in-depth exploration of algorithm theory\n\n\n\nLessons\n\nWorkshop schedule (trainer-led learning)\nSelf-learning\n\n\n\nInstallation Requirements\n\nApplications\nDownload the most recent versions of R and RStudio for your laptop:\n\nR (version 4.0.0 or above)\nRStudio\n\n\n\nPackages for R\n\n\n\n\n\n\nNotes\n\n\n\nNote 1: Install the packages in the order listed below.\nNote 2:  All the package names listed below are case sensitive!\nNote 3: If you have a Mac with an M1 chip, download and install this tool before intalling your packages: https://mac.r-project.org/tools/gfortran-12.2-universal.pkg\nNote 4: At any point (especially if you’ve used R/Bioconductor in the past), in the console R may ask you if you want to update any old packages by asking Update all/some/none? [a/s/n]:. If you see this, type “a” at the prompt and hit Enter to update any old packages. Updating packages can sometimes take quite a bit of time to run, so please account for that before you start with these installations.\nNote 5: If you see a message in your console along the lines of “binary version available but the source version is later”, followed by a question, “Do you want to install from sources the package which needs compilation? y/n”, type n for no, and hit enter.\n\n\n(1) Install the 4 packages listed below from Bioconductor using the the BiocManager::install() function.\n\nAnnotationHub\nensembldb\nmulttest\nglmGamPoi\n\nPlease install them one-by-one as follows:\n\nBiocManager::install(\"AnnotationHub\")\nBiocManager::install(\"ensembldb\")\n& so on ...\n\n(2) Install the 8 packages listed below from CRAN using the install.packages() function.\n\ntidyverse\nMatrix\nRCurl\nscales\ncowplot\nBiocManager\nSeurat\nmetap\nreshape2\nplyr\n\nPlease install them one-by-one as follows:\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"Matrix\")\ninstall.packages(\"RCurl\")\n& so on ...\n\n(3) Finally, please check that all the packages were installed successfully by loading them one at a time using the library() function.\n\nlibrary(Seurat)\nlibrary(tidyverse)\nlibrary(Matrix)\nlibrary(RCurl)\nlibrary(scales)\nlibrary(cowplot)\nlibrary(metap)\nlibrary(reshape2)\nlibrary(plyr)\nlibrary(AnnotationHub)\nlibrary(ensembldb)\nlibrary(multtest)\nlibrary(glmGamPoi)\n\n(4) Once all packages have been loaded, run sessionInfo().\n\nsessionInfo()\n\n\n\n\n\nCitation\nTo cite material from this course in your publications, please use:\n\n\n\n\n\n\nCitation\n\n\n\nMary Piper, Meeta Mistry, Jihe Liu, William Gammerdinger, & Radhika Khetani. (2022, January 6). hbctraining/scRNA-seq_online: scRNA-seq Lessons from HCBC (first release). Zenodo. https://doi.org/10.5281/zenodo.5826256.\n\n\nA lot of time and effort went into the preparation of these materials. Citations help us understand the needs of the community, gain recognition for our work, and attract further funding to support our teaching activities. Thank you for citing this material if it helped you in your data analysis."
  },
  {
    "objectID": "lessons/07_SC_clustering_cells_SCT.html",
    "href": "lessons/07_SC_clustering_cells_SCT.html",
    "title": "Clustering Analysis",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/07_SC_clustering_cells_SCT.html#learning-objectives",
    "href": "lessons/07_SC_clustering_cells_SCT.html#learning-objectives",
    "title": "Clustering Analysis",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nDescribe methods for evaluating the number of principal components used for clustering\nPerform clustering of cells based on significant principal components"
  },
  {
    "objectID": "lessons/07_SC_clustering_cells_SCT.html#clustering-cells-based-on-top-pcs-metagenes",
    "href": "lessons/07_SC_clustering_cells_SCT.html#clustering-cells-based-on-top-pcs-metagenes",
    "title": "Clustering Analysis",
    "section": "Clustering cells based on top PCs (metagenes)",
    "text": "Clustering cells based on top PCs (metagenes)\n\nSet up\nBefore starting with this lesson, let’s create a new script for the next few steps in the workflow called clustering.R.\nNext, let’s load all the libraries that we need.\n\n# Single-cell RNA-seq - clustering\n\n# Load libraries\nlibrary(Seurat)\nlibrary(tidyverse)\nlibrary(RCurl)\nlibrary(cowplot)"
  },
  {
    "objectID": "lessons/07_SC_clustering_cells_SCT.html#identify-significant-pcs",
    "href": "lessons/07_SC_clustering_cells_SCT.html#identify-significant-pcs",
    "title": "Clustering Analysis",
    "section": "Identify significant PCs",
    "text": "Identify significant PCs\nTo overcome the extensive technical noise in the expression of any single gene for scRNA-seq data, Seurat assigns cells to clusters based on their PCA scores derived from the expression of the integrated most variable genes, with each PC essentially representing a “metagene” that combines information across a correlated gene set. Determining how many PCs to include in the clustering step is therefore important to ensure that we are capturing the majority of the variation, or cell types, present in our dataset.\nIt is useful to explore the PCs prior to deciding which PCs to include for the downstream clustering analysis.\n\nOne way of exploring the PCs is using a heatmap to visualize the most variant genes for select PCs with the genes and cells ordered by PCA scores. The idea here is to look at the PCs and determine whether the genes driving them make sense for differentiating the different cell types.\n\nThe cells argument specifies the number of cells with the most negative or postive PCA scores to use for the plotting. The idea is that we are looking for a PC where the heatmap starts to look more “fuzzy”, i.e. where the distinctions between the groups of genes is not so distinct.\n\n# Explore heatmap of PCs\nDimHeatmap(seurat_integrated, \n           dims = 1:9, \n           cells = 500, \n           balanced = TRUE)\n\n\n\n\nThis method can be slow and hard to visualize individual genes if we would like to explore a large number of PCs. In the same vein and to explore a large number of PCs, we could print out the top 10 (or more) positive and negative genes by PCA scores driving the PCs.\n\n# Printing out the most variable genes driving PCs\nprint(x = seurat_integrated[[\"pca\"]], \n      dims = 1:10, \n      nfeatures = 5)\n\nPC_ 1 \nPositive:  FTL, TIMP1, FTH1, C15orf48, CXCL8 \nNegative:  RPL3, RPL13, RPS6, RPS18, RPL10 \nPC_ 2 \nPositive:  GNLY, CCL5, NKG7, GZMB, FGFBP2 \nNegative:  CD74, IGHM, IGKC, HLA-DRA, CD79A \nPC_ 3 \nPositive:  CD74, IGKC, HLA-DRA, IGHM, HLA-DRB1 \nNegative:  TRAC, FTL, CCL2, PABPC1, S100A8 \nPC_ 4 \nPositive:  CD74, IGHM, CCL5, GNLY, IGKC \nNegative:  HSPB1, CACYBP, HSPH1, HSP90AB1, HSPA8 \nPC_ 5 \nPositive:  VMO1, FCGR3A, MS4A7, TIMP1, TNFSF10 \nNegative:  CCL2, FTL, CXCL8, S100A8, S100A9 \nPC_ 6 \nPositive:  IGHM, IGKC, CD79A, CCL2, MS4A1 \nNegative:  HLA-DQA1, TXN, HLA-DRA, HLA-DPA1, LYZ \nPC_ 7 \nPositive:  TIMP1, S100A8, LYZ, IGHM, MARCKSL1 \nNegative:  CCL2, CCL3, CCL4, CCL4L2, MIR155HG \nPC_ 8 \nPositive:  CCL3, CCL4, CXCL8, IL1B, CCL4L2 \nNegative:  CCL2, LGALS3, FTL, ISG15, CTSL \nPC_ 9 \nPositive:  MIR155HG, NME1, HERPUD1, FTH1, DUSP4 \nNegative:  HSPA1A, HSPB1, CCL2, CD74, IDO1 \nPC_ 10 \nPositive:  CCL2, CREM, ANXA1, CXCR4, FTH1 \nNegative:  GNLY, S100A8, TIMP1, S100A9, FTL \n\n\n\nThe elbow plot is another helpful way to determine how many PCs to use for clustering so that we are capturing majority of the variation in the data. The elbow plot visualizes the standard deviation of each PC, and we are looking for where the standard deviations begins to plateau. Essentially, where the elbow appears is usually the threshold for identifying the majority of the variation. However, this method can be quite subjective.\n\nLet’s draw an elbow plot using the top 40 PCs:\n\n# Plot the elbow plot\nElbowPlot(object = seurat_integrated, \n          ndims = 40)\n\n\n\n\nBased on this plot, we could roughly determine the majority of the variation by where the elbow occurs around PC8 - PC10, or one could argue that it should be when the data points start to get close to the X-axis, PC30 or so. This gives us a very rough idea of the number of PCs needed to be included, we can extract the information visualized here in a more quantitative manner, which may be a bit more reliable.\nWhile the above 2 methods were used a lot more with older methods from Seurat for normalization and identification of variable genes, they are no longer as important as they used to be. This is because the SCTransform method is more accurate than older methods.\n\n\n\n\n\n\nWhy is selection of PCs more important for older methods?\n\n\n\nThe older methods incorporated some technical sources of variation into some of the higher PCs, so selection of PCs was more important. SCTransform estimates the variance better and does not frequently include these sources of technical variation in the higher PCs.\nIn theory, with SCTransform, the more PCs we choose the more variation is accounted for when performing the clustering, but it takes a lot longer to perform the clustering. Therefore for this analysis, we will use the first 40 PCs to generate the clusters."
  },
  {
    "objectID": "lessons/07_SC_clustering_cells_SCT.html#cluster-the-cells",
    "href": "lessons/07_SC_clustering_cells_SCT.html#cluster-the-cells",
    "title": "Clustering Analysis",
    "section": "Cluster the cells",
    "text": "Cluster the cells\nSeurat uses a graph-based clustering approach using a K-nearest neighbor approach, and then attempts to partition this graph into highly interconnected ‘quasi-cliques’ or ‘communities’ [Seurat - Guided Clustering Tutorial]. A nice in-depth description of clustering methods is provided in the SVI Bioinformatics and Cellular Genomics Lab course.\n\nFind neighbors\nThe first step is to construct a K-nearest neighbor (KNN) graph based on the euclidean distance in PCA space.\n\n\n\nImage source: Analysis of Single cell RNA-seq data\n\nEdges are drawn between cells with similar features expression patterns.\nEdge weights are refined between any two cells based on shared overlap in their local neighborhoods.\n\nThis is done in Seurat by using the FindNeighbors() function:\n\n# Determine the K-nearest neighbor graph\nseurat_integrated &lt;- FindNeighbors(object = seurat_integrated, \n                                dims = 1:40)\n\n\n\nFind clusters\nNext, Seurat will iteratively group cells together with the goal of optimizing the standard modularity function.\nWe will use the FindClusters() function to perform the graph-based clustering. The resolution is an important argument that sets the “granularity” of the downstream clustering and will need to be optimized for every individual experiment. For datasets of 3,000 - 5,000 cells, the resolution set between 0.4-1.4 generally yields good clustering. Increased resolution values lead to a greater number of clusters, which is often required for larger datasets.\nThe FindClusters() function allows us to enter a series of resolutions and will calculate the “granularity” of the clustering. This is very helpful for testing which resolution works for moving forward without having to run the function for each resolution.\n\n# Determine the clusters for various resolutions                              \nseurat_integrated &lt;- FindClusters(object = seurat_integrated,\n                               resolution = c(0.4, 0.6, 0.8, 1.0, 1.4))\n\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1113933\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9206\nNumber of communities: 13\nElapsed time: 3 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1113933\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.9016\nNumber of communities: 15\nElapsed time: 3 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1113933\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8842\nNumber of communities: 17\nElapsed time: 3 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1113933\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8699\nNumber of communities: 22\nElapsed time: 3 seconds\nModularity Optimizer version 1.3.0 by Ludo Waltman and Nees Jan van Eck\n\nNumber of nodes: 29629\nNumber of edges: 1113933\n\nRunning Louvain algorithm...\nMaximum modularity in 10 random starts: 0.8464\nNumber of communities: 27\nElapsed time: 3 seconds"
  },
  {
    "objectID": "lessons/07_SC_clustering_cells_SCT.html#visualize-clusters-of-cells",
    "href": "lessons/07_SC_clustering_cells_SCT.html#visualize-clusters-of-cells",
    "title": "Clustering Analysis",
    "section": "Visualize clusters of cells",
    "text": "Visualize clusters of cells\nTo visualize the cell clusters, there are a few different dimensionality reduction techniques that can be helpful. The most popular methods include t-distributed stochastic neighbor embedding (t-SNE) and Uniform Manifold Approximation and Projection (UMAP) techniques.\nBoth methods aim to place cells with similar local neighborhoods in high-dimensional space together in low-dimensional space. These methods will require you to input number of PCA dimentions to use for the visualization, we suggest using the same number of PCs as input to the clustering analysis. Here, we will proceed with the UMAP method for visualizing the clusters.\nWe can only visualize the results of one resolution setting at a time. If we look at the metadata of our Seurat object(seurat_integrated@meta.data), you should observe a separate column for each of the different resolutions calculated.\n\n# Explore resolutions\nseurat_integrated@meta.data %&gt;% \n        View()\n\nTo choose a resolution to start with, we often pick something in the middle of the range like 0.6 or 0.8. We will start with a resolution of 0.8 by assigning the identity of the clusters using the Idents() function.\n\n# Assign identity of clusters\nIdents(object = seurat_integrated) &lt;- \"integrated_snn_res.0.8\"\n\nNow, we can plot the UMAP to look at how cells cluster together at a resolution of 0.8:\n\n## Calculation of UMAP\n## DO NOT RUN (calculated in the last lesson)\n\nseurat_integrated &lt;- RunUMAP(seurat_integrated,\n                             reduction = \"pca\",\n                             dims = 1:40)\n\n\n# Plot the UMAP\nDimPlot(seurat_integrated,\n        reduction = \"umap\",\n        label = TRUE,\n        label.size = 6)\n\n\n\n\nIt can be useful to explore other resolutions as well. It will give you a quick idea about how the clusters would change based on the resolution parameter. For example, let’s switch to a resolution of 0.4:\n\n# Assign identity of clusters\nIdents(object = seurat_integrated) &lt;- \"integrated_snn_res.0.4\"\n\n# Plot the UMAP\nDimPlot(seurat_integrated,\n        reduction = \"umap\",\n        label = TRUE,\n        label.size = 6)\n\n\n\n\nHow does your UMAP plot compare to the one above?\nIt is possible that there is some variability in the way your clusters look compared to the image in this lesson. In particular you may see a difference in the labeling of clusters. This is an unfortunate consequence of slight variations in the versions of packages (mostly Seurat dependencies).\nIf your clusters look identical to what’s in the lesson, please go ahead to the next section.\n\nIf your clusters do look different from what we have in the lesson, please follow the instructions provided below.\nInside your data folder you will see a folder called additional_data. It contains the seurat_integrated object that we have created for the class.\n\nLoad in the object to your R session and overwrite the existing one:\n\n\nload(bzfile(\"data/additional_data/seurat_integrated.RData.bz2\"))\n\n\n\n\n\n\n\n\nExercise\n\n\n\nAfter loading seurat_integrated.RData.bz2, check the object clusters with different resolution (0.4, 0.6, 0.8, 1.0, 1.4). For each resolution plot the corresponding UMAP and report how many clusters you observe. Which resolution do you think makes sense?\n\n\n\nWe will now continue with the 0.8 resolution to check the quality control metrics and known markers for the anticipated cell types. Plot the UMAP again to make sure your image now (or still) matches what you see in the lesson:\n\n# Assign identity of clusters\nIdents(object = seurat_integrated) &lt;- \"integrated_snn_res.0.8\"\n\n# Plot the UMAP\nDimPlot(seurat_integrated,\n        reduction = \"umap\",\n        label = TRUE,\n        label.size = 6)"
  },
  {
    "objectID": "lessons/fetching_annotations.html",
    "href": "lessons/fetching_annotations.html",
    "title": "Fetching Annotations",
    "section": "",
    "text": "library(AnnotationHub)\nlibrary(tidyverse)\n\n\n# Connect to AnnotationHub\nah &lt;- AnnotationHub()\n\n# Access the Ensembl database for organism\nahDb &lt;- query(ah, \n              pattern = c(\"Homo sapiens\", \"EnsDb\"), \n              ignore.case = TRUE)\n\n# Acquire the latest annotation files\nid &lt;- ahDb %&gt;%\n        mcols() %&gt;%\n        rownames() %&gt;%\n        tail(n = 1)\n\n# Download the appropriate Ensembldb database\nedb &lt;- ah[[id]]\n\n# Extract gene-level information from database\nannotations &lt;- genes(edb, \n                     return.type = \"data.frame\")\n\n# Select annotations of interest\nannotations &lt;- annotations %&gt;%\n        dplyr::select(gene_id, gene_name, seq_name, gene_biotype, description)\nhead(annotations)\n\n           gene_id   gene_name seq_name                       gene_biotype\n1  ENSG00000290825     DDX11L2        1                             lncRNA\n6  ENSG00000223972     DDX11L1        1 transcribed_unprocessed_pseudogene\n7  ENSG00000227232      WASH7P        1             unprocessed_pseudogene\n8  ENSG00000278267   MIR6859-1        1                              miRNA\n9  ENSG00000243485 MIR1302-2HG        1                             lncRNA\n10 ENSG00000284332   MIR1302-2        1                              miRNA\n                                                                                     description\n1  DEAD/H-box helicase 11 like 2 (pseudogene) [Source:NCBI gene (formerly Entrezgene);Acc:84771]\n6                 DEAD/H-box helicase 11 like 1 (pseudogene) [Source:HGNC Symbol;Acc:HGNC:37102]\n7                          WASP family homolog 7, pseudogene [Source:HGNC Symbol;Acc:HGNC:38034]\n8                                            microRNA 6859-1 [Source:HGNC Symbol;Acc:HGNC:50039]\n9                                        MIR1302-2 host gene [Source:HGNC Symbol;Acc:HGNC:52482]\n10                                           microRNA 1302-2 [Source:HGNC Symbol;Acc:HGNC:35294]"
  },
  {
    "objectID": "lessons/03_SC_quality_control-setup.html",
    "href": "lessons/03_SC_quality_control-setup.html",
    "title": "Quality Control Setup",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/03_SC_quality_control-setup.html#learning-objectives",
    "href": "lessons/03_SC_quality_control-setup.html#learning-objectives",
    "title": "Quality Control Setup",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nDemonstrate how to import data and set up project for upcoming quality control analysis."
  },
  {
    "objectID": "lessons/03_SC_quality_control-setup.html#exploring-the-example-dataset",
    "href": "lessons/03_SC_quality_control-setup.html#exploring-the-example-dataset",
    "title": "Quality Control Setup",
    "section": "Exploring the example dataset",
    "text": "Exploring the example dataset\nFor this workshop we will be working with a single-cell RNA-seq dataset which is part of a larger study from Kang et al, 2017. In this paper, the authors present a computational algorithm that harnesses genetic variation (eQTL) to determine the genetic identity of each droplet containing a single cell (singlet) and identify droplets containing two cells from different individuals (doublets).\nThe data used to test their algorithm is comprised of pooled Peripheral Blood Mononuclear Cells (PBMCs) taken from eight lupus patients, split into control and interferon beta-treated (stimulated) conditions.\n\nImage credit: Kang et al, 2017\n\nRaw data\nThis dataset is available on GEO (GSE96583), however the available counts matrix lacked mitochondrial reads, so we downloaded the BAM files from the SRA (SRP102802). These BAM files were converted back to FASTQ files, then run through Cell Ranger to obtain the count data that we will be using.\n\n\n\n\n\n\nNote\n\n\n\nThe count data for this dataset is also freely available from 10X Genomics and is used in the Seurat tutorial.\n\n\n\n\nMetadata\nIn addition to the raw data, we also need to collect information about the data; this is known as metadata. There is often a temptation to just start exploring the data, but it is not very meaningful if we know nothing about the samples that this data originated from.\nSome relevant metadata for our dataset is provided below:\n\nThe libraries were prepared using 10X Genomics version 2 chemistry\nThe samples were sequenced on the Illumina NextSeq 500\nPBMC samples from eight individual lupus patients were separated into two aliquots each.\n\nOne aliquot of PBMCs was activated by 100 U/mL of recombinant IFN-β for 6 hours.\nThe second aliquot was left untreated.\nAfter 6 hours, the eight samples for each condition were pooled together in two final pools (stimulated cells and control cells). We will be working with these two, pooled samples. (We did not demultiplex the samples because SNP genotype information was used to demultiplex in the paper and the barcodes/sample IDs were not readily available for this data. Generally, you would demultiplex and perform QC on each individual sample rather than pooling the samples.)\n\n12,138 and 12,167 cells were identified (after removing doublets) for control and stimulated pooled samples, respectively.\nSince the samples are PBMCs, we will expect immune cells, such as:\n\nB cells\nT cells\nNK cells\nmonocytes\nmacrophages\npossibly megakaryocytes\n\n\nIt is recommended that you have some expectation regarding the cell types you expect to see in a dataset prior to performing the QC. This will inform you if you have any cell types with low complexity (lots of transcripts from a few genes) or cells with higher levels of mitochondrial expression. This will enable us to account for these biological factors during the analysis workflow.\nNone of the above cell types are expected to be low complexity or anticipated to have high mitochondrial content."
  },
  {
    "objectID": "lessons/03_SC_quality_control-setup.html#set-up",
    "href": "lessons/03_SC_quality_control-setup.html#set-up",
    "title": "Quality Control Setup",
    "section": "Set up",
    "text": "Set up\nFor this workshop, we will be working within an RStudio project. In order to follow along you should have downloaded the R project.\n\n\n\n\n\n\nImportant\n\n\n\nIf you haven’t done this already, the project can be accessed using this link.\n\n\nOnce downloaded, you should see a file called single_cell_rnaseq.zip on your computer (likely, in your Downloads folder).\n\nUnzip this file. It will result in a folder of the same name.\nMove the folder to the location on your computer where you would like to perform the analysis.\nOpen up the folder. The contents will look like the screenshot below.\nLocate the .Rproj file and double-click on it. This will open up RStudio with the “single_cell_rnaseq” project loaded."
  },
  {
    "objectID": "lessons/03_SC_quality_control-setup.html#project-organization",
    "href": "lessons/03_SC_quality_control-setup.html#project-organization",
    "title": "Quality Control Setup",
    "section": "Project organization",
    "text": "Project organization\nOne of the most important parts of research that involves large amounts of data, is how best to manage it. We tend to prioritize the analysis, but there are many other important aspects of data management that are often overlooked in the excitement to get a first look at new data. The HMS Data Management Working Group, discusses in-depth some things to consider beyond the data creation and analysis.\nOne important aspect of data management is organization. For each experiment you work on and analyze data for, it is considered best practice to get organized by creating a planned storage space (directory structure). We will do that for our single-cell analysis.\nLook inside your project space and you will find that a directory structure has been setup for you:\n\nsingle_cell_rnaseq/\n├── data\n├── results\n└── figures\n\n\n\n\n\n\n\nNOTE FOR WINDOWS OS users\n\n\n\nWhen you open the project folder after unzipping, please check if you have a data folder with a sub folder also called data. If this is the case, please move all the files from the subfolder into the parent data folder.\n\n\n\nNew script\nNext, open a new Rscript file, and start with some comments to indicate what this file is going to contain:\n\n# July/August 2021\n# HBC single-cell RNA-seq workshop\n\n# Single-cell RNA-seq analysis - QC\n\nSave the Rscript as quality_control.R. Your working directory should look something like this:\n\n\n\nLoading libraries\nNow, we can load the necessary libraries:\n\n# Load libraries\nlibrary(SingleCellExperiment)\nlibrary(Seurat)\nlibrary(tidyverse)\nlibrary(Matrix)\nlibrary(scales)\nlibrary(cowplot)\nlibrary(RCurl)"
  },
  {
    "objectID": "lessons/03_SC_quality_control-setup.html#loading-single-cell-rna-seq-count-data",
    "href": "lessons/03_SC_quality_control-setup.html#loading-single-cell-rna-seq-count-data",
    "title": "Quality Control Setup",
    "section": "Loading single-cell RNA-seq count data",
    "text": "Loading single-cell RNA-seq count data\nRegardless of the technology or pipeline used to process your raw single-cell RNA-seq sequence data, the output with quantified expression will generally be the same. That is, for each individual sample you will have the following three files:\n\nA file with the cell IDs, representing all cells quantified\nA file with the gene IDs, representing all genes quantified\nA matrix of counts per gene for every cell\n\nWe can explore these files by clicking the data/ctrl_raw_feature_bc_matrix folder:\n\n1. barcodes.tsv\nThis is a text file which contains all cellular barcodes present for that sample. Barcodes are listed in the order of data presented in the matrix file (i.e. these are the column names).\n\n\n\n2. features.tsv\nThis is a text file which contains the identifiers of the quantified genes. The source of the identifier can vary depending on what reference (i.e. Ensembl, NCBI, UCSC) you use in the quantification methods, but most often these are official gene symbols. The order of these genes corresponds to the order of the rows in the matrix file (i.e. these are the row names).\n\n\n\n3. matrix.mtx\nThis is a text file which contains a matrix of count values. The rows are associated with the gene IDs above and columns correspond to the cellular barcodes. Note that there are many zero values in this matrix.\n\nLoading this data into R requires us to use functions that allow us to efficiently combine these three files into a single count matrix. However, instead of creating a regular matrix data structure, the functions we will use create a sparse matrix to reduce the amount of memory (RAM), processing capacity (CPU) and storage required to work with our huge count matrix.\nDifferent methods for reading in data include:\n\nreadMM(): This function is from the Matrix package and will convert our standard matrix into a sparse matrix. The features.tsv file and barcodes.tsv must first be individually loaded into R and then they can be combined. For specific code and instructions on how to do this please see these additional material.\nRead10X(): This function is from the Seurat package and will use the Cell Ranger output directory as input, directly. With this method individual files do not need to be loaded in, instead the function will load and combine them into a sparse matrix. We will be using this function to load in our data!\n\n\n\nReading in a single sample\nAfter processing 10X data using its proprietary software Cell Ranger, you will have an outs directory (always). Within this directory you will find a number of different files including the files listed below:\n\nweb_summary.html: report that explores different QC metrics, including the mapping metrics, filtering thresholds, estimated number of cells after filtering, and information on the number of reads and genes per cell after filtering.\nBAM alignment files: files used for visualization of the mapped reads and for re-creation of FASTQ files, if needed\nfiltered_feature_bc_matrix: folder containing all files needed to construct the count matrix using data filtered by Cell Ranger\nraw_feature_bc_matrix: folder containing all files needed to construct the count matrix using the raw unfiltered data\n\nWhile Cell Ranger performs filtering on the expression counts (see note below), we wish to perform our own QC and filtering because we want to account for the biology of our experiment/biological system. Given this we are only interested in the raw_feature_bc_matrix folder in the Cell Ranger output.\n\n\n\n\n\n\nNote\n\n\n\nWhy do we not use the filtered_feature_bc_matrix folder?** The filtered_feature_bc_matrix uses internal filtering criteria by Cell Ranger, and we do not have control of what cells to keep or abandon._\nThe filtering performed by Cell Ranger when generating the filtered_feature_bc_matrix is often good; however, sometimes data can be of very high quality and the Cell Ranger filtering process can remove high quality cells. In addition, it is generally preferable to explore your own data while taking into account the biology of the experiment for applying thresholds during filtering. For example, if you expect a particular cell type in your dataset to be smaller and/or not as transcriptionally active as other cell types in your dataset, these cells have the potential to be filtered out. However, with Cell Ranger v3 they have tried to account for cells of different sizes (for example, tumor vs infiltrating lymphocytes), and now may not filter as many low quality cells as needed.\n\n\nIf we had a single sample, we could generate the count matrix and then subsequently create a Seurat object:\n\n\n\n\n\n\nThe seurat object\n\n\n\nThe Seurat object is a custom list-like object that has well-defined spaces to store specific information/data. You can find more information about the slots in the Seurat object at this link.\n\n\n\n# How to read in 10X data for a single sample (output is a sparse matrix)\nctrl_counts &lt;- Read10X(data.dir = \"../data/ctrl_raw_feature_bc_matrix\")\n\n# Turn count matrix into a Seurat object (output is a Seurat object)\nctrl &lt;- CreateSeuratObject(counts = ctrl_counts,\n                           min.features = 100)\nctrl\n\nAn object of class Seurat \n33538 features across 15688 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe min.features argument specifies the minimum number of genes that need to be detected per cell. This argument will filter out poor quality cells that likely just have random barcodes encapsulated without any cell present. Usually, cells with less than 100 genes detected are not considered for analysis.\n\n\nSeurat automatically creates some metadata for each of the cells when you use the Read10X() function to read in data. This information is stored in the meta.data slot within the Seurat object.\n\n# Explore the metadata\nhead(ctrl@meta.data)\n\n                    orig.ident nCount_RNA nFeature_RNA\nAAACATACAATGCC-1 SeuratProject       2344          874\nAAACATACATTTCC-1 SeuratProject       3125          896\nAAACATACCAGAAA-1 SeuratProject       2578          725\nAAACATACCAGCTA-1 SeuratProject       3261          979\nAAACATACCATGCA-1 SeuratProject        746          362\nAAACATACCTCGCT-1 SeuratProject       3519          866\n\n\nWhat do the columns of metadata mean?\n\norig.ident: this often contains the sample identity if known, but will default to “SeuratProject”\nnCount_RNA: number of UMIs per cell\nnFeature_RNA: number of genes detected per cell\n\n\n\nReading in multiple samples with a for loop\nIn practice, you will likely have several samples that you will need to read in data for, and that can get tedious and error-prone if you do it one at a time. So, to make the data import into R more efficient we can use a for loop, which will iterate over a series of commands for each of the inputs given and create seurat objects for each of our samples.\nIn R, the for loop has the following structure/syntax:\n\n## DO NOT RUN\n\nfor (variable in input){\n    command1\n    command2\n    command3\n}\n\nToday we will use it to iterate over the two sample folders and execute two commands for each sample as we did above for a single sample -\n\nRead in the count data (Read10X()) and\nCreate the Seurat objects from the read in data (CreateSeuratObject())\n\nGo ahead and copy and paste the code below into your script and then run it.\n\nsample_names &lt;- c(\"ctrl\", \"stim\")\n\n# Empty list to populate seurat object for each sample\nlist_seurat &lt;- list()\n\nfor (sample in sample_names) {\n    # Path to data directory\n    data_dir &lt;- paste0(\"../data/\", sample, \"_raw_feature_bc_matrix\")\n\n    # Create a Seurat object for each sample\n    seurat_data &lt;- Read10X(data.dir = data_dir)\n    seurat_obj &lt;- CreateSeuratObject(counts = seurat_data,\n                                      min.features = 100,\n                                      project = sample)\n\n    # Save seurat object to list\n    list_seurat[[sample]] &lt;- seurat_obj\n}\n\nLet’s break down the for loop and go over the different lines of code:\n\n\n\n\n\n\nBreaking down the for loop\n\n\n\n\nStep 1: Specify inputs\nFor this dataset, we have two samples and two associated folders that we would like to use as input to create the two Seurat objects:\n\nctrl_raw_feature_bc_matrix\nstim_raw_feature_bc_matrix\n\nWe can specify these sample names in the input part for our for loop as elements of a vector using c(). We are assigning these to a variable and we can call that variable anything we would like (try to give it a name that makes sense). In this example, we called the variable sample.\nDuring the execution of the above loop, sample will first contain the value “ctrl”, run through the commands all the way through to storing the seurat object as a list. Next, it will contain the value “stim” and once again run through all the commands. If you had 15 folders as input, instead of 2, the above code will run through 15 times, for each of your data folders.\nTo start, let us test out what happens if we print out what sample looks like and the associated data_dir path we specify.\n\nsample_names &lt;- c(\"ctrl\", \"stim\")\n# Empty list to populate seurat object for each sample\nlist_seurat &lt;- list()\n\n# Create each individual Seurat object\nfor (sample in sample_names) {\n    print(sample)\n    # Path to data directory\n    data_dir &lt;- paste0(\"../data/\", sample, \"_raw_feature_bc_matrix\")\n    print(data_dir)\n}\n\n\n\nStep 2: Read in data for the input\nWe can continue our for loop by adding a line to read in data with Read10X():\n\n## DO NOT RUN\n        seurat_data &lt;- Read10X(data.dir = data_dir)\n\n\n\nStep 3: Create Seurat object from the 10X count data\nNow, we can create the Seurat object by using the CreateSeuratObject() nction, adding in the argument project, where we can add the sample name.\n\n## DO NOT RUN\n        seurat_obj &lt;- CreateSeuratObject(counts = seurat_data, \n                                         min.features = 100, \n                                         project = sample)        \n\n\n\nStep 4: Assign Seurat object to a new variable based on sample\nThe last command assignts the Seurat object created (seurat_obj) to the empty list that was initialized before the for loop. In this way, when we iterate and move on to the next sample in our input we will not overwrite the Seurat object created in the previous iteration:\n\n## DO NOT RUN\n        list_seurat[[sample]] &lt;- seurat_obj\n}\n\n\n\n\nNow that we have created both of these objects, let’s take a quick look at the list we just created. We should see that there are two seurat objects in our list that correspond to each sample.\n\nlist_seurat\n\n$ctrl\nAn object of class Seurat \n33538 features across 15688 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n$stim\nAn object of class Seurat \n33538 features across 15756 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n\nNext, we need to merge these objects together into a single Seurat object. This will make it easier to run the QC steps for both sample groups together and enable us to easily compare the data quality for all the samples.\nWe can use the merge() and JoinLayers() functions from the Seurat package to do this:\n\n# Create a merged Seurat object\nmerged_seurat &lt;- merge(x = list_seurat[[\"ctrl\"]], \n                       y = list_seurat[[\"stim\"]], \n                       add.cell.id = c(\"ctrl\", \"stim\"))\n\n# Concatenate the count matrices of both samples together\nmerged_seurat &lt;- JoinLayers(merged_seurat)\nmerged_seurat\n\nAn object of class Seurat \n33538 features across 31444 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n\nBecause the same cell IDs can be used for different samples, we add a sample-specific prefix to each of our cell IDs using the add.cell.id argument.\n\n\n\n\n\n\nWhat if I am merging more than two samples?\n\n\n\nSeurat now has functionality to merge many samples together. You can do this quite easily by adding all sample objects to the y argument in a vector format. An example is provided below:\n\n## DO NOT RUN\n merged_seurat &lt;- merge(x = seurat_list[[1]], \n                        y = seurat_list[[2:length(seurat_list)]],\n                        add.cell.id = names(seurat_list))\n\n\n\nIf we look at the metadata of the merged object we should be able to see the prefixes in the rownames:\n\n# Check that the merged object has the appropriate sample-specific prefixes\nhead(merged_seurat@meta.data)\n\n                      orig.ident nCount_RNA nFeature_RNA\nctrl_AAACATACAATGCC-1       ctrl       2344          874\nctrl_AAACATACATTTCC-1       ctrl       3125          896\nctrl_AAACATACCAGAAA-1       ctrl       2578          725\nctrl_AAACATACCAGCTA-1       ctrl       3261          979\nctrl_AAACATACCATGCA-1       ctrl        746          362\nctrl_AAACATACCTCGCT-1       ctrl       3519          866\n\ntail(merged_seurat@meta.data)\n\n                      orig.ident nCount_RNA nFeature_RNA\nstim_TTTGCATGCGACAT-1       stim        620          295\nstim_TTTGCATGCTAAGC-1       stim       1641          545\nstim_TTTGCATGGGACGA-1       stim       1233          518\nstim_TTTGCATGGTGAGG-1       stim       1084          469\nstim_TTTGCATGGTTTGG-1       stim        818          432\nstim_TTTGCATGTCTTAC-1       stim       1104          438"
  },
  {
    "objectID": "lessons/04_SC_quality_control.html",
    "href": "lessons/04_SC_quality_control.html",
    "title": "Quality Control Analysis",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/04_SC_quality_control.html#learning-objectives",
    "href": "lessons/04_SC_quality_control.html#learning-objectives",
    "title": "Quality Control Analysis",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nConstruct quality control metrics and visually evaluate the quality of the data\nApply appropriate filters to remove low quality cells"
  },
  {
    "objectID": "lessons/04_SC_quality_control.html#generating-quality-metrics",
    "href": "lessons/04_SC_quality_control.html#generating-quality-metrics",
    "title": "Quality Control Analysis",
    "section": "Generating quality metrics",
    "text": "Generating quality metrics\nWhen data is loaded into Seurat and the initial object is created, there is some basic metadata asssembled for each of the cells in the count matrix. To take a close look at this metadata, let’s view the data frame stored in the meta.data slot of our merged_seurat object:\n\n# Explore merged metadata\nView(merged_seurat@meta.data)\n\n\nThere are three columns of information:\n\norig.ident: this column will contain the sample identity if known. It will default to the value we provided for the project argument when loading in the data\nnCount_RNA: this column represents the number of UMIs per cell\nnFeature_RNA: this column represents the number of genes detected per cell\n\nIn order to create the appropriate plots for the quality control analysis, we need to calculate some additional metrics. These include:\n\nNumber of genes detected per UMI: this metric with give us an idea of the complexity of our dataset (more genes detected per UMI, more complex our data)\nMitochondrial ratio: this metric will give us a percentage of cell reads originating from the mitochondrial genes\n\n\nNovelty score\nThis value is quite easy to calculate, as we take the log10 of the number of genes detected per cell and the log10 of the number of UMIs per cell, then divide the log10 number of genes by the log10 number of UMIs. The novelty score and how it relates to complexity of the RNA species, is described in more detail later in this lesson.\n\n# Add number of genes per UMI for each cell to metadata\nmerged_seurat$log10GenesPerUMI &lt;- log10(merged_seurat$nFeature_RNA) / log10(merged_seurat$nCount_RNA)\n\n\n\nMitochondrial Ratio\nSeurat has a convenient function that allows us to calculate the proportion of transcripts mapping to mitochondrial genes. The PercentageFeatureSet() function takes in a pattern argument and searches through all gene identifiers in the dataset for that pattern. Since we are looking for mitochondrial genes, we are searching any gene identifiers that begin with the pattern “MT-”. For each cell, the function takes the sum of counts across all genes (features) belonging to the “Mt-” set, and then divides by the count sum for all genes (features). This value is multiplied by 100 to obtain a percentage value.\n\n\n\n\n\n\nNote\n\n\n\nFor our analysis, rather than using a percentage value we would prefer to work with the ratio value. As such, we will reverse that last step performed by the function by taking the output value and dividing by 100.\n\n\n\n# Compute percent mito ratio\nmerged_seurat$mitoRatio &lt;- PercentageFeatureSet(object = merged_seurat, pattern = \"^MT-\")\nmerged_seurat$mitoRatio &lt;- merged_seurat@meta.data$mitoRatio / 100\n\n\n\n\n\n\n\nNote\n\n\n\nThe pattern provided (“^MT-”) works for human gene names. You may need to adjust the pattern argument depending on your organism of interest. Additionally, if you weren’t using gene names as the gene ID then this function wouldn’t work as we have used it above as the pattern will not suffice. Since there are caveats to using this function, it is advisable to manually compute this metric. If you are interested, we have code available to compute this metric on your own.\n\n\n\n\nAdditional metadata columns\nWe are a now all set with quality metrics required for assessing our data. However, we would like to include some additional information that would be useful to have in our metadata including cell IDs and condition information.\nWhen we added columns of information to our metadata file above, we simply added it directly to the metadata slot in the Seurat object using the $ operator. We could continue to do so for the next few columns of data, but instead we will extract the dataframe into a separate variable. In this way we can work with the metadata data frame as a seperate entity from the seurat object without the risk of affecting any other data stored inside the object.\nLet’s begin by creating the metadata dataframe by extracting the meta.data slot from the Seurat object:\n\n# Create metadata dataframe\nmetadata &lt;- merged_seurat@meta.data\n\nNext, we’ll add a new column for cell identifiers. This information is currently located in the row names of our metadata dataframe. We will keep the rownames as is and duplicate it into a new column called cells:\n\n# Add cell IDs to metadata\nmetadata$cells &lt;- rownames(metadata)\n\nYou should see that each cell ID has a ctrl_ or stim_ prefix as we had specified when we merged the Seurat objects. We can use this prefix to create a new column indicating which condition each cell is classfied under. We will call this column sample:\n\n# Create sample column\nmetadata$sample &lt;- NA\nmetadata$sample[which(str_detect(metadata$cells, \"^ctrl_\"))] &lt;- \"ctrl\"\nmetadata$sample[which(str_detect(metadata$cells, \"^stim_\"))] &lt;- \"stim\"\n\nAnd finally, we will rename some of the existing columns in our metadata dataframe to be more intuitive:\n\n# Rename columns\nmetadata &lt;- metadata %&gt;%\n        dplyr::rename(seq_folder = orig.ident,\n                      nUMI = nCount_RNA,\n                      nGene = nFeature_RNA)\n\nNow you are all setup with the metrics you need to assess the quality of your data! Your final metadata table will have rows that correspond to each cell, and columns with information about those cells:\n\n\n\nSaving the updated metadata to our Seurat object\nBefore we assess our metrics we are going to save all of the work we have done thus far back into our Seurat object. We can do this by simply assigning the dataframe into the meta.data slot:\n\n# Add metadata back to Seurat object\nmerged_seurat@meta.data &lt;- metadata\n                           \n# Create .RData object to load at any time\nsave(merged_seurat, file=\"../data/merged_filtered_seurat.RData\")"
  },
  {
    "objectID": "lessons/04_SC_quality_control.html#assessing-the-quality-metrics",
    "href": "lessons/04_SC_quality_control.html#assessing-the-quality-metrics",
    "title": "Quality Control Analysis",
    "section": "Assessing the quality metrics",
    "text": "Assessing the quality metrics\nNow that we have generated the various metrics to assess, we can explore them with visualizations. We will assess various metrics and then decide on which cells are low quality and should be removed from the analysis:\n\nCell counts\nUMI counts per cell\nGenes detected per cell\nComplexity (novelty score)\nMitochondrial counts ratio\n\n\n\n\n\n\n\nWhat about doublets?\n\n\n\nIn single-cell RNA sequencing experiments, doublets are generated from two cells. They typically arise due to errors in cell sorting or capture, especially in droplet-based protocols involving thousands of cells. Doublets are obviously undesirable when the aim is to characterize populations at the single-cell level. In particular, they can incorrectly suggest the existence of intermediate populations or transitory states that do not actually exist. Thus, it is desirable to remove doublet libraries so that they do not compromise interpretation of the results.\n\n\n\n\n\n\n\n\nWhy aren’t we checking for doublets?\n\n\n\nMany workflows use maximum thresholds for UMIs or genes, with the idea that a much higher number of reads or genes detected indicate multiple cells. While this rationale seems to be intuitive, it is not accurate. Also, many of the tools used to detect doublets tend to get rid of cells with intermediate or continuous phenotypes, although they may work well on datasets with very discrete cell types. Scrublet is a popular tool for doublet detection, but we haven’t adequately benchmarked it yet. Currently, we recommend not including any thresholds at this point in time. When we have identified markers for each of the clusters, we suggest exploring the markers to determine whether the markers apply to more than one cell type.\n\n\n\nCell counts\nThe cell counts are determined by the number of unique cellular barcodes detected. For this experiment, between 12,000 -13,000 cells are expected.\nIn an ideal world, you would expect the number of unique cellular barcodes to correpsond to the number of cells you loaded. However, this is not the case as capture rates of cells are only a proportion of what is loaded. For example, the inDrops cell capture efficiency is higher (70-80%) compared to 10X which is between 50-60%.\n\n\n\n\n\n\nNote\n\n\n\nThe capture efficiency could appear much lower if the cell concentration used for library preparation was not accurate. Cell concentration should NOT be determined by FACS machine or Bioanalyzer (these tools are not accurate for concentration determination), instead use a hemocytometer or automated cell counter for calculation of cell concentration._\n\n\nThe cell numbers can also vary by protocol, producing cell numbers that are much higher than what we loaded. For example, during the inDrops protocol, the cellular barcodes are present in the hydrogels, which are encapsulated in the droplets with a single cell and lysis/reaction mixture. While each hydrogel should have a single cellular barcode associated with it, occasionally a hydrogel can have more than one cellular barcode. Similarly, with the 10X protocol there is a chance of obtaining only a barcoded bead in the emulsion droplet (GEM) and no actual cell. Both of these, in addition to the presence of dying cells can lead to a higher number of cellular barcodes than cells.\n\n# Visualize the number of cell counts per sample\nmetadata %&gt;% \n    ggplot(aes(x=sample, fill=sample)) + \n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n    theme(plot.title = element_text(hjust=0.5, face=\"bold\")) +\n    ggtitle(\"NCells\")\n\n\n\n\nWe see over 15,000 cells per sample, which is quite a bit more than the 12-13,000 expected. It is clear that we likely have some junk ‘cells’ present.\n\n\nUMI counts (transcripts) per cell\nThe UMI counts per cell should generally be above 500, that is the low end of what we expect. If UMI counts are between 500-1000 counts, it is usable but the cells probably should have been sequenced more deeply.\n\n# Visualize the number UMIs/transcripts per cell\nmetadata %&gt;% \n    ggplot(aes(color=sample, x=nUMI, fill= sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    ylab(\"Cell density\") +\n    geom_vline(xintercept = 500)\n\n\n\n\nWe can see that majority of our cells in both samples have 1000 UMIs or greater, which is great.\n\n\nGenes detected per cell\nWe have similar expectations for gene detection as for UMI detection, although it may be a bit lower than UMIs. For high quality data, the proportional histogram should contain a single large peak that represents cells that were encapsulated. If we see a small shoulder to the left of the major peak (not present in our data), or a bimodal distribution of the cells, that can indicate a couple of things. It might be that there are a set of cells that failed for some reason. It could also be that there are biologically different types of cells (i.e. quiescent cell populations, less complex cells of interest), and/or one type is much smaller than the other (i.e. cells with high counts may be cells that are larger in size). Therefore, this threshold should be assessed with other metrics that we describe in this lesson.\n\n# Visualize the distribution of genes detected per cell via histogram\nmetadata %&gt;% \n    ggplot(aes(color=sample, x=nGene, fill= sample)) + \n    geom_density(alpha = 0.2) + \n    theme_classic() +\n    scale_x_log10() + \n    geom_vline(xintercept = 300)\n\n\n\n\n\n\nComplexity\nWe can evaluate each cell in terms of how complex the RNA species are by using a measure called the novelty score. The novelty score is computed by taking the ratio of nGenes over nUMI. If there are many captured transcripts (high nUMI) and a low number of genes detected in a cell, this likely means that you only captured a low number of genes and simply sequenced transcripts from those lower number of genes over and over again. These low complexity (low novelty) cells could represent a specific cell type (i.e. red blood cells which lack a typical transcriptome), or could be due to an artifact or contamination. Generally, we expect the novelty score to be above 0.80 for good quality cells.\n\n# Visualize the overall complexity of the gene expression by visualizing the genes detected per UMI (novelty score)\nmetadata %&gt;%\n    ggplot(aes(x=log10GenesPerUMI, color = sample, fill=sample)) +\n    geom_density(alpha = 0.2) +\n    theme_classic() +\n    geom_vline(xintercept = 0.8)\n\n\n\n\n\n\nMitochondrial counts ratio\nThis metric can identify whether there is a large amount of mitochondrial contamination from dead or dying cells. We define poor quality samples for mitochondrial counts as cells which surpass the 0.2 mitochondrial ratio mark, unless of course you are expecting this in your sample.\n\n# Visualize the distribution of mitochondrial gene expression detected per cell\nmetadata %&gt;% \n    ggplot(aes(color=sample, x=mitoRatio, fill=sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 0.2)\n\n\n\n\n\n\n\n\n\n\nReads per cell\n\n\n\nThis is another metric that can be useful to explore; however, the workflow used would need to save this information to assess. Generally, with this metric you hope to see all of the samples with peaks in relatively the same location between 10,000 and 100,000 reads per cell.\n\n\n\n\nJoint filtering effects\nConsidering any of these QC metrics in isolation can lead to misinterpretation of cellular signals. For example, cells with a comparatively high fraction of mitochondrial counts may be involved in respiratory processes and may be cells that you would like to keep. Likewise, other metrics can have other biological interpretations. A general rule of thumb when performing QC is to set thresholds for individual metrics to be as permissive as possible, and always consider the joint effects of these metrics. In this way, you reduce the risk of filtering out any viable cell populations.\nTwo metrics that are often evaluated together are the number of UMIs and the number of genes detected per cell. Here, we have plotted the number of genes versus the number of UMIs coloured by the fraction of mitochondrial reads. Jointly visualizing the count and gene thresholds and additionally overlaying the mitochondrial fraction, gives a summarized persepective of the quality per cell.\n\n# Visualize the correlation between genes detected and number of UMIs and determine whether strong presence of cells with low numbers of genes/UMIs\nmetadata %&gt;% \n    ggplot(aes(x=nUMI, y=nGene, color=mitoRatio)) + \n    geom_point() + \n    scale_colour_gradient(low = \"gray90\", high = \"black\") +\n    stat_smooth(method=lm) +\n    scale_x_log10() + \n    scale_y_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 500) +\n    geom_hline(yintercept = 250) +\n    facet_wrap(~sample)\n\n\n\n\nGood cells will generally exhibit both higher number of genes per cell and higher numbers of UMIs (upper right quadrant of the plot). Cells that are poor quality are likely to have low genes and UMIs per cell, and correspond to the data points in the bottom left quadrant of the plot. With this plot we also evaluate the slope of the line, and any scatter of data points in the bottom right hand quadrant of the plot. These cells have a high number of UMIs but only a few number of genes. These could be dying cells, but also could represent a population of a low complexity celltype (i.e red blood cells).\nMitochondrial read fractions are only high in particularly low count cells with few detected genes (darker colored data points). This could be indicative of damaged/dying cells whose cytoplasmic mRNA has leaked out through a broken membrane, and thus, only mRNA located in the mitochondria is still conserved. We can see from the plot, that these cells are filtered out by our count and gene number thresholds."
  },
  {
    "objectID": "lessons/04_SC_quality_control.html#filtering",
    "href": "lessons/04_SC_quality_control.html#filtering",
    "title": "Quality Control Analysis",
    "section": "Filtering",
    "text": "Filtering\n\nCell-level filtering\nNow that we have visualized the various metrics, we can decide on the thresholds to apply which will result in the removal of low quality cells. Often the recommendations mentioned earlier are a rough guideline, and the specific experiment needs to inform the exact thresholds chosen. We will use the following thresholds:\n\nnUMI &gt; 500\nnGene &gt; 250\nlog10GenesPerUMI &gt; 0.8\nmitoRatio &lt; 0.2\n\nTo filter, we wil go back to our Seurat object and use the subset() function:\n\n# Filter out low quality cells using selected thresholds - these will change with experiment\nfiltered_seurat &lt;- subset(x = merged_seurat, \n                         subset= (nUMI &gt;= 500) & \n                           (nGene &gt;= 250) & \n                           (log10GenesPerUMI &gt; 0.80) & \n                           (mitoRatio &lt; 0.20))\nfiltered_seurat\n\nAn object of class Seurat \n33538 features across 29629 samples within 1 assay \nActive assay: RNA (33538 features, 0 variable features)\n 1 layer present: counts\n\n\n\n\nGene-level filtering\nWithin our data we will have many genes with zero counts. These genes can dramatically reduce the average expression for a cell and so we will remove them from our data. We will start by identifying which genes have a zero count in each cell:\n\n# Extract counts\ncounts &lt;- GetAssayData(object = filtered_seurat, layer = \"counts\")\n\n# Output a logical matrix specifying for each gene on whether or not there are more than zero counts per cell\nnonzero &lt;- counts &gt; 0\n\nNow, we will perform some filtering by prevalence. If a gene is only expressed in a handful of cells, it is not particularly meaningful as it still brings down the averages for all other cells it is not expressed in. For our data we choose to keep only genes which are expressed in 10 or more cells. By using this filter, genes which have zero counts in all cells will effectively be removed.\n\n# Sums all TRUE values and returns TRUE if more than 10 TRUE values per gene\nkeep_genes &lt;- Matrix::rowSums(nonzero) &gt;= 10\n\n# Only keeping those genes expressed in more than 10 cells\nfiltered_counts &lt;- counts[keep_genes, ]\n\nFinally, take those filtered counts and create a new Seurat object for downstream analysis.\n\n# Reassign to filtered Seurat object\nfiltered_seurat &lt;- CreateSeuratObject(filtered_counts, meta.data = filtered_seurat@meta.data)\nfiltered_seurat\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 1 layer present: counts"
  },
  {
    "objectID": "lessons/04_SC_quality_control.html#re-assess-qc-metrics",
    "href": "lessons/04_SC_quality_control.html#re-assess-qc-metrics",
    "title": "Quality Control Analysis",
    "section": "Re-assess QC metrics",
    "text": "Re-assess QC metrics\nAfter performing the filtering, it’s recommended to look back over the metrics to make sure that your data matches your expectations and is good for downstream analysis.\n\n\n\n\n\n\n\nExercises\n\n\n\n\nExtract the new metadata from the filtered Seurat object using the code provided below:\n\n\n# Save filtered subset to new metadata\nmetadata_clean &lt;- filtered_seurat@meta.data\n\n\nPerform all of the same QC plots using the filtered data.\nReport the number of cells left for each sample, and comment on whether the number of cells removed is high or low. Can you give reasons why this number is still not ~12K (which is how many cells were loaded for the experiment)?\nAfter filtering for nGene per cell, you should still observe a small shoulder to the right of the main peak. What might this shoulder represent?\nWhen plotting the nGene against nUMI do you observe any data points in the bottom right quadrant of the plot? What can you say about these cells that have been removed?"
  },
  {
    "objectID": "lessons/04_SC_quality_control.html#saving-filtered-cells",
    "href": "lessons/04_SC_quality_control.html#saving-filtered-cells",
    "title": "Quality Control Analysis",
    "section": "Saving filtered cells",
    "text": "Saving filtered cells\nBased on these QC metrics we would identify any failed samples and move forward with our filtered cells. Often we iterate through the QC metrics using different filtering criteria; it is not necessarily a linear process. When satisfied with the filtering criteria, we would save our filtered cell object for clustering and marker identification.\n\n# Create .RData object to load at any time\nsave(filtered_seurat, file=\"../data/seurat_filtered.RData\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe data we are working with is pretty good quality. If you are interested in knowing what ‘bad’ data might look like when performing QC, we have some materials linked here where we explore similar QC metrics of a poor quality sample._"
  },
  {
    "objectID": "lessons/02_SC_generation_of_count_matrix.html",
    "href": "lessons/02_SC_generation_of_count_matrix.html",
    "title": "Generation of count matrix",
    "section": "",
    "text": "Depending on the library preparation method used, the RNA sequences (also referred to as reads or tags), will be derived either from the 3’ ends (or 5’ ends) of the transcripts (10X Genomics, CEL-seq2, Drop-seq, inDrops) or from full-length transcripts (Smart-seq).\n\nImage credit: Papalexi E and Satija R. Single-cell RNA sequencing to explore immune cell heterogeneity, Nature Reviews Immunology 2018 (https://doi.org/10.1038/nri.2017.76)\nThe choice of method involves the biological question of interest. The following advantages are listed below for the methods:\n\n3’ (or 5’)-end sequencing:\n\nMore accurate quantification through the use of unique molecular identifiers distinguishing biological duplicates from amplification (PCR) duplicates\nLarger number of cells sequenced allows better identity of cell type populations\nCheaper per cell cost\nBest results with &gt; 10,000 cells\n\nFull length sequencing:\n\nDetection of isoform-level differences in expression\nIdentification of allele-specific differences in expression\nDeeper sequencing of a smaller number of cells\nBest for samples with low number of cells\n\n\nMany of the same analysis steps need to occur for 3’-end sequencing as for full-length, but 3’ protocols have been increasing in popularity and consist of a few more steps in the analysis. Therefore, our materials are going to detail the analysis of data from these 3’ protocols with a focus on the droplet-based methods (inDrops, Drop-seq, 10X Genomics)."
  },
  {
    "objectID": "lessons/02_SC_generation_of_count_matrix.html#single-cell-rna-seq-data---raw-data-to-count-matrix",
    "href": "lessons/02_SC_generation_of_count_matrix.html#single-cell-rna-seq-data---raw-data-to-count-matrix",
    "title": "Generation of count matrix",
    "section": "",
    "text": "Depending on the library preparation method used, the RNA sequences (also referred to as reads or tags), will be derived either from the 3’ ends (or 5’ ends) of the transcripts (10X Genomics, CEL-seq2, Drop-seq, inDrops) or from full-length transcripts (Smart-seq).\n\nImage credit: Papalexi E and Satija R. Single-cell RNA sequencing to explore immune cell heterogeneity, Nature Reviews Immunology 2018 (https://doi.org/10.1038/nri.2017.76)\nThe choice of method involves the biological question of interest. The following advantages are listed below for the methods:\n\n3’ (or 5’)-end sequencing:\n\nMore accurate quantification through the use of unique molecular identifiers distinguishing biological duplicates from amplification (PCR) duplicates\nLarger number of cells sequenced allows better identity of cell type populations\nCheaper per cell cost\nBest results with &gt; 10,000 cells\n\nFull length sequencing:\n\nDetection of isoform-level differences in expression\nIdentification of allele-specific differences in expression\nDeeper sequencing of a smaller number of cells\nBest for samples with low number of cells\n\n\nMany of the same analysis steps need to occur for 3’-end sequencing as for full-length, but 3’ protocols have been increasing in popularity and consist of a few more steps in the analysis. Therefore, our materials are going to detail the analysis of data from these 3’ protocols with a focus on the droplet-based methods (inDrops, Drop-seq, 10X Genomics)."
  },
  {
    "objectID": "lessons/02_SC_generation_of_count_matrix.html#end-reads-includes-all-droplet-based-methods",
    "href": "lessons/02_SC_generation_of_count_matrix.html#end-reads-includes-all-droplet-based-methods",
    "title": "Generation of count matrix",
    "section": "3’-end reads (includes all droplet-based methods)",
    "text": "3’-end reads (includes all droplet-based methods)\nFor the analysis of scRNA-seq data, it is helpful to understand what information is present in each of the reads and how we use it moving forward through the analysis.\nFor the 3’-end sequencing methods, reads originating from different molecules of the same transcript would have originated only from the 3’ end of the transcripts, so would have a high likelihood of having the same sequence. However, the PCR step during library preparation could also generate read duplicates. To determine whether a read is a biological or technical duplicate, these methods use unique molecular identifiers, or UMIs.\n\nReads with different UMIs mapping to the same transcript were derived from different molecules and are biological duplicates - each read should be counted.\nReads with the same UMI originated from the same molecule and are technical duplicates - the UMIs should be collapsed to be counted as a single read.\nIn image below, the reads for ACTB should be collapsed and counted as a single read, while the reads for ARL1 should each be counted.\n\n\nImage credit: modified from Macosko EZ et al. Highly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets, Cell 2015 (https://doi.org/10.1016/j.cell.2015.05.002)\nSo we know that we need to keep track of the UMIs, but what other information do we need to properly quantify the expression in each gene in each of the cells in our samples? Regardless of droplet method, the following are required for proper quantification at the cellular level:\n\n\nSample index: determines which sample the read originated from (red bottom arrow)\n\nAdded during library preparation - needs to be documented\n\nCellular barcode: determines which cell the read originated from (purple top arrow)\n\nEach library preparation method has a stock of cellular barcodes used during the library preparation\n\nUnique molecular identifier (UMI): determines which transcript molecule the read originated from\n\nThe UMI will be used to collapse PCR duplicates (purple bottom arrow)\n\nSequencing read1: the Read1 sequence (red top arrow)\nSequencing read2: the Read2 sequence (purple bottom arrow)\n\nImage credit: Sarah Boswell, Director of the Single Cell Sequencing Core at HMS"
  },
  {
    "objectID": "lessons/02_SC_generation_of_count_matrix.html#single-cell-rna-seq-workflow",
    "href": "lessons/02_SC_generation_of_count_matrix.html#single-cell-rna-seq-workflow",
    "title": "Generation of count matrix",
    "section": "Single-cell RNA-seq workflow",
    "text": "Single-cell RNA-seq workflow\nThe scRNA-seq method will determine how to parse the barcodes and UMIs from the sequencing reads. So, although a few of the specific steps will slightly differ, the overall workflow will generally follow the same steps regardless of method. The general workflow is shown below:\n\nImage credit: Luecken, MD and Theis, FJ. Current best practices in single‐cell RNA‐seq analysis: a tutorial, Mol Syst Biol 2019 (doi: https://doi.org/10.15252/msb.20188746)\nThe steps of the workflow are:\n\nGeneration of the count matrix (method-specific steps): formating reads, demultiplexing samples, mapping and quantification\nQuality control of the raw counts: filtering of poor quality cells\nClustering of filtered counts: clustering cells based on similarities in transcriptional activity (cell types = different clusters)\nMarker identification and cluster annotation: identifying gene markers for each cluster and annotating known cell type clusters\nOptional downstream steps\n\nRegardless of the analysis being done, conclusions about a population based on a single sample per condition are not trustworthy. BIOLOGICAL REPLICATES ARE STILL NEEDED! That is, if you want to make conclusions that correspond to the population and not just the single sample."
  },
  {
    "objectID": "lessons/02_SC_generation_of_count_matrix.html#generation-of-count-matrix",
    "href": "lessons/02_SC_generation_of_count_matrix.html#generation-of-count-matrix",
    "title": "Generation of count matrix",
    "section": "Generation of count matrix",
    "text": "Generation of count matrix\nWe are going to start by discussing the first part of this workflow, which is generating the count matrix from the raw sequencing data. We will focus on the 3’ end sequencing used by droplet-based methods, such as inDrops, 10X Genomics, and Drop-seq.\n\nAfter sequencing, the sequencing facility will either output the raw sequencing data as BCL or FASTQ format or will generate the count matrix. If the reads are in BCL format, then we will need to convert to FASTQ format. There is a useful command-line tool called bcl2fastq that can easily perform this conversion.\n\n\n\n\n\n\nNote\n\n\n\nWe do not demultiplex at this step in the workflow. You may have sequenced 6 samples, but the reads for all samples may be present all in the same BCL or FASTQ file.\n\n\nThe generation of the count matrix from the raw sequencing data will go through similar steps for many of the scRNA-seq methods.\n\nalevin is a command-line tool that estimates expression of scRNA-seq data for which the 3’ ends of transcripts were sequenced. umi-tools and zUMIs are additional tools that can perform these processes. These tools incorporate collapsing of UMIs to correct for amplification bias. The steps in this process include the following:\n\nFormatting reads and filtering noisy cellular barcodes\nDemultiplexing the samples\nMapping/pseudo-mapping to transcriptome\nCollapsing UMIs and quantification of reads\n\nIf using 10X Genomics library preparation method, then the Cell Ranger pipeline would be used for all of the above steps.\n\n1. Formatting reads and filtering noisy cellular barcodes\nThe FASTQ files can then be used to parse out the cell barcodes, UMIs, and sample barcodes. For droplet-based methods, many of the cellular barcodes will match a low number of reads (&lt; 1000 reads) due to:\n\nencapsulation of free floating RNA from dying cells\nsimple cells (RBCs, etc.) expressing few genes\ncells that failed for some reason\n\nThese excess barcodes need to be filtered out of the sequence data prior to read alignment. To do this filtering, the ‘cellular barcode’ and the ‘molecular barcode’ are extracted and saved for each cell. For example, if using umi-tools, the information is added to the header line for each read, with the following format:\n@HWI-ST808:130:H0B8YADXX:1:1101:2088:2222:CELL_GGTCCA:UMI_CCCT\nAGGAAGATGGAGGAGAGAAGGCGGTGAAAGAGACCTGTAAAAAGCCACCGN\n+\n@@@DDBD&gt;=AFCF+&lt;CAFHDECII:DGGGHGIGGIIIEHGIIIGIIDHII#\nKnown cellular barcodes used in the library preparation method should be known, and unknown barcodes would be dropped, while allowing for an acceptable number of mismatches to the known cellular barcodes.\n\n\n2. Demultiplexing sample reads\nThe next step of the process is to demultiplex the samples, if sequencing more than a single sample. This is the one step of this process not handled by the umi-tools, but is accomplished by zUMIs. We would need to parse the reads to determine the sample barcode associated with each cell.\n\n\n3. Mapping/pseudo-mapping to cDNAs\nTo determine which gene the read originated from, the reads are aligned using traditional (STAR) or light-weight methods (Kallisto/RapMap).\n\n\n4. Collapsing UMIs and quantification of reads\nThe duplicate UMIs are collapsed, and only the unique UMIs are quantified using a tool like Kallisto or featureCounts. The resulting output is a cell by gene matrix of counts:\n\nImage credit: extracted from Lafzi et al. Tutorial: guidelines for the experimental design of single-cell RNA sequencing studies, Nature Protocols 2018 (https://doi.org/10.1038/s41596-018-0073-y)\nEach value in the matrix represents the number of reads in a cell originating from the corresponding gene. Using the count matrix, we can explore and filter the data, keeping only the higher quality cells."
  },
  {
    "objectID": "lessons/links-to-lessons.html",
    "href": "lessons/links-to-lessons.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "lessons/links-to-lessons.html#installations",
    "href": "lessons/links-to-lessons.html#installations",
    "title": "",
    "section": "Installations",
    "text": "Installations\n\nFollow the instructions linked here to download R and RStudio + Install Packages from CRAN and Bioconductor\nDownload this project"
  },
  {
    "objectID": "lessons/links-to-lessons.html#lessons",
    "href": "lessons/links-to-lessons.html#lessons",
    "title": "",
    "section": "Lessons",
    "text": "Lessons\n\nPart 1\n\n[Introduction to scRNA-seq01_intro_to_scRNA-seq.qmd)\n[Raw data to count matrix02_SC_generation_of_count_matrix.qmd)\n\n\n\n\nPart II\n\nQuality control set-up\nQuality control\nOverview of Clustering Workflow\nTheory of PCA\nNormalization and regressing out unwanted variation\n\n\nSolution to exercises in above lessons\n\n\n\n\nPart III\n\nIntegration\nClustering\nClustering quality control\nMarker identification\n\n\nSolution to exercises in above lessons"
  },
  {
    "objectID": "lessons/links-to-lessons.html#building-on-this-workshop",
    "href": "lessons/links-to-lessons.html#building-on-this-workshop",
    "title": "",
    "section": "Building on this workshop",
    "text": "Building on this workshop\n\nDownstream analysis\n\nDifferential expression between conditions\n\nOther online scRNA-seq courses:\n\nhttp://bioconductor.org/books/release/OSCA/\nhttps://liulab-dfci.github.io/bioinfo-combio/\nhttps://hemberg-lab.github.io/scRNA.seq.course/\nhttps://github.com/SingleCellTranscriptomics\nhttps://broadinstitute.github.io/2020_scWorkshop/\n\nResources for scRNA-seq Sample Prep:\n\nhttps://www.protocols.io/\nhttps://support.10xgenomics.com/single-cell-gene-expression/sample-prep\nhttps://community.10xgenomics.com/"
  },
  {
    "objectID": "lessons/links-to-lessons.html#resources",
    "href": "lessons/links-to-lessons.html#resources",
    "title": "",
    "section": "Resources",
    "text": "Resources\nWe have covered the analysis steps in quite a bit of detail for scRNA-seq exploration of cellular heterogeneity using the Seurat package. For more information on topics covered, we encourage you to take a look at the following resources:\n\nSeurat vignettes\nSeurat cheatsheet\nSatija Lab: Single Cell Genomics Day\n“Principal Component Analysis (PCA) clearly explained”, a video from Josh Starmer\nAdditional information about cell cycle scoring\nUsing R on the O2 cluster\nHighlighted papers for sample processing steps (pre-sequencing):\n\n“Sampling time-dependent artifacts in single-cell genomics studies.” Massoni-Badosa et al. 2019\n“Dissociation of solid tumor tissues with cold active protease for single-cell RNA-seq minimizes conserved collagenase-associated stress responses.” O’Flanagan et al. 2020\n“Systematic assessment of tissue dissociation and storage biases in single-cell and single-nucleus RNA-seq workflows.” Denisenko et al. 2020\n\nBest practices for single-cell analysis across modalities"
  },
  {
    "objectID": "lessons/QC_bad_data.html",
    "href": "lessons/QC_bad_data.html",
    "title": "Low Quality Samples",
    "section": "",
    "text": "The cell counts are determined by the number of unique cellular barcodes detected. During the droplet-based protocols, the cellular barcodes are present in the hydrogels, which are encapsulated in the droplets with a single cell and lysis/reaction mixture. While each hydrogel should have a single cellular barcode associated with it, occasionally a hydrogel can have more than one cellular barcode. We often see all possible combinations of cellular barcodes at a low level, leading to a higher number of cellular barcodes than cells.\nYou expect the number of unique cellular barcodes to be often greater than the number of seuqenced cells due to some hydrogels having more than one cellular barcode. The yellow sample below seems to have at least double the number of cellular barcodes as the other samples.\n\n\n\n\nThe number of UMIs per cell tends to be very low for the Unsorted sample (yellow). The other samples have good numbers of UMIs per cell, indicating a problem only with the Unsorted sample. Using this cutoff, we will lose the majority of the Unsorted cells.\n\n\n\n\nSeeing gene detection in the range of 500-5000 is normal for inDrop/10X analyses. However, expectations can vary depending on the complexity of the cells expected in the experiment. Similar expectations for gene detection as for UMI detection.\nAll samples other than the Unsorted sample have a good number of genes detected (with medians between 1,000 - 3,000 genes), which correspond to the numbers of UMIs per cell for each sample. However, the Unsorted sample has a very low median number of genes per cell, indicating a sample failure.\n\n\n\n\nPoor quality cells are likely to have low genes and UMIs per cell. Therefore, a poor sample is likely to have cells in the lower left of the graph. Good cells should exhibit both higher number of genes per cell and higher numbers of UMIs. We also expect similar lines with similar slopes for all samples.\nThe Unsorted sample has many cells with few UMIs and low number of genes per cell. The other samples look fine.\n\n\n\n\nPoor quality samples for mitochondrial counts would have larger peaks above the 0.1 mitochondrial ratio mark, unless it is expected based on sample type.\nThere was just a very low number of genes detected for the Unsorted sample, so mitochondrial expression appears higher mainly due to this fact. The poor quality of the Unsorted sample does not appear to be due to dead or dying cells. The other samples have little mitochondrial expression, although hPSC sample has a bit more than the Sorted samples. Since the hPSC sample was expected to have cell types with higher levels of mitochondrial expression, it may have been advisable to not to use a threshold for this metric.\n\n\n\n\nWe can see the samples where we sequenced each cell less have a higher overall novelty, that is because we have not started saturated the sequencing for any given gene for these samples. Outlier cells in these samples might be cells that we have a less complex RNA species than other cells. Sometimes we can detect contamination with low complexity cell types like red blood cells via this metric.\nAll of the samples look fine for complexity, except for the Unsorted sample, so it is unlikely that there is contamination with low complexity cell types in these of the samples. The Unsorted sample has a larger shoulder than desired, but is not bad by this metric.\n\n\n\n\nOne main plot to look at to determine the success of the filtering criteria is the number of cell counts. The number of cells to expect depends on the library preparation method, but for inDrops we see ~80% or less of the total sequenced cells per sample and for 10X it is often ~50% or less.\nCell counts\n\nIn addition, it is a good idea to explore all of the quality plots for the filtered data. All plots should be much improved for the number of reads per cell, genes detected, UMIs per cell, mitochondrial ratio, and novelty. Since the Unsorted sample was a poor quality sample, the filter will remove a large number of the cells for this sample; in this case all cells except 1 were filtered out."
  },
  {
    "objectID": "lessons/QC_bad_data.html#cell-counts",
    "href": "lessons/QC_bad_data.html#cell-counts",
    "title": "Low Quality Samples",
    "section": "",
    "text": "The cell counts are determined by the number of unique cellular barcodes detected. During the droplet-based protocols, the cellular barcodes are present in the hydrogels, which are encapsulated in the droplets with a single cell and lysis/reaction mixture. While each hydrogel should have a single cellular barcode associated with it, occasionally a hydrogel can have more than one cellular barcode. We often see all possible combinations of cellular barcodes at a low level, leading to a higher number of cellular barcodes than cells.\nYou expect the number of unique cellular barcodes to be often greater than the number of seuqenced cells due to some hydrogels having more than one cellular barcode. The yellow sample below seems to have at least double the number of cellular barcodes as the other samples."
  },
  {
    "objectID": "lessons/QC_bad_data.html#umi-counts-per-cell",
    "href": "lessons/QC_bad_data.html#umi-counts-per-cell",
    "title": "Low Quality Samples",
    "section": "",
    "text": "The number of UMIs per cell tends to be very low for the Unsorted sample (yellow). The other samples have good numbers of UMIs per cell, indicating a problem only with the Unsorted sample. Using this cutoff, we will lose the majority of the Unsorted cells."
  },
  {
    "objectID": "lessons/QC_bad_data.html#genes-detected-per-cell",
    "href": "lessons/QC_bad_data.html#genes-detected-per-cell",
    "title": "Low Quality Samples",
    "section": "",
    "text": "Seeing gene detection in the range of 500-5000 is normal for inDrop/10X analyses. However, expectations can vary depending on the complexity of the cells expected in the experiment. Similar expectations for gene detection as for UMI detection.\nAll samples other than the Unsorted sample have a good number of genes detected (with medians between 1,000 - 3,000 genes), which correspond to the numbers of UMIs per cell for each sample. However, the Unsorted sample has a very low median number of genes per cell, indicating a sample failure."
  },
  {
    "objectID": "lessons/QC_bad_data.html#umis-vs.-genes-detected",
    "href": "lessons/QC_bad_data.html#umis-vs.-genes-detected",
    "title": "Low Quality Samples",
    "section": "",
    "text": "Poor quality cells are likely to have low genes and UMIs per cell. Therefore, a poor sample is likely to have cells in the lower left of the graph. Good cells should exhibit both higher number of genes per cell and higher numbers of UMIs. We also expect similar lines with similar slopes for all samples.\nThe Unsorted sample has many cells with few UMIs and low number of genes per cell. The other samples look fine."
  },
  {
    "objectID": "lessons/QC_bad_data.html#mitochondrial-counts-ratio",
    "href": "lessons/QC_bad_data.html#mitochondrial-counts-ratio",
    "title": "Low Quality Samples",
    "section": "",
    "text": "Poor quality samples for mitochondrial counts would have larger peaks above the 0.1 mitochondrial ratio mark, unless it is expected based on sample type.\nThere was just a very low number of genes detected for the Unsorted sample, so mitochondrial expression appears higher mainly due to this fact. The poor quality of the Unsorted sample does not appear to be due to dead or dying cells. The other samples have little mitochondrial expression, although hPSC sample has a bit more than the Sorted samples. Since the hPSC sample was expected to have cell types with higher levels of mitochondrial expression, it may have been advisable to not to use a threshold for this metric."
  },
  {
    "objectID": "lessons/QC_bad_data.html#novelty",
    "href": "lessons/QC_bad_data.html#novelty",
    "title": "Low Quality Samples",
    "section": "",
    "text": "We can see the samples where we sequenced each cell less have a higher overall novelty, that is because we have not started saturated the sequencing for any given gene for these samples. Outlier cells in these samples might be cells that we have a less complex RNA species than other cells. Sometimes we can detect contamination with low complexity cell types like red blood cells via this metric.\nAll of the samples look fine for complexity, except for the Unsorted sample, so it is unlikely that there is contamination with low complexity cell types in these of the samples. The Unsorted sample has a larger shoulder than desired, but is not bad by this metric."
  },
  {
    "objectID": "lessons/QC_bad_data.html#filtered-results",
    "href": "lessons/QC_bad_data.html#filtered-results",
    "title": "Low Quality Samples",
    "section": "",
    "text": "One main plot to look at to determine the success of the filtering criteria is the number of cell counts. The number of cells to expect depends on the library preparation method, but for inDrops we see ~80% or less of the total sequenced cells per sample and for 10X it is often ~50% or less.\nCell counts\n\nIn addition, it is a good idea to explore all of the quality plots for the filtered data. All plots should be much improved for the number of reads per cell, genes detected, UMIs per cell, mitochondrial ratio, and novelty. Since the Unsorted sample was a poor quality sample, the filter will remove a large number of the cells for this sample; in this case all cells except 1 were filtered out."
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html",
    "href": "lessons/seurat_cheatsheet.html",
    "title": "Seurat Cheatsheet",
    "section": "",
    "text": "This cheatsheet is meant to provide examples of the various functions available in Seurat. This includes how to access certain information, handy tips, and visualization functions built into the package. We have pulled together all of this information with examples using the dataset used throughout this workshop so that there are clear visuals on what the output of each function is.\nThese materials were developed by referencing the following pages from the Seurat website:\n\nhttps://satijalab.org/seurat/articles/essential_commands.html\nhttps://satijalab.org/seurat/articles/visualization_vignette.html"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#seurat-cheatsheet",
    "href": "lessons/seurat_cheatsheet.html#seurat-cheatsheet",
    "title": "Seurat Cheatsheet",
    "section": "",
    "text": "This cheatsheet is meant to provide examples of the various functions available in Seurat. This includes how to access certain information, handy tips, and visualization functions built into the package. We have pulled together all of this information with examples using the dataset used throughout this workshop so that there are clear visuals on what the output of each function is.\nThese materials were developed by referencing the following pages from the Seurat website:\n\nhttps://satijalab.org/seurat/articles/essential_commands.html\nhttps://satijalab.org/seurat/articles/visualization_vignette.html"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#cell-barcodes",
    "href": "lessons/seurat_cheatsheet.html#cell-barcodes",
    "title": "Seurat Cheatsheet",
    "section": "Cell barcodes",
    "text": "Cell barcodes\nWithin Seurat, there are multiple ways to access the cell barcode IDs.\nWe can use colnames() to get a vector of cell barcodes in the same order as they appear in the Seurat object.\n\ncolnames(seurat_integrated) %&gt;% head()\n\n[1] \"ctrl_AAACATACAATGCC-1\" \"ctrl_AAACATACATTTCC-1\" \"ctrl_AAACATACCAGAAA-1\"\n[4] \"ctrl_AAACATACCAGCTA-1\" \"ctrl_AAACATACCATGCA-1\" \"ctrl_AAACATACCTCGCT-1\"\n\n\nSimilarly we can use the Cells() function:\n\nCells(seurat_integrated) %&gt;% head()\n\n[1] \"ctrl_AAACATACAATGCC-1\" \"ctrl_AAACATACATTTCC-1\" \"ctrl_AAACATACCAGAAA-1\"\n[4] \"ctrl_AAACATACCAGCTA-1\" \"ctrl_AAACATACCATGCA-1\" \"ctrl_AAACATACCTCGCT-1\"\n\n\nIt is very important that the values stored in Cells() are the same as the rownames in meta.data. Otherwise Seurat will start throwing errors at you!\n\nall(rownames(seurat_integrated@meta.data) == Cells(seurat_integrated))\n\n[1] TRUE"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#featuresgenes",
    "href": "lessons/seurat_cheatsheet.html#featuresgenes",
    "title": "Seurat Cheatsheet",
    "section": "Features/genes",
    "text": "Features/genes\nNow we want to be able to access the rows, or genes, in our Seurat object. Rather than calling these values “genes”, many tools will call them “features” as different assays (CITE-seq, ATAC-seq) provide alternative information than genes as output.\nThe Features() function returns a vector of all features/genes in our dataset in the same order as it appears in the count matrix.\n\nFeatures(seurat_integrated) %&gt;% head()\n\n[1] \"FTL\"   \"IGKC\"  \"CCL2\"  \"GNLY\"  \"IGLC2\" \"CCL3\" \n\n\nThe rownames() function provides the same output:\n\nrownames(seurat_integrated) %&gt;% head()\n\n[1] \"FTL\"   \"IGKC\"  \"CCL2\"  \"GNLY\"  \"IGLC2\" \"CCL3\" \n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nWhat are the last 5 cells barcodes and the last 5 genes in the integrated seurat object."
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#number-of-cells-and-features",
    "href": "lessons/seurat_cheatsheet.html#number-of-cells-and-features",
    "title": "Seurat Cheatsheet",
    "section": "Number of cells and features",
    "text": "Number of cells and features\nIf you recall, Seurat stores your count matrix as cells (columns) x genes (rows).\nTherefore, we can access the number of cells by using the ncol() function.\n\nncol(seurat_integrated)\n\n[1] 29629\n\n\nThe number of features is returned with the nrow() function:\n\nnrow(seurat_integrated)\n\n[1] 3000\n\n\nThe dim() function provides both the number of cells and genes for the default assay. Here we see the number of features followed by the number of cells:\n\ndim(seurat_integrated)\n\n[1]  3000 29629"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#rename-idents",
    "href": "lessons/seurat_cheatsheet.html#rename-idents",
    "title": "Seurat Cheatsheet",
    "section": "Rename Idents",
    "text": "Rename Idents\nTo quickly make modifications to identities, you can use the RenameIdents() function where new values are mapped to the identities. This is particularly helpful when annotating your cells from clusters to celltypes as showcased here. Bear in mind that these new identities are not stored in the meta.data automatically. We recommend adding these identities as a new column in the Seurat object to keep track of it for future use.\n\n# Rename all identities\nseurat_integrated &lt;- RenameIdents(object = seurat_integrated, \n                                 \"1\" = \"CD14+ monocytes\",\n                                 \"3\" = \"CD14+ monocytes\",\n                                 \"2\" = \"Activated T cells\"\n                                 )\n\n# These new celltype values are only stored in the idents\n# Good practice is to store these changes in a column\nseurat_integrated$celltype &lt;- Idents(seurat_integrated)\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nWhat are the last 5 identities for the cells in the integrated seurat object?"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#accessing-variable-features",
    "href": "lessons/seurat_cheatsheet.html#accessing-variable-features",
    "title": "Seurat Cheatsheet",
    "section": "Accessing variable features",
    "text": "Accessing variable features\nTo obtain a vector of all highly variable genes that were selected after running FindVariableFeatures(), we can use the VariableFeatures() function.\n\nVariableFeatures(seurat_integrated) %&gt;% head()\n\n[1] \"FTL\"   \"IGKC\"  \"CCL2\"  \"GNLY\"  \"IGLC2\" \"CCL3\""
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#setting-variable-features",
    "href": "lessons/seurat_cheatsheet.html#setting-variable-features",
    "title": "Seurat Cheatsheet",
    "section": "Setting variable features",
    "text": "Setting variable features\nUsing the same VariableFeatures() function, we can set our own custom set of genes as our highly variable genes.\nAs an example, here we are omitting mitochondrial genes from the original list of variable genes:\n\n# Get list of all variable genes\n# Remove variable genes that start with MT-\nvar_genes &lt;- VariableFeatures(seurat_integrated)\nvar_genes &lt;- var_genes[!startsWith(var_genes, \"MT-\")]\n\n# Now we set our vector of gene names back to VariableFeatures()\nVariableFeatures(seurat_integrated) &lt;- var_genes\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nWhat are the the 5 least variable genes in the integrated seurat object?"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#assays",
    "href": "lessons/seurat_cheatsheet.html#assays",
    "title": "Seurat Cheatsheet",
    "section": "Assays",
    "text": "Assays\nWithin a Seurat object you can have multiple “assays”. Each assay contains its own count matrix that is separate from the other assays in the object. This structure was created with multimodal datasets in mind so we can store, for example, ATAC peaks within the same Seurat object as your RNA counts.\nSCTransform also makes use of these assays to store the SCT normalized matrix in a separate assay called “SCT”.\nTo access the list of assays in your Seurat object, you can call @assays.\n\nseurat_integrated@assays\n\n$RNA\nAssay data with 14065 features for 29629 cells\nFirst 10 features:\n AL627309.1, AL669831.5, LINC00115, FAM41C, NOC2L, KLHL17, PLEKHN1,\nHES4, ISG15, AGRN \n\n$SCT\nSCTAssay data with 14065 features for 29629 cells, and 2 SCTModel(s) \nFirst 10 features:\n AL627309.1, AL669831.5, LINC00115, FAM41C, NOC2L, KLHL17, PLEKHN1,\nHES4, ISG15, AGRN \n\n$integrated\nSCTAssay data with 3000 features for 29629 cells, and 1 SCTModel(s) \nTop 10 variable features:\n FTL, IGKC, CCL2, GNLY, IGLC2, CCL3, CCL4, CXCL10, CCL7, TIMP1 \n\n\nWe can additionally see which of the assays in our dataset is set as the default with the DefaultAssays() function. This default assay is automatically used as by Seurat functions, unless you specify otherise in the parameters of your function.\n\nDefaultAssay(seurat_integrated)\n\n[1] \"integrated\"\n\n\nHere we can see that the default assay is set to “integrated”. If we instead wanted to use the RNA counts, we can set a new default by once again calling the DefaultAssay() function and storing the name of a different assay.\n\n# Set new default assay\nDefaultAssay(seurat_integrated) &lt;- \"RNA\"\n\n# Print out the new default to see if it changed\nDefaultAssay(seurat_integrated)\n\n[1] \"RNA\"\n\n\nWe can access each assay as if the Seurat object was a named list with double brackets:\n\nseurat_integrated[[\"SCT\"]]\n\nSCTAssay data with 14065 features for 29629 cells, and 2 SCTModel(s) \nFirst 10 features:\n AL627309.1, AL669831.5, LINC00115, FAM41C, NOC2L, KLHL17, PLEKHN1,\nHES4, ISG15, AGRN \n\n\nAnd similarly run any function on it:\n\ndim(seurat_integrated[[\"integrated\"]])\n\n[1]  3000 29629\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nWhat are the dimensions for each assay in the integrated seurat object?"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#layers",
    "href": "lessons/seurat_cheatsheet.html#layers",
    "title": "Seurat Cheatsheet",
    "section": "Layers",
    "text": "Layers\nLayers are the different counts matrices that you can access within each assay (prior to Seurat version 5, this feature was known as “slots”).\nFollowing the standard Seurat workflow, you would have the following matrices:\n\ncounts (raw counts matrix)\ndata (normalized count matrix (generated after SCTransform() or NormalizeData())\nscale.data (output from the ScaleData())\n\nWe can see which layers are accessible with the Layers() function.\n\nLayers(seurat_integrated[[\"RNA\"]])\n\n[1] \"counts\" \"data\"  \n\n\nIn this object we can see that we do not have the scale.data layer currently. So if we run ScaleData() we will be able to access this layer/matrix.\n\nseurat_integrated &lt;- ScaleData(seurat_integrated)\nLayers(seurat_integrated)\n\n[1] \"counts\"     \"data\"       \"scale.data\""
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#accessing-full-count-matrix",
    "href": "lessons/seurat_cheatsheet.html#accessing-full-count-matrix",
    "title": "Seurat Cheatsheet",
    "section": "Accessing full count matrix",
    "text": "Accessing full count matrix\nYou can grab the entire counts matrix by making use of the LayerData() function.\n\n# Subsetting to the first 5 genes and cells for easy viewing\nLayerData(seurat_integrated, assay=\"RNA\", layer=\"counts\")[1:5, 1:5]\n\n5 x 5 sparse Matrix of class \"dgCMatrix\"\n           ctrl_AAACATACAATGCC-1 ctrl_AAACATACATTTCC-1 ctrl_AAACATACCAGAAA-1\nAL627309.1                     .                     .                     .\nAL669831.5                     .                     .                     .\nLINC00115                      .                     .                     .\nFAM41C                         .                     .                     .\nNOC2L                          .                     .                     .\n           ctrl_AAACATACCAGCTA-1 ctrl_AAACATACCATGCA-1\nAL627309.1                     .                     .\nAL669831.5                     .                     .\nLINC00115                      .                     .\nFAM41C                         .                     .\nNOC2L                          .                     .\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nShow the code to get the entire SCT normalized (data) count matrix."
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#accessing-specific-features-and-metadata",
    "href": "lessons/seurat_cheatsheet.html#accessing-specific-features-and-metadata",
    "title": "Seurat Cheatsheet",
    "section": "Accessing specific features and metadata",
    "text": "Accessing specific features and metadata\nThe FetchData() function is useful to directly access the counts of a feature for each cell. You can also specify the layer and assay to specify which piece of information you want.\n\n# Normalized counts for the gene PTPRC in the assay SCT\nFetchData(seurat_integrated, vars=c(\"PTPRC\", \"sample\"), assay=\"SCT\", layer=\"data\") %&gt;% head()\n\n                         PTPRC sample\nctrl_AAACATACAATGCC-1 2.254699   ctrl\nctrl_AAACATACATTTCC-1 1.435328   ctrl\nctrl_AAACATACCAGAAA-1 1.584935   ctrl\nctrl_AAACATACCAGCTA-1 1.403025   ctrl\nctrl_AAACATACCATGCA-1 2.667563   ctrl\nctrl_AAACATACCTCGCT-1 0.000000   ctrl\n\n\nConveniently, you can also get information from multiple assays at the same time. To do so, you prepend the assay name (in lowercase format) for the feature you supply to the FetchData() function.\n\n# Grab the normalized counts in the integrated and RNA assays\nFetchData(seurat_integrated, vars=c(\"rna_PTPRC\", \"integrated_PTPRC\"), layer=\"data\") %&gt;% head()\n\n                      rna_PTPRC integrated_PTPRC\nctrl_AAACATACAATGCC-1  2.254699        0.4585611\nctrl_AAACATACATTTCC-1  1.435328       -0.3528445\nctrl_AAACATACCAGAAA-1  1.584935       -0.1980966\nctrl_AAACATACCAGCTA-1  1.403025       -0.3175056\nctrl_AAACATACCATGCA-1  2.667563        0.7853486\nctrl_AAACATACCTCGCT-1  0.000000       -0.8399404\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nShow how you would use the FetchData() function to generate a dataframe of UMAP_1, UMAP_2, and sample values for each cell."
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#pca",
    "href": "lessons/seurat_cheatsheet.html#pca",
    "title": "Seurat Cheatsheet",
    "section": "PCA",
    "text": "PCA\nThe scores for each PC is stored within the embeddings slot of the Seurat object. These can be accessed by using the Embeddings() function.\n\n# Alternative method of accessing PCA values\n# seurat_integrated[['pca']]@cell.embeddings\nEmbeddings(seurat_integrated, reduction=\"pca\")[1:5, 1:5]\n\n                             PC_1      PC_2      PC_3       PC_4        PC_5\nctrl_AAACATACAATGCC-1 -14.9778236 -2.879193 -5.059351  -1.602766   0.8728779\nctrl_AAACATACATTTCC-1  22.3923271 -5.296913  4.951958   3.112632   0.3379874\nctrl_AAACATACCAGAAA-1  28.9847264  1.203408 -5.947993  -1.042701  -7.5690434\nctrl_AAACATACCAGCTA-1  20.1284164  2.826128 -5.265061  -3.620790 -11.3740400\nctrl_AAACATACCATGCA-1  -0.4713399  1.122713  5.195209 -23.884004  -2.2996247\n\n\nThe weight (loadings) for each feature is also stored and can be accessed with Loadings() function.\n\n# pbmc[['pca]]@feature.loadings\nLoadings(seurat_integrated, reduction=\"pca\")[1:5, 1:5]\n\n              PC_1         PC_2        PC_3        PC_4        PC_5\nFTL    0.424580221 -0.029245940 -0.07877921 -0.01084091 -0.17392237\nIGKC  -0.022397858 -0.113342789  0.24606406  0.09924655 -0.08598287\nCCL2   0.138755172  0.002935082 -0.07471508 -0.02671091 -0.25223145\nGNLY  -0.017962104  0.357256939  0.07523939  0.10126832 -0.05577892\nIGLC2 -0.007534059 -0.037760970  0.07610433  0.03463625 -0.02070632\n\n\nWe can also view more information about the top PCs, like the genes that are most strongly correlated with the first few PCs with the ProjectDim() function.\n\nProjectDim(seurat_integrated, reduction = \"pca\")\n\nPC_ 1 \nPositive:  FTL, TIMP1, FTH1, C15orf48, CXCL8, CCL2, S100A8, FCER1G, TYROBP, S100A4 \n       CD63, LGALS3, LYZ, S100A9, ACTB, LGALS1, ANXA5, HLA-DRA, SOD2, S100A11 \nNegative:  RPL3, RPL13, RPS6, RPS18, RPL10, RPL21, RPL13A, RPS2, RPS4X, RPS3 \n       RPS14, RPL32, RPL7, PABPC1, RPS19, RPL34, TRAC, RPS3A, RPS27A, TRBC1 \nPC_ 2 \nPositive:  GNLY, CCL5, NKG7, GZMB, FGFBP2, CST7, APOBEC3G, GZMH, KLRD1, CLIC3 \n       PRF1, GZMA, CTSW, CHST12, HOPX, HLA-A, CCL4, RARRES3, HLA-B, AOAH \nNegative:  CD74, IGHM, IGKC, HLA-DRA, CD79A, CCR7, RPL13, HLA-DRB1, EEF1A1, RPS18 \n       RPS6, RPL10, RPL32, PABPC1, RPL18A, RPS2, LTB, HLA-DQA1, HLA-DQB1, RPL13A \nPC_ 3 \nPositive:  CD74, IGKC, HLA-DRA, IGHM, HLA-DRB1, HLA-DQA1, HLA-DPA1, CD79A, HLA-DPB1, HLA-DQB1 \n       CD83, HERPUD1, MS4A1, ID3, HLA-DMA, IGLC2, GNLY, HSP90AB1, CD79B, GZMB \nNegative:  TRAC, FTL, CCL2, PABPC1, S100A8, TRBC1, CD3D, GIMAP7, RPS18, RPS14 \n       RPL3, RPL13, S100A9, FTH1, RPL34, RPL10, RPS4X, LTB, SARAF, RPL21 \nPC_ 4 \nPositive:  CD74, IGHM, CCL5, GNLY, IGKC, NKG7, HLA-DRA, GZMB, RPL3, CD79A \n       HLA-DPB1, RPL10, RPS2, HLA-DPA1, HLA-DRB1, RPS4X, RPL13, EEF1A1, RPS18, RPS19 \nNegative:  HSPB1, CACYBP, HSPH1, HSP90AB1, HSPA8, SRSF7, SRSF2, UBC, HSPA1A, UBB \n       YPEL5, H3F3B, DNAJB6, GADD45B, HSPE1, EIF1, DDIT4, RSRC2, ZFAND2A, DNAJB1 \nPC_ 5 \nPositive:  VMO1, FCGR3A, MS4A7, TIMP1, TNFSF10, CXCL10, CALHM6, CXCL16, MS4A4A, LST1 \n       JPT1, AIF1, IFITM3, GBP1, SAT1, ATP1B3, GBP5, TNFSF13B, FGL2, PLAC8 \nNegative:  CCL2, FTL, CXCL8, S100A8, S100A9, CCL7, CXCL3, IGKC, IGHM, CTSL \n       CD63, CXCL2, LGALS3, PLA2G7, CSTB, IL1B, CXCL1, SERPINB2, CTSB, GNLY \n\n\nAn object of class Seurat \n31130 features across 29629 samples within 3 assays \nActive assay: RNA (14065 features, 0 variable features)\n 3 layers present: counts, data, scale.data\n 2 other assays present: SCT, integrated\n 2 dimensional reductions calculated: pca, umap"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#umaptsne",
    "href": "lessons/seurat_cheatsheet.html#umaptsne",
    "title": "Seurat Cheatsheet",
    "section": "UMAP/tSNE",
    "text": "UMAP/tSNE\nTo access the coordinates used for UMAP/tSNE plots, we specify the reduction of interest in the Embeddings() function.\n\n# seurat_integrated[['umap']]@cell.embeddings\nEmbeddings(seurat_integrated, reduction=\"umap\") %&gt;% head()\n\n                          UMAP_1     UMAP_2\nctrl_AAACATACAATGCC-1   7.270473  0.9072988\nctrl_AAACATACATTTCC-1  -8.742020  1.5622634\nctrl_AAACATACCAGAAA-1 -10.032904  4.7139827\nctrl_AAACATACCAGCTA-1  -8.363044  5.0377137\nctrl_AAACATACCATGCA-1   6.875784 -4.6442526\nctrl_AAACATACCTCGCT-1  -9.338899  2.2808882"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#dimplot",
    "href": "lessons/seurat_cheatsheet.html#dimplot",
    "title": "Seurat Cheatsheet",
    "section": "DimPlot",
    "text": "DimPlot\nThe DimPlot() function allows us to visualize metadata that is categorical on different reductions (PCA, UMAP).\nBy default DimPlot() will color cells by the Idents() and use UMAP as the default reduction.\n\nDimPlot(seurat_integrated) + ggtitle(\"Seurat clusters\")\n\n\n\n\nWe can specify a different metadata column using the group.by argument\n\nDimPlot(seurat_integrated, group.by = \"sample\")\n\n\n\n\nWe can also use the split.by argument to create multiple plots that only show cells that have the same value for the metadata column specified.\n\nDimPlot(seurat_integrated, split.by = \"sample\", group.by=\"Phase\")"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#featureplot",
    "href": "lessons/seurat_cheatsheet.html#featureplot",
    "title": "Seurat Cheatsheet",
    "section": "FeaturePlot",
    "text": "FeaturePlot\nThe FeaturePlot() function allows us to visualize both metadata and features that are continuous on different reductions (PCA, UMAP).\n\nFeaturePlot(seurat_integrated, features = c(\"FCGR3A\", \"MS4A7\"))\n\n\n\n\nWe can additionally order the values in a way that cells with higher values are shown in front (to avoid other cells drowning out them).\nTo identify cells that show the highest expression of a feature, we can set a min.cutoff based upon quantiles, where cells below the the threshold will show no expression.\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = c(\"FCGR3A\", \"MS4A7\"), \n            order = TRUE,\n            min.cutoff = 'q10')\n\n\n\n\nWe can also add labels onto our UMAP to easily identify which groups of cells we are seeing the expression using the LabelClusters() function. The parameters shown here put a white background behind the text to make it easier to see the labels.\n\nIdents(seurat_integrated) &lt;- \"integrated_snn_res.0.8\"\np &lt;- FeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = \"FCGR3A\", \n            order = TRUE,\n            min.cutoff = 'q10')\nLabelClusters(p, id = \"ident\",  fontface = \"bold\", size = 3, bg.colour = \"white\", bg.r = .2, force = 0)"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#featurescatter",
    "href": "lessons/seurat_cheatsheet.html#featurescatter",
    "title": "Seurat Cheatsheet",
    "section": "FeatureScatter",
    "text": "FeatureScatter\nFeatureScatter() creates a scatterplot of expression values for two features with each cell being colored by the ident. Bear in mind that you can also specify a continuous metadata column and not just 2 genes/features.\n\nIdents(seurat_integrated) &lt;- \"integrated_snn_res.0.8\"\nFeatureScatter(seurat_integrated, feature1 = \"MT-ND5\", feature2 = \"mitoRatio\") + \n  ggtitle(\"MitoRatio vs MT-ND5 expression\")"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#cellscatter",
    "href": "lessons/seurat_cheatsheet.html#cellscatter",
    "title": "Seurat Cheatsheet",
    "section": "CellScatter",
    "text": "CellScatter\nTo visualize the differences between two specific cells, you can use the CellScatter() function to get a scatterplot of values for each feature in both cells.\n\ncell1 &lt;- Cells(seurat_integrated)[1] \ncell2 &lt;- Cells(seurat_integrated)[2]\n\n# Here we can see the metadata for the first two cells in the dataset\n# We are comparing \"Activated T cell\" vs \"CD14+ monocytes\" (so they should be very different)\nseurat_integrated@meta.data %&gt;% subset(cells %in% c(cell1, cell2)) %&gt;% select(sample, celltype)\n\n                      sample          celltype\nctrl_AAACATACAATGCC-1   ctrl Activated T cells\nctrl_AAACATACATTTCC-1   ctrl   CD14+ monocytes\n\n\n\nCellScatter(seurat_integrated, cell1=cell1, cell2=cell2)"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#vlnplot",
    "href": "lessons/seurat_cheatsheet.html#vlnplot",
    "title": "Seurat Cheatsheet",
    "section": "VlnPlot",
    "text": "VlnPlot\nWe can create a violin plot to compare the distribution of gene expression across different populations using the VlnPlot() function.\nThis is a very customizable function, with many parameters to customize the look of the plots.\n\nVlnPlot(seurat_integrated, c(\"CD14\", \"CD79A\"))\n\n\n\n\nIn this example, we are grouping expression by sample and showing 2 plots per column. We are also removing the points (cells) by setting their size to 0.\n\nVlnPlot(seurat_integrated, c(\"IFIT1\", \"CD53\", \"CD52\", \"CXCL8\"), \n        group.by=\"sample\", ncol=2, pt.size=0)"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#ridgeplot",
    "href": "lessons/seurat_cheatsheet.html#ridgeplot",
    "title": "Seurat Cheatsheet",
    "section": "RidgePlot",
    "text": "RidgePlot\nRidge plots are most commonly used with CITE-seq or hashtagged dataset as they provide an easy way to identify cells that express a protein/antibody.\nFor our scRNA dataset, when we call RidgePlot(), on the y-axis we see the unique identities assigned for each cell. The x-axis shows us the expression level for whichever feature we chose. This is a great visualization to use when justifying annotation decisions.\n\nRidgePlot(seurat_integrated, \"CD3D\", assay=\"RNA\") + NoLegend()"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#dimheatmap",
    "href": "lessons/seurat_cheatsheet.html#dimheatmap",
    "title": "Seurat Cheatsheet",
    "section": "DimHeatmap",
    "text": "DimHeatmap\nTo see the effect of genes on the principal component, we can see the top and bottom features in PC1 using the DimHeatmap() function.\n\nDimHeatmap(seurat_integrated, nfeatures = 10)"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#doheatmap",
    "href": "lessons/seurat_cheatsheet.html#doheatmap",
    "title": "Seurat Cheatsheet",
    "section": "DoHeatmap",
    "text": "DoHeatmap\nTo plot the expression values for genes across all cells (grouped by their identity), you can call Seurat’s DoHeatmap() function to identify which populations certain genes are lowly or hihgly expressed.\n\nIdents(seurat_integrated) &lt;- \"integrated_snn_res.0.8\"\nDoHeatmap(seurat_integrated, features=c(\"CD14\", \"FCGR3A\", \"FCER1A\", \n                                        \"IL3RA\", \"CD79A\", \"CD3D\"))"
  },
  {
    "objectID": "lessons/seurat_cheatsheet.html#dotplot",
    "href": "lessons/seurat_cheatsheet.html#dotplot",
    "title": "Seurat Cheatsheet",
    "section": "DotPlot",
    "text": "DotPlot\nSeurat also has a built in visualization tool which allows us to view the average expression of genes groups clusters called DotPlot(). The size of the circle represents the number of cells that express the gene within a group and the hue reprents the average expression of the feature.\nIf you supply a named list with labels annotating genes, those labels will appear at the top of the plot for easier visualization.\n\n# List of known celltype markers\nmarkers &lt;- list()\nmarkers[[\"CD14+ monocytes\"]] &lt;- c(\"CD14\", \"LYZ\")\nmarkers[[\"FCGR3A+ monocyte\"]] &lt;- c(\"FCGR3A\", \"MS4A7\")\nmarkers[[\"Macrophages\"]] &lt;- c(\"MARCO\", \"ITGAM\", \"ADGRE1\")\nmarkers[[\"Conventional dendritic\"]] &lt;- c(\"FCER1A\", \"CST3\")\nmarkers[[\"Plasmacytoid dendritic\"]] &lt;- c(\"IL3RA\", \"GZMB\", \"SERPINF1\", \"ITM2C\")\n\n# Create dotplot based on RNA expression\nDotPlot(seurat_integrated, markers, assay=\"RNA\", group.by = \"integrated_snn_res.0.8\")"
  },
  {
    "objectID": "lessons/06a_integration_cca_theory.html",
    "href": "lessons/06a_integration_cca_theory.html",
    "title": "Integration",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/06a_integration_cca_theory.html#learning-objectives",
    "href": "lessons/06a_integration_cca_theory.html#learning-objectives",
    "title": "Integration",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nUnderstand the theory of integration with CCA"
  },
  {
    "objectID": "lessons/06a_integration_cca_theory.html#to-integrate-or-not-to-integrate",
    "href": "lessons/06a_integration_cca_theory.html#to-integrate-or-not-to-integrate",
    "title": "Integration",
    "section": "To integrate or not to integrate?",
    "text": "To integrate or not to integrate?\nGenerally, we always look at our clustering without integration before deciding whether we need to perform any alignment. It can be helpful to first run through clustering with samples from different sample classes together to see whether there are condition-specific clusters for cell types present in both conditions. Oftentimes, when clustering cells from multiple conditions there are condition-specific clusters and integration can help ensure the same cell types cluster together.\nDo not just always perform integration because you think there might be differences - explore the data. If we had performed the normalization on both conditions together in a Seurat object and visualized the similarity between cells, we would have seen in our dataset there is condition-specific clustering:\n\n\n\n\n\nHow do we create this UMAP?\n\nThe UMAP above can be generated by using the seurat_phase object from the previous lesson. For this object we have already run PCA, so the next steps would be to RunUMAP() and then plot, as shown in the code below.\n\n# Run UMAP\nseurat_phase &lt;- RunUMAP(seurat_phase,\n                        dims = 1:40,reduction = \"pca\")\n# Plot UMAP\nDimPlot(seurat_phase)   \n\n\nCondition-specific clustering of the cells indicates that we need to integrate the cells across conditions to ensure that cells of the same cell type cluster together. If cells cluster by sample, condition, batch, dataset, modality, performing integration can help align cells across the groups to greatly improve the clustering and the downstream analyses.\nWhy is it important that cells of the same cell type cluster together?\nWe want to identify cell types which are present in all samples/conditions/modalities within our dataset, and therefore would like to observe a representation of cells from both samples/conditions/modalities in every cluster. This will enable more interpretable results downstream (i.e. DE analysis, ligand-receptor analysis, differential abundance analysis…).\nIn this lesson, we will cover the integration of our samples across conditions, which is adapted from the Seurat Guided Integration Tutorial.\n\n\n\n\n\n\nNote\n\n\n\nSeurat has a vignette for how to run through the workflow from normalization to clustering without integration. Other steps in the workflow remain fairly similar, but the samples would not necessarily be split in the beginning and integration would not be performed._"
  },
  {
    "objectID": "lessons/06a_integration_cca_theory.html#example-scenarios-for-integration",
    "href": "lessons/06a_integration_cca_theory.html#example-scenarios-for-integration",
    "title": "Integration",
    "section": "Example scenarios for integration",
    "text": "Example scenarios for integration\n\nDifferent conditions (e.g. control and stimulated) \nDifferent datasets (e.g. scRNA-seq from datasets generated using different library preparation methods on the same samples) \nDifferent modalities (e.g. scRNA-seq and scATAC-seq) \nDifferent batches (e.g. when experimental conditions make batch processing of samples necessary)"
  },
  {
    "objectID": "lessons/06a_integration_cca_theory.html#integration-using-cca",
    "href": "lessons/06a_integration_cca_theory.html#integration-using-cca",
    "title": "Integration",
    "section": "Integration using CCA",
    "text": "Integration using CCA\nIntegration is a powerful method that uses shared highly variable genes from each group to identify shared subpopulations across conditions or datasets [Stuart and Bulter et al. (2018)]. The goal of integration is to ensure that the cell types of one condition/dataset align with the same celltypes of the other conditions/datasets (e.g. control macrophages align with stimulated macrophages).\nThe integration method that is available in the Seurat package utilizes the canonical correlation analysis (CCA); a method that expects “correspondences” or shared biological states among at least a subset of single cells across the groups. The result of this integration approach is a corrected data matrix for all datasets, enabling them to be analyzed jointly in a single workflow. To transfer information from a reference to query dataset, Seurat does not modify the underlying expression data, but instead projects continuous data across experiments.\nThe steps in the Seurat integration workflow are outlined in the figure below:\n\n\n\nImage credit: Stuart T and Butler A, et al. Comprehensive integration of single cell data, bioRxiv 2018 (https://doi.org/10.1101/460147)\n1. Identify shared variable genes:\nIntegration aims to take the matrix for each dataset (Ctrl and Stim) and identify correlated structures across them and align them in a common space. The shared highly variable genes from each dataset are used to form the intersection set, because they are the most likely to represent those genes distinguishing the different cell types present.\nEach dataset can have a different number of cells, but must have the same number of genes.\n2. Perform canonical correlation analysis (CCA):\nNext, Seurat will jointly reduce the dimensionality of both datasets using diagonalized canonical correlation analysis (CCA) which is a form of PCA. Similar to principal components in PCA, the CCA will result in canonical correlation vectors. An L2-normalization is applied to the canonical correlation vectors, to use as input for the next step (identifying MNNs).\n3. Find mutual nearest neighbors (MNNs) or anchors:\nIn this new shared low-dimensional space, Seurat will identify anchors or mutual nearest neighbors (MNNs) across datasets. These MNNs are pairs of cells that can be thought of as ‘best buddies’.\nFor each cell in one condition: - The cell’s closest neighbor in the other condition is identified based on gene expression values - its ‘best buddy’. - The reciprocal analysis is performed, and if the two cells are ‘best buddies’ in both directions, then those cells will be marked as anchors to ‘anchor’ the two datasets together.\n4. Filter anchors to remove incorrect anchors:\nAssess the similarity between anchor pairs by the overlap in their local neighborhoods (incorrect anchors will have low scores) - do the adjacent cells have ‘best buddies’ that are adjacent to each other? If not, these are removed the anchor list.\n5. Integrate the conditions/datasets:\nUsing the anchors and corresponding scores the cell expression values are transformed, allowing for the integration of the conditions/datasets (different samples, conditions, datasets, modalities). For each cell in the dataset we now have an integrated value, but only for the variable features used for this analysis.\n\n\n\n\n\n\nNote\n\n\n\nTransformation of each cell uses a weighted average of the two cells of each anchor across anchors of the datasets. Weights determined by cell similarity score (distance between cell and k nearest anchors) and anchor scores, so cells in the same neighborhood should have similar correction values.\n\n\nIf cell types are present in one dataset, but not the other, then the cells will still appear as a separate sample-specific cluster.\n\n\n\n\n\n\nNote\n\n\n\nIf there are a substantial number of cells that do not have a match between groups or there are a large number of cells to integrate, an alternative approach recommended by the Seurat vignette is reciprocal PCA (RPCA)."
  },
  {
    "objectID": "lessons/06_SC_SCT_normalization.html",
    "href": "lessons/06_SC_SCT_normalization.html",
    "title": "Normalization, identification of most variable genes",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/06_SC_SCT_normalization.html#learning-objectives",
    "href": "lessons/06_SC_SCT_normalization.html#learning-objectives",
    "title": "Normalization, identification of most variable genes",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nDiscuss why normalizing counts is necessary for accurate comparison between cells\nDescribe different normalization approaches\nEvaluate the effects from any unwanted sources of variation and correct for them"
  },
  {
    "objectID": "lessons/06_SC_SCT_normalization.html#normalization",
    "href": "lessons/06_SC_SCT_normalization.html#normalization",
    "title": "Normalization, identification of most variable genes",
    "section": "Normalization",
    "text": "Normalization\nAn essential first step in the majority of mRNA expression analyses is normalization, whereby systematic variations are adjusted for to make expression counts comparable across genes and/or samples. The counts of mapped reads for each gene is proportional to the expression of RNA (“interesting”) in addition to many other factors (“uninteresting”). Normalization is the process of adjusting raw count values to account for the “uninteresting” factors.\nThe main factors often considered during normalization are:\n\nSequencing depth: Accounting for sequencing depth is necessary for comparison of gene expression between cells. In the example below, each gene appears to have doubled in expression in cell 2, however this is a consequence of cell 2 having twice the sequencing depth.\n\n\n\n\nEach cell in scRNA-seq will have a differing number of reads associated with it. So to accurately compare expression between cells, it is necessary to normalize for sequencing depth.\n\nGene length: Accounting for gene length is necessary for comparing expression between different genes within the same cell. The number of reads mapped to a longer gene can appear to have equal count/expression as a shorter gene that is more highly expressed.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf using a 3’ or 5’ droplet-based method, the length of the gene will not affect the analysis because only the 5’ or 3’ end of the transcript is sequenced.* However, if using full-length sequencing, the transcript length should be accounted for.\n\n\n\nMethods for scRNA-seq normalization\nVarious methods have been developed specifically for scRNA-seq normalization. Some simpler methods resemble what we have seen with bulk RNA-seq; the application of global scale factors adjusting for a count-depth relationship that is assumed common across all genes. However, if those assumptions are not true then this basic normalization can lead to over-correction for lowly and moderately expressed genes and, in some cases, under-normalization of highly expressed genes (Bacher R et al, 2017). More complex methods will apply correction on a per-gene basis. In this lesson we will explore both approaches.\nRegardless of which method is used for normalization, it can be helpful to think of it as a two-step process (even though it is often described as a single step in most papers). The first is a scaling step and the second is a transformation.\n1. Scaling\nThe first step in normalization is to multiply each UMI count by a cell specific factor to get all cells to have the same UMI counts. Why would we want to do this? Different cells have different amounts of mRNA; this could be due to differences between cell types or variation within the same cell type depending on how well the chemistry worked in one drop versus another. In either case, we are not interested in comparing these absolute counts between cells. Instead we are interested in comparing concentrations, and scaling helps achieve this.\n2. Transformation\nThe next step is a transformation, and it is at this step where we can distinguish the simpler versus complex methods as mentioned above.\nSimple transformations are those which apply the same function to each individual measurement. Common examples include a log transform (which is applied in the original Seurat workflow), or a square root transform (less commonly used)."
  },
  {
    "objectID": "lessons/06_SC_SCT_normalization.html#explore-sources-of-unwanted-variation",
    "href": "lessons/06_SC_SCT_normalization.html#explore-sources-of-unwanted-variation",
    "title": "Normalization, identification of most variable genes",
    "section": "Explore sources of unwanted variation",
    "text": "Explore sources of unwanted variation\nThe most common biological data correction (or source of “uninteresting” variation) in single cell RNA-seq is the effects of the cell cycle on the transcriptome. We need to explore the data and see if we observe any effects in our data.\n\nSet-up\nLet’s start by creating a new script for the normalization and integration steps. Create a new script (File -&gt; New File -&gt; R script), and save it as SCT_integration_analysis.R.\nFor the remainder of the workflow we will be mainly using functions available in the Seurat package. Therefore, we need to load the Seurat library in addition to the tidyverse library and a few others listed below.\n\n# Single-cell RNA-seq - normalization\n\n# Load libraries\nlibrary(Seurat)\nlibrary(tidyverse)\nlibrary(RCurl)\nlibrary(cowplot)\n\nBefore we make any comparisons across cells, we will apply a simple normalization. This is solely for the purpose of exploring the sources of variation in our data.\nThe input for this analysis is a seurat object. We will use the one that we created in the QC lesson called filtered_seurat.\n\n# Normalize the counts\nseurat_phase &lt;- NormalizeData(filtered_seurat)\n\nNext, we take this normalized data and check to see if data correction methods are necessary.\n\n\nEvaluating effects of cell cycle\nTo assign each cell a score based on its expression of G2/M and S phase markers, we can use the Seuart function CellCycleScoring(). This function calculates cell cycle phase scores based on canonical markers that required as input.\nWe have provided a list of human cell cycle markers for you in the data folder as an Rdata file called cycle.rda. However, if you are not working with human data we have additional materials detailing how to acquire cell cycle markers for other organisms of interest.\n\n# Load cell cycle markers\nload(\"../data/cycle.rda\")\n\n# Score cells for cell cycle\nseurat_phase &lt;- CellCycleScoring(seurat_phase, \n                                 g2m.features = g2m_genes, \n                                 s.features = s_genes)\n\n# View cell cycle scores and phases assigned to cells\nhead(seurat_phase@meta.data)                                \n\n                      orig.ident nCount_RNA nFeature_RNA seq_folder nUMI nGene\nctrl_AAACATACAATGCC-1       ctrl       2344          874       ctrl 2344   874\nctrl_AAACATACATTTCC-1       ctrl       3124          895       ctrl 3125   896\nctrl_AAACATACCAGAAA-1       ctrl       2578          725       ctrl 2578   725\nctrl_AAACATACCAGCTA-1       ctrl       3260          978       ctrl 3261   979\nctrl_AAACATACCATGCA-1       ctrl        746          362       ctrl  746   362\nctrl_AAACATACCTCGCT-1       ctrl       3518          865       ctrl 3519   866\n                      log10GenesPerUMI  mitoRatio                 cells sample\nctrl_AAACATACAATGCC-1        0.8728630 0.01962457 ctrl_AAACATACAATGCC-1   ctrl\nctrl_AAACATACATTTCC-1        0.8447596 0.01792000 ctrl_AAACATACATTTCC-1   ctrl\nctrl_AAACATACCAGAAA-1        0.8384933 0.01551590 ctrl_AAACATACCAGAAA-1   ctrl\nctrl_AAACATACCAGCTA-1        0.8512622 0.01379945 ctrl_AAACATACCAGCTA-1   ctrl\nctrl_AAACATACCATGCA-1        0.8906861 0.02144772 ctrl_AAACATACCATGCA-1   ctrl\nctrl_AAACATACCTCGCT-1        0.8283053 0.01392441 ctrl_AAACATACCTCGCT-1   ctrl\n                          S.Score   G2M.Score Phase\nctrl_AAACATACAATGCC-1  0.04330502  0.05422631   G2M\nctrl_AAACATACATTTCC-1  0.02661900  0.05159679   G2M\nctrl_AAACATACCAGAAA-1 -0.04670650 -0.04841661    G1\nctrl_AAACATACCAGCTA-1 -0.05832833  0.05045960   G2M\nctrl_AAACATACCATGCA-1  0.03929605 -0.02995512     S\nctrl_AAACATACCTCGCT-1  0.03201279  0.01685778     S\n\n\nAfter scoring the cells for cell cycle, we would like to determine whether cell cycle is a major source of variation in our dataset using PCA.\n\n\nPCA\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for “dimensionality reduction”.\n\n\n\n\n\n\nNote\n\n\n\nFor a more detailed explanation on PCA, please look over this lesson (adapted from StatQuests/Josh Starmer’s YouTube video). We also strongly encourage you to explore the video StatQuest’s video for a more thorough understanding.\n\n\nLet’s say you are working with a single-cell RNA-seq dataset with 12,000 cells and you have quantified the expression of 20,000 genes. The schematic below demonstrates how you would go from a cell x gene matrix to principal component (PC) scores for each inividual cell.\n\n\n\nAfter the PC scores have been calculated, you are looking at a matrix of 12,000 x 12,000 that represents the information about relative gene expression in all the cells. You can select the PC1 and PC2 columns and plot that in a 2D way.\n\n\n\nYou can also use the PC scores from the first 40 PCs for downstream analysis like clustering, marker identification etc., since these represent the majority of the variation in the data. We will be talking a lot more about this later in this workshop.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor datasets with a larger number of cells, only the PC1 and PC2 scores for each cell are usually plotted, or used for visualization. Since these PCs explain the most variation in the dataset, the expectation is that the cells that are more similar to each other will cluster together with PC1 and PC2.\n\n\n\n\nUsing PCA to evaluate the effects of cell cycle\nTo perform PCA, we need to first choose the most variable features, then scale the data. Since highly expressed genes exhibit the highest amount of variation and we don’t want our ‘highly variable genes’ only to reflect high expression, we need to scale the data to scale variation with expression level. The Seurat ScaleData() function will scale the data by:\n\nAdjusting the expression of each gene to give a mean expression across cells to be 0\nScaling expression of each gene to give a variance across cells to be 1\n\n\n# Identify the most variable genes\nseurat_phase &lt;- FindVariableFeatures(seurat_phase, \n                     selection.method = \"vst\",\n                     nfeatures = 2000, \n                     verbose = FALSE)\n             \n# Scale the counts\nseurat_phase &lt;- ScaleData(seurat_phase)\n\n\n\n\n\n\n\nNote\n\n\n\nFor the selection.method and nfeatures arguments the values specified are the default settings. Therefore, you do not necessarily need to include these in your code. We have included it here for transparency and inform you what you are using._\n\n\nHighly variable gene selection is extremely important since many downstream steps are computed only on these genes. Seurat allows us to access the ranked highly variable genes with the VariableFeatures() function. We can additionally visualize the dispersion of all genes using Seurat’s VariableFeaturePlot(), which shows a gene’s average expression across all cells on the x-axis and variance on the y-axis. Ideally we want to use genes that have high variance since this can indicate a change in expression depending on populations of cells. Adding labels using the LabelPoints() helps us understand which genes will be driving shape of our data.\n\n# Identify the 15 most highly variable genes\nranked_variable_genes &lt;- VariableFeatures(seurat_phase)\ntop_genes &lt;- ranked_variable_genes[1:15]\n\n# Plot the average expression and variance of these genes\n# With labels to indicate which genes are in the top 15\np &lt;- VariableFeaturePlot(seurat_phase)\nLabelPoints(plot = p, points = top_genes, repel = TRUE)\n\n\n\n\nNow, we can perform the PCA analysis and plot the first two principal components against each other. We also split the figure by cell cycle phase, to evaluate similarities and/or differences. We do not see large differences due to cell cycle phase. Based on this plot, we would not regress out the variation due to cell cycle.\n\n# Perform PCA\nseurat_phase &lt;- RunPCA(seurat_phase)\n\n# Plot the PCA colored by cell cycle phase\nDimPlot(seurat_phase,\n        reduction = \"pca\",\n        group.by= \"Phase\",\n        split.by = \"Phase\")\n\n\n\n\n\n\nWhen should cell cycle phase be regressed out?\n\nBelow are two PCA plots taken from the Seurat vignette dealing with Cell-Cycle Scoring and Regression.\n\n\nThis first plot is similar to what we plotted above, it is a PCA prior to regression to evaluate if the cell cycle is playing a big role in driving PC1 and PC2. Clearly, the cells are separating by cell type in this case, so the vignette suggests regressing out these effects.\n\n\n\n\n\n\n\nThis second PCA plot is post-regression, and displays how effective the regression was in removing the effect we observed.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExercise: Evaluating effects of mitochondrial expression\n\n\n\nMitochondrial expression is another factor which can greatly influence clustering. Oftentimes, it is useful to regress out variation due to mitochondrial expression. However, if the differences in mitochondrial gene expression represent a biological phenomenon that may help to distinguish cell clusters, then we advise not regressing this out. In this exercise, we can perform a quick check similar to looking at cell cycle and decide whether or not we want to regress it out.\n\nFirst, turn the mitochondrial ratio variable into a new categorical variable based on quartiles (using the code below):\n\n\n# Check quartile values\nsummary(seurat_phase@meta.data$mitoRatio)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.01438 0.01993 0.02139 0.02669 0.14464 \n\n# Turn mitoRatio into categorical factor vector based on quartile values\nseurat_phase@meta.data$mitoFr &lt;- cut(seurat_phase@meta.data$mitoRatio, \n                   breaks=c(-Inf, 0.0144, 0.0199, 0.0267, Inf), \n                   labels=c(\"Low\",\"Medium\",\"Medium high\", \"High\"))\n\n\nNext, plot the PCA similar to how we did with cell cycle regression. Hint: use the new mitoFrvariable to split cells and color them accordingly.\nEvaluate the PCA plot generated in #2.\n\nDetermine whether or not you observe an effect.\nDescribe what you see.\nWould you regress out mitochondrial fraction as a source of unwanted variation?"
  },
  {
    "objectID": "lessons/06_SC_SCT_normalization.html#normalization-and-regressing-out-sources-of-unwanted-variation-using-sctransform",
    "href": "lessons/06_SC_SCT_normalization.html#normalization-and-regressing-out-sources-of-unwanted-variation-using-sctransform",
    "title": "Normalization, identification of most variable genes",
    "section": "Normalization and regressing out sources of unwanted variation using SCTransform",
    "text": "Normalization and regressing out sources of unwanted variation using SCTransform\nIn the Hafemeister and Satija, 2019 paper the authors explored the issues with simple transformations. Specifically they evaluated the standard log normalization approach and found that genes with different abundances are affected differently and that effective normalization (using the log transform) is only observed with low/medium abundance genes (Figure 1D, below). Additionally, substantial imbalances in variance were observed with the log-normalized data (Figure 1E, below). In particular, cells with low total UMI counts exhibited disproportionately higher variance for high-abundance genes, dampening the variance contribution from other gene abundances. \n\n\n\nImage credit: Hafemeister C and Satija R. Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression, Genom Biology 2019 (https://doi.org/10.1101/576827)\nThe conclusion is, we cannot treat all genes the same.\nThe proposed solution was the use of Pearson residuals for transformation, as implemented in Seurat’s SCTransform function. With this approach: * Measurements are multiplied by a gene-specific weight * Each gene is weighted based on how much evidence there is that it is non-uniformly expressed across cells * More evidence == more of a weight; Genes that are expressed in only a small fraction of cells will be favored (useful for finding rare cell populations) * Not just a consideration of the expression level is, but also the distribution of expression\n\n\n\n\n\n\nWhy don’t we just run SCTransform to normalize?\n\n\n\nWhile the functions NormalizeData, VariableFeatures and ScaleData can be replaced by the function SCTransform, the latter uses a more sophisticated way to perform the normalization and scaling. We suggest using log normalization because it is good to observe the data and any trends using a simple transformation, as methods like SCT can alter the data in a way that is not as intuitive to interpret.\n\n\nNow that we have established which effects are observed in our data, we can use the SCTransform method to regress out these effects. The SCTransform method was proposed as a better alternative to the log transform normalization method that we used for exploring sources of unwanted variation. The method not only normalizes data, but it also performs a variance stabilization and allows for additional covariates to be regressed out.\nAs described earlier, all genes cannot be treated the same. As such, the SCTransform method constructs a generalized linear model (GLM) for each gene with UMI counts as the response and sequencing depth as the explanatory variable. Information is pooled across genes with similar abundances, to regularize parameter estimates and obtain residuals which represent effectively normalized data values which are no longer correlated with sequencing depth.\n\n\n\nImage credit: Hafemeister C and Satija R. Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression, Genom Biology 2019 (https://doi.org/10.1101/576827)\n\n\n\n\n\n\nNote\n\n\n\nSince the UMI counts are part of the GLM, the effects are automatically regressed out. The user can include any additional covariates (vars.to.regress) that may have an effect on expression and will be included in the model.\n\n\nTo run the SCTransform we have the code below as an example. Do not run this code, as we prefer to run this for each sample separately in the next section below.\n\n## DO NOT RUN CODE ##\n\n# SCTranform\nseurat_phase &lt;- SCTransform(seurat_phase, vars.to.regress = c(\"mitoRatio\"))"
  },
  {
    "objectID": "lessons/06_SC_SCT_normalization.html#iterating-over-samples-in-a-dataset",
    "href": "lessons/06_SC_SCT_normalization.html#iterating-over-samples-in-a-dataset",
    "title": "Normalization, identification of most variable genes",
    "section": "Iterating over samples in a dataset",
    "text": "Iterating over samples in a dataset\nSince we have two samples in our dataset (from two conditions), we want to keep them as separate objects and transform them as that is what is required for integration. We will first split the cells in seurat_phase object into “Control” and “Stimulated”:\n\n# Split seurat object by condition to perform cell cycle scoring and SCT on all samples\nsplit_seurat &lt;- SplitObject(seurat_phase, split.by = \"sample\")\nsplit_seurat\n\n$ctrl\nAn object of class Seurat \n14065 features across 14847 samples within 1 assay \nActive assay: RNA (14065 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 dimensional reduction calculated: pca\n\n$stim\nAn object of class Seurat \n14065 features across 14782 samples within 1 assay \nActive assay: RNA (14065 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n 1 dimensional reduction calculated: pca\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf you only wanted to integrate on a subset of your samples (e.g. all Ctrl replicates only), you could select which ones you wanted from the split_seurat object as shown below and move forward with those.\n\nctrl_reps &lt;- split_seurat[c(\"ctrl_1\", \"ctrl_2\")]\n\n\n\nNow we will use a ‘for loop’ to run the SCTransform() on each sample, and regress out mitochondrial expression by specifying in the vars.to.regress argument of the SCTransform() function.\nBefore we run this for loop, we know that the output can generate large R objects/variables in terms of memory. If we have a large dataset, then we might need to adjust the limit for allowable object sizes within R (Default is 500  1024 ^ 2 = 500 Mb*) using the following code:\n\noptions(future.globals.maxSize = 4000 * 1024^2)\n\nNow, we run the following loop to perform the sctransform on all samples. This may take some time (~10 minutes):\n\nfor (i in 1:length(split_seurat)) {\n    split_seurat[[i]] &lt;- SCTransform(split_seurat[[i]], \n                                     vars.to.regress = c(\"mitoRatio\"),\n                                     vst.flavor = \"v2\")\n    }\n\nPlease note that in the for loop above, we specify that vst.flavor = \"v2\" to use the updated version of SCT. “v2” was introduced in early 2022, and is now commonly used. This update improves: * Speed and memory consumption * The stability of parameter estimates * Variable feature identification in subsequent steps\nFor more information, please see the Seurat vignette’s section on SCTransform, v2 regularization.\n\n\n\n\n\n\nNote\n\n\n\nBy default, after normalizing, adjusting the variance, and regressing out uninteresting sources of variation, SCTransform will rank the genes by residual variance and output the 3000 most variant genes. If the dataset has larger cell numbers, then it may be beneficial to adjust this parameter higher using the variable.features.n argument._\n\n\nNote, the last line of output specifies “Set default assay to SCT”. This specifies that moving forward we would like to use the data after SCT was implemented. We can view the different assays that we have stored in our seurat object.\n\n# Check which assays are stored in objects\nsplit_seurat$ctrl@assays\n\n$RNA\nAssay (v5) data with 14065 features for 14847 cells\nTop 10 variable features:\n HBB, HBA2, CCL4L2, HBA1, IGKC, CCL7, PPBP, CCL4, CCL3, CCL8 \nLayers:\n counts, data, scale.data \n\n$SCT\nSCTAssay data with 13799 features for 14847 cells, and 1 SCTModel(s) \nTop 10 variable features:\n FTL, CCL2, IGKC, GNLY, IGLC2, CCL3, TIMP1, IGHM, CCL4, PPBP \n\n\nNow we can see that in addition to the raw RNA counts, we now have a SCT component in our assays slot. The most variable features will be the only genes stored inside the SCT assay. As we move through the scRNA-seq analysis, we will choose the most appropriate assay to use for the different steps in the analysis.\n\n\n\n\n\n\n\nExercises\n\n\n\n\nAre the same assays available for the “stim” samples within the split_seurat object? What is the code you used to check that?\nAny observations for the genes or features listed under “First 10 features:” and the “Top 10 variable features:” for “ctrl” versus “stim”?\n\n\n\n\n\nSave the object!\nBefore finishing up, let’s save this object to the data/ folder. It can take a while to get back to this stage especially when working with large datasets, it is best practice to save the object as an easily loadable file locally.\n\n# Save the split seurat object\nsaveRDS(split_seurat, \"../data/split_seurat.rds\")\n\n\n\n\n\n\n\nNote\n\n\n\nTo load the .rds file back into your environment you would use the llowing code:\n\n# Load the split seurat object into the environment\nsplit_seurat &lt;- readRDS(\"../data/split_seurat.rds\")"
  },
  {
    "objectID": "lessons/sc_exercises_qc_analysis.html",
    "href": "lessons/sc_exercises_qc_analysis.html",
    "title": "Answer key - Quality Control Analysis",
    "section": "",
    "text": "1. Extract the new metadata from the filtered Seurat object using the code provided below:\n\n# Save filtered subset to new metadata\nmetadata_clean &lt;- filtered_seurat@meta.data\n\n2. Perform all of the same QC plots using the filtered data.\n\nCell counts\nAfter filtering, we should not have more cells than we sequenced. Generally we aim to have about the number we sequenced or a bit less.\n\n## Cell counts\nmetadata_clean %&gt;% \n    ggplot(aes(x=sample, fill=sample)) + \n    geom_bar() +\n    theme_classic() +\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1)) +\n    theme(plot.title = element_text(hjust=0.5, face=\"bold\")) +\n    ggtitle(\"NCells\")\n\n\n\n\n\n\nUMI counts\nThe filtering using a threshold of 500 has removed the cells with low numbers of UMIs from the analysis.\n\n# UMI counts\nmetadata_clean %&gt;% \n    ggplot(aes(color=sample, x=nUMI, fill= sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    ylab(\"log10 cell density\") +\n    geom_vline(xintercept = 500)\n\n\n\n\n\n\nGenes detected\n\n# Genes detected\nmetadata_clean %&gt;% \n    ggplot(aes(color=sample, x=nGene, fill= sample)) + \n    geom_density(alpha = 0.2) + \n    theme_classic() +\n    scale_x_log10() + \n    geom_vline(xintercept = 250)\n\n\n\n\n\n\nUMIs vs genes\n\n# UMIs vs genes\nmetadata_clean %&gt;% \n  ggplot(aes(x=nUMI, y=nGene, color=mitoRatio)) + \n  geom_point() + \n  scale_colour_gradient(low = \"gray90\", high = \"black\") +\n  stat_smooth(method=lm) +\n  scale_x_log10() + \n  scale_y_log10() + \n  theme_classic() +\n  geom_vline(xintercept = 500) +\n  geom_hline(yintercept = 250) +\n  facet_wrap(~sample)\n\n\n\n\n\n\nMitochondrial counts ratio\n\n# Mitochondrial counts ratio\nmetadata_clean %&gt;% \n    ggplot(aes(color=sample, x=mitoRatio, fill=sample)) + \n    geom_density(alpha = 0.2) + \n    scale_x_log10() + \n    theme_classic() +\n    geom_vline(xintercept = 0.2)\n\n\n\n\n\n\nNovelty\n\n# Novelty\nmetadata_clean %&gt;%\n    ggplot(aes(x=log10GenesPerUMI, color = sample, fill=sample)) +\n    geom_density(alpha = 0.2) +\n    theme_classic() +\n    geom_vline(xintercept = 0.8)\n\n\n\n\n3. Report the number of cells left for each sample, and comment on whether the number of cells removed is high or low. Can you give reasons why this number is still not ~12K (which is how many cells were loaded for the experiment)?\nThere are just under 15K cells left for both the control and stim cells. The number of cells removed is reasonably low.\nWhile it would be ideal to have 12K cells, we do not expect that due to the lower capture efficiency (i.e. the number of actual cells encapsulated within droplets containing barcodes) of these technologies. If we still see higher than expected numbers of cells after filtering, this means we could afford to filter more stringently (but we don’t necessarily have to).\n4. After filtering for nGene per cell, you should still observe a small shoulder to the right of the main peak. What might this shoulder represent?\nThis peak could represent a biologically distinct population of cells. It could be a set a of cells that share some properties and as a consequence exhibit more diversity in its transcriptome (with the larger number of genes detected).\n5. When plotting the nGene against nUMI do you observe any data points in the bottom right quadrant of the plot? What can you say about these cells that have been removed?\nThe cells that were removed were those with high nUMI but low numbers of genes detected. These cells had many captured transcripts but represent only a small number of genes. These low complexity cells could represent a specific cell type (i.e. red blood cells which lack a typical transcriptome), or could be due to some other strange artifact or contamination."
  },
  {
    "objectID": "lessons/05_theory_of_PCA.html",
    "href": "lessons/05_theory_of_PCA.html",
    "title": "Theory of PCA",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/05_theory_of_PCA.html#learning-objectives",
    "href": "lessons/05_theory_of_PCA.html#learning-objectives",
    "title": "Theory of PCA",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExplain how similarity between cells/samples can be evaluated by the Principal Components Analysis (PCA)"
  },
  {
    "objectID": "lessons/05_theory_of_PCA.html#principal-component-analysis-pca",
    "href": "lessons/05_theory_of_PCA.html#principal-component-analysis-pca",
    "title": "Theory of PCA",
    "section": "Principal Component Analysis (PCA)",
    "text": "Principal Component Analysis (PCA)\nPrincipal Component Analysis (PCA) is a technique used to emphasize variation as well as similarity, and to bring out strong patterns in a dataset; it is one of the methods used for “dimensionality reduction”. We will briefly go over PCA in this lesson (adapted from StatQuests/Josh Starmer’s YouTube video), but we strongly encourage you to explore the video StatQuest’s video for a more thorough explanation/understanding.\n\nBasic explanation with a simple example\nLet’s say you had quantified the expression of four genes in two samples (or cells), you could plot the expression values of those genes with one sample represented on the x-axis and the other sample on the y-axis as shown below:\n\n\n\nYou could draw a line through the data in the direction representing the most variation, which is on the diagonal in this example. The maximum variation in the dataset is between the genes that make up the two endpoints of this line.\nWe also see the genes vary somewhat above and below the line. We could draw another line through the data representing the second most amount of variation in the data, since this plot is in 2D (2 axes).\n\n\n\nThe genes near the ends of each line would be those with the highest variation; these genes have the greatest influence on the direction of the line, mathematically.\n\n\n\nFor example, a small change in the value of Gene C would greatly change the direction of the longer line, whereas a small change in Gene A or Gene D would have little affect on it.\n\n\n\nWe could also rotate the entire plot and view the lines representing the variation as left-to-right and up-and-down. We see most of the variation in the data is left-to-right (longer line) and the second most variation in the data is up-and-down (shorter line). You can now think of these lines as the axes that represent the variation. These axes are essentially the “Principal Components”, with PC1 representing the most variation in the data and PC2 representing the second most variation in the data.\n\n\n\nNow, what if we had three samples/cells, then we would have an extra direction in which we could have variation (3D). Therefore, if we have N samples/cells we would have N-directions of variation or N principal components (PCs)! Once these PCs have been calculated, the PC that deals with the largest variation in the dataset is designated PC1, and the next one is designated PC2 and so on.\nOnce the PCs have been determined for an dataset, we have to figure out how each sample/cell fits back into that context to enable us to visualize the similarities/dissimilarities in an intuitive manner. The question here is “what is sample_X’s score for a given PC based on the gene expression in sample_X?”. This is the actual step where the dimensionality is reduced, since you plot PC scores for each sample/cell on the final PCA plot.\nPC scores are calculated for all sample-PC pairs as described in the steps and schematic below:\n\nFirst, each gene is assigned an “influence” score based on how much it influenced each PC. Genes that did not have any influence on a given PC get scores near zero, while genes with more influence receive larger scores. Genes on the ends of a PC line will have a larger influence, so they would receive larger scores but with opposite signs.\n\n\n\n\n\nOnce the influence has been determined, the score for each sample is calculated using the following equation:\nSample1 PC1 score = (read count * influence) + … for all genes\n\nFor our 2-sample example, the following is how the scores would be calculated:\n## Sample1\nPC1 score = (4 * -2) + (1 * -10) + (8 * 8) + (5 * 1) = 51\nPC2 score = (4 * 0.5) + (1 * 1) + (8 * -5) + (5 * 6) = -7\n\n## Sample2\nPC1 score = (5 * -2) + (4 * -10) + (8 * 8) + (7 * 1) = 21\nPC2 score = (5 * 0.5) + (4 * 1) + (8 * -5) + (7 * 6) = 8.5\nHere is a schematic that goes over the first 2 steps:\n\n\n\n\nOnce these scores are calculated for all the PCs, they can be plotted on a simple scatter plot. Below is the plot for the example here, going from the 2D matrix to a 2D plot:"
  },
  {
    "objectID": "lessons/seurat_subclustering.html",
    "href": "lessons/seurat_subclustering.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\nSubclustering scRNA-seq datasets\nAfter we have completed the scRNA-seq workflow and identified the various cell types present in our samples, we might decide that for a particular cell type, we would like to identify subtypes. For example, if we have a large cluster of CD4+ Helper T cells, we may want to identify subsets of Th1, Th2, Th17, Th9, and Tfh cells. To identify these cell subsets, we would subset the dataset to the cell type(s) of interest (e.g. CD4+ Helper T cells). To subset the dataset, Seurat has a handy subset() function; the identity of the cell type(s) can be used as input to extract the cells.\nTo perform the subclustering, there are a couple of different methods you could try. The easiest would be to run the FindNeighbors() and FindClusters() on the subsetted cells, adjusting the resolution to give you the optimal clustering. However, with this approach you are not redefining the most variable genes used to find clusters, so it might not work if the genes delineating these subsets are not those driving any of the top PCs used for the clustering.\nAlternatively, we could start over with the raw counts for this subset of cells and run SCTransform() to determine the greatest sources of variation present. This would allow us to focus our clustering on the most variant genes present among our subset of cells. Hopefully, the most variant genes are those driving the various desired subsets (e.g. Th1, Th2, Th17, Th9, and Tfh cells). If integration is necessary, then this step would still need to be performed.\nSince subsetting the dataset can result in a much smaller number of cells, it is important to consider the total number of cells you are looking to cluster and some of the parameters that might be affected by the small numbers. For example, if integrating, there is a ‘K’ number of cells used for determining the neighborhoods for identifying and filtering anchors. Therefore, if your integration isn’t very good for a small dataset, you might want to consider lowering the ‘K’ parameter. However, if ‘K’ is too small, it could also lead to poor integration."
  },
  {
    "objectID": "lessons/06b_integration_code_harmony.html",
    "href": "lessons/06b_integration_code_harmony.html",
    "title": "Performing Integration",
    "section": "",
    "text": "Approximate time: 30 minutes"
  },
  {
    "objectID": "lessons/06b_integration_code_harmony.html#learning-objectives",
    "href": "lessons/06b_integration_code_harmony.html#learning-objectives",
    "title": "Performing Integration",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nPerform integration of cells across conditions to identify cells that are similar to each other\nDescribe complex integration tasks and alternative tools for integration"
  },
  {
    "objectID": "lessons/06b_integration_code_harmony.html#running-cca",
    "href": "lessons/06b_integration_code_harmony.html#running-cca",
    "title": "Performing Integration",
    "section": "Running CCA",
    "text": "Running CCA\nIn the last lesson we described in detail the steps of integration. Now, we need to run the code to inetgrate our data. We will start by using our SCTransform object as input, let’s perform the integration across conditions (ctrl and stim).\nFirst, we need to identify the shared variable genes for the integration. By default, this function only selects the top 2000 genes. In this step Seuart performs a more complex version of an intersect between the highly variable genes from each condition (based on SCTransform). We have specified 3000 genes for the size of the intersect set.\n\n# Select the most variable features to use for integration\ninteg_features &lt;- SelectIntegrationFeatures(object.list = split_seurat, \n                                            nfeatures = 3000) \n\n\n\n\n\n\n\nNote\n\n\n\nIf you are missing the split_seurat object, you can first load it from your data folder:\n\n# Load the split seurat object into the environment\nsplit_seurat &lt;- readRDS(\"../data/split_seurat.rds\")\n\nIf you do not have the split_seurat.rds file in your data folder, you can right-click here to download it to the data folder (it may take a bit of time to download).\n\n\nNow, we need to prepare the SCTransform object for integration. This function basically prepares for integration analysis by ensuring all necessary data (specifically the SCTransform residuals) are present for the features chosen as anchors between datasets.\n\n# Prepare the SCT list object for integration\nsplit_seurat &lt;- PrepSCTIntegration(object.list = split_seurat, \n                                   anchor.features = integ_features)\n\nNow, we are going to perform CCA, find the best buddies or anchors and filter incorrect anchors. For our dataset, this will take up to 15 minutes to run. Also, note that the progress bar in your console will stay at 0%, but know that it is actually running.\n\n# Find best buddies - can take a while to run\ninteg_anchors &lt;- FindIntegrationAnchors(object.list = split_seurat, \n                                        normalization.method = \"SCT\", \n                                        anchor.features = integ_features)\n\nFinally, we can integrate across conditions.\n\n# Integrate across conditions\nseurat_integrated &lt;- IntegrateData(anchorset = integ_anchors, \n                                   normalization.method = \"SCT\")\n\n# Rejoin the layers in the RNA assay that we split earlier\nseurat_integrated[[\"RNA\"]] &lt;- JoinLayers(seurat_integrated[[\"RNA\"]])\n\n\nUMAP visualization\nAfter integration, to visualize the integrated data we can use dimensionality reduction techniques, such as PCA and Uniform Manifold Approximation and Projection (UMAP). While PCA will determine all PCs, we can only plot two at a time. In contrast, UMAP will take the information from any number of top PCs to arrange the cells in this multidimensional space. It will take those distances in multidimensional space and plot them in two dimensions working to preserve local and global structure. In this way, the distances between cells represent similarity in expression. If you wish to explore UMAP in more detail, this post is a nice introduction to UMAP theory.\nTo generate these visualizations we need to first run PCA and UMAP methods. Let’s start with PCA.\n\n# Run PCA\nseurat_integrated &lt;- RunPCA(object = seurat_integrated)\n\n# Plot PCA\nPCAPlot(seurat_integrated,\n        split.by = \"sample\")  \n\n\n\n\nWe can see with the PCA mapping that we have a good overlay of both conditions by PCA.\nNow, we can also visualize with UMAP. Let’s run the method and plot. UMAP is a stochastic algorithm – this means that it makes use of randomness both to speed up approximation steps, and to aid in solving hard optimization problems. Due to the stochastic nature, different runs of UMAP can produce different results. We can set the seed to a specific (but random) number, and this avoids the creation of a slightly different UMAP each time re-run our code.\n\n\n\n\n\n\nNote\n\n\n\nTypically, the set.seed() would be placed at the beginning of your script. In this way the selected random number would be applied to any function that uses pseudorandom numbers in its algorithm.\n\n\n\n# Set seed\nset.seed(123456)\n\n# Run UMAP\nseurat_integrated &lt;- RunUMAP(seurat_integrated, \n                             dims = 1:40,\n                                   reduction = \"pca\")\n\n# Plot UMAP                             \nDimPlot(seurat_integrated)                             \n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen we compare the similarity between the ctrl and stim clusters in the above plot with what we see using the the unintegrated dataset, it is clear that this dataset benefitted from the integration!\n\n\n\n\nSide-by-side comparison of clusters\nSometimes it’s easier to see whether all of the cells align well if we split the plotting between conditions, which we can do by adding the split.by argument to the DimPlot() function:\n\n# Plot UMAP split by sample\nDimPlot(seurat_integrated,\n        split.by = \"sample\")  \n\n\n\n\n\n\n\nSave the “integrated” object!\nSince it can take a while to integrate, it’s often a good idea to save the integrated seurat object.\n\n# Save integrated seurat object\nsaveRDS(seurat_integrated, \"../results/integrated_seurat.rds\")"
  },
  {
    "objectID": "lessons/06b_integration_code_harmony.html#complex-integration-tasks",
    "href": "lessons/06b_integration_code_harmony.html#complex-integration-tasks",
    "title": "Performing Integration",
    "section": "Complex Integration Tasks",
    "text": "Complex Integration Tasks\nIn the section above, we’ve presented the Seurat integration workflow, which uses canonical correlation analysis (CCA) and multiple nearest neighbors (MNN) to find “anchors” and integrate across samples, conditions, modalities, etc. While the Seurat integration approach is widely used and several benchmarking studies support its great performance in many cases, it is important to recognize that alternative integration algorithms exist and may work better for more complex integration tasks (see Luecken et al. (2022) for a comprehensive review).\nNot all integration algorithms rely on the same methodology, and they do not always provide the same type of corrected output (embeddings, count matrix…). Their performance is also affected by preliminary data processing steps, including which normalization method was used and how highly variable genes (HVGs) were determined. All those considerations are important to keep in mind when selecting a data integration approach for your study.\nWhat do we mean by a “complex” integration task?\nIn their benchmarking study, Luecken et al. (2022) compared the performance of different scRNA-seq integration tools when confronted to different “complex” tasks. The “complexity” of integrating a dataset may relate to the number of samples (perhaps generated using different protocols) but also to the biological question the study seeks to address (e.g. comparing cell types across tissues, species…). In these contexts, you may need to integrate across multiple confounding factors before you can start exploring the biology of your system.\n\nIn these more complex scenarios, you want to select a data integration approach that successfully balances out the following challenges:\n\nCorrecting for inter-sample variability due to source samples from different donors\nCorrecting for variability across protocols/technologies (10X, SMART-Seq2, inDrop…; single-cell vs. single nucleus; variable number of input cells and sequencing depth; different sample preparation steps…)\nIdentifying consistent cell types across different tissues (peripheral blood, bone marrow, lung…) and/or different locations (e.g. areas of the brain)\nKeeping apart cell subtypes (or even cell states) that show similar transcriptomes (CD4 naive vs. memory, NK vs NKT)\nKeeping apart cell subtypes that are unique to a tissue/condition\nConserving the developmental trajectory, if applicable\n\nNot all tools may perform as well on every task, and complex datasets may require testing several data integration approaches. You might want to analyze independently each of the batches you consider to integrate across, in order to define cell identities at this level before integrating and checking that the initially annotated cell types are mixed as expected."
  },
  {
    "objectID": "lessons/06b_integration_code_harmony.html#harmonizing-as-a-method-of-integration",
    "href": "lessons/06b_integration_code_harmony.html#harmonizing-as-a-method-of-integration",
    "title": "Performing Integration",
    "section": "Harmonizing as a method of integration",
    "text": "Harmonizing as a method of integration\nHarmony was devleoped in 2019, and is an example of a tool that can work with complex integration tasks. It is available as an R package on GitHub, and it has functions for standalone and Seurat pipeline analyses. It has been shown to perform incredibly well from recent benchmarking studies [1].\n\nOverview of Harmony\nIn this section, we illustrate the use of Harmony as a possible alternative to the Seurat integration workflow. Compared to other algorithms, Harmony notably presents the following advantages (Korsunsky et al. 2019, Tran et al. 2020):\n\nPossibility to integrate data across several variables (for example, by experimental batch and by condition)\nSignificant gain in speed and lower memory requirements for integration of large datasets\nInteroperability with the Seurat workflow\n\nInstead of using CCA, Harmony applies a transformation to the principal component (PCs) values, using all available PCs, e.g. as pre-computed within the Seurat workflow. In this space of transformed PCs, Harmony uses k-means clustering to delineate clusters, seeking to define clusters with maximum “diversity”. The diversity of each cluster reflects whether it contains balanced amounts of cells from each of the batches (donor, condition, tissue, technolgy…) we seek to integrate on, as should be observed in a well-integrated dataset. After defining diverse clusters, Harmony determines how much a cell’s batch identity impacts on its PC coordinates, and applies a correction to “shift” the cell towards the centroid of the cluster it belongs to. Cells are projected again using these corrected PCs, and the process is repeated iteratively until convergence.\n\nImage credit: Korsunsky, I., Millard, N., Fan, J. et al. Fast, sensitive and accurate integration of single-cell data with Harmony. Nat Methods 16, 1289–1296 (2019). https://doi.org/10.1038/s41592-019-0619-0\nFor a more detailed breakdown of the Harmony algorithm, we recommend checking this advanced vignette from the package developers.\n\n\nClick here for details on Implementing Harmony within the Seurat workflow\n\nIn practice, we can easily use Harmony within our Seurat workflow. To perform integration, Harmony takes as input a merged Seurat object, containing data that has been appropriately normalized (i.e. here, normalized using SCTransform) and for which highly variable features and PCs are defined.\nThere are 2 ways to create the input:\n\n\nMerge the raw Seurat objects for all samples to integrate; then perform normalization, variable feature selection and PC calculation on this merged object (workflow recommended by Harmony developers)\n\n\nPerform (SCT) normalization independently on each sample and find integration features across samples using Seurat; then merge these normalized Seurat objects, set variable features manually to integration features, and finally calculate PCs on this merged object (workflow best reflecting recommendations for application of SCTransform)\n\n\n\nIn the first scenario, assuming raw_seurat_list is a list of N samples containing raw data that have only undergone QC filtering, we would thus run the following code:\n# Merge raw samples\nmerged_seurat &lt;- merge(x = raw_seurat_list[[1]],\n               y = raw_seurat_list[2:length(raw_seurat_list)],\n               merge.data = TRUE)\n\n# Perform log-normalization and feature selection, as well as SCT normalization on global object\nmerged_seurat &lt;- merged_seurat %&gt;%\n    NormalizeData() %&gt;%\n    FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;% \n    ScaleData() %&gt;%\n    SCTransform(vars.to.regress = c(\"mitoRatio\"))\n\n# Calculate PCs using variable features determined by SCTransform (3000 by default)\nmerged_seurat &lt;- RunPCA(merged_seurat, assay = \"SCT\", npcs = 50)\n\nIn the second scenario, assuming norm_seurat_list is a list of N samples similar to our split_seurat object, i.e. containing data that have been normalized as demonstrated in the previous lecture on SCT normalization, we would thus run the following code:\n# Find most variable features across samples to integrate\ninteg_features &lt;- SelectIntegrationFeatures(object.list = norm_seurat_list, nfeatures = 3000)\n\n# Merge normalized samples\nmerged_seurat &lt;- merge(x = norm_seurat_list[[1]],\n               y = norm_seurat_list[2:length(raw_seurat_list)],\n               merge.data = TRUE)\nDefaultAssay(merged_seurat) &lt;- \"SCT\"\n\n# Manually set variable features of merged Seurat object\nVariableFeatures(merged_seurat) &lt;- integ_features\n\n# Calculate PCs using manually set variable features\nmerged_seurat &lt;- RunPCA(merged_seurat, assay = \"SCT\", npcs = 50)\n\n\nNOTE: As mentioned above, there is active discussion within the community regarding which of those 2 approaches to use (see for example here and here). We recommend that you check GitHub forums to make your own opinion and for updates.\n\nRegardless of the approach, we now have a merged Seurat object containing normalized data for all the samples we need to integrate, as well as defined variable features and PCs.\nOne last thing we need to do before running Harmony is to make sure that the metadata of our Seurat object contains one (or several) variable(s) describing the factor(s) we want to integrate on (e.g. one variable for sample_id, one variable for experiment_date).\nWe’re then ready to run Harmony!\nharmonized_seurat &lt;- RunHarmony(merged_seurat, \n                group.by.vars = c(\"sample_id\", \"experiment_date\"), \n                reduction = \"pca\", assay.use = \"SCT\", reduction.save = \"harmony\")\n\n\nNOTE: You can specify however many variables to integrate on using the group.by.vars parameter, although we would recommend keeping these to the minimum necessary for your study.\n\nThe line of code above adds a new reduction of 50 “harmony components” (~ corrected PCs) to our Seurat object, stored in harmonized_seurat@reductions$harmony.\nTo make sure our Harmony integration is reflected in the data visualization, we still need to generate a UMAP derived from these harmony embeddings instead of PCs:\nharmonized_seurat &lt;- RunUMAP(harmonized_seurat, reduction = \"harmony\", assay = \"SCT\", dims = 1:40)\n\nFinally, when running the clustering analysis later on (see next lecture for details), we will also need to set the reduction to use as “harmony” (instead of “pca” by default).\nharmonized_seurat &lt;- FindNeighbors(object = harmonized_seurat, reduction = \"harmony\")\nharmonized_seurat &lt;- FindClusters(harmonized_seurat, resolution = c(0.2, 0.4, 0.6, 0.8, 1.0, 1.2))\n\nThe rest of the Seurat workflow and downstream analyses after integration using Harmony can then proceed without further amendments."
  },
  {
    "objectID": "lessons/08_SC_clustering_quality_control.html",
    "href": "lessons/08_SC_clustering_quality_control.html",
    "title": "Clustering QC",
    "section": "",
    "text": "Approximate time: 90 minutes"
  },
  {
    "objectID": "lessons/08_SC_clustering_quality_control.html#learning-objectives",
    "href": "lessons/08_SC_clustering_quality_control.html#learning-objectives",
    "title": "Clustering QC",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nEvaluate whether clustering artifacts are present\nDetermine the quality of clustering with PCA and UMAP plots, and decide when to re-cluster\nAssess known cell type markers to hypothesize cell type identities of clusters"
  },
  {
    "objectID": "lessons/08_SC_clustering_quality_control.html#exploration-of-quality-control-metrics",
    "href": "lessons/08_SC_clustering_quality_control.html#exploration-of-quality-control-metrics",
    "title": "Clustering QC",
    "section": "Exploration of quality control metrics",
    "text": "Exploration of quality control metrics\nTo determine whether our clusters might be due to artifacts such as cell cycle phase or mitochondrial expression, it can be useful to explore these metrics visually to see if any clusters exhibit enrichment or are different from the other clusters. However, if enrichment or differences are observed for particular clusters it may not be worrisome if it can be explained by the cell type.\nTo explore and visualize the various quality metrics, we will use the versatile DimPlot() and FeaturePlot() functions from Seurat.\n\nSegregation of clusters by sample\nWe can start by exploring the distribution of cells per cluster in each sample:\n\n# Extract identity and sample information from seurat object to determine the number of cells per cluster per sample\nn_cells &lt;- FetchData(seurat_integrated, \n                     vars = c(\"ident\", \"sample\")) %&gt;%\n           dplyr::count(ident, sample)\n\n# Barplot of number of cells per cluster by sample\nggplot(n_cells, aes(x=ident, y=n, fill=sample)) +\n    geom_bar(position=position_dodge(), stat=\"identity\") +\n    theme_classic() +\n    geom_text(aes(label=n), vjust = -.2, position=position_dodge(1))\n\n\n\n\nWe can visualize the cells per cluster for each sample using the UMAP:\n\n# UMAP of cells in each cluster by sample\nDimPlot(seurat_integrated, \n        label = TRUE, \n        split.by = \"sample\")  + NoLegend()\n\n\n\n\nAdditionally, we can supply the metadata dataframe from our seurat object into ggplot to create more visuals. Looking at a UMAP is a great way to get a first pass look at your dataset, but we encourage you to look at your data in multiple different ways. For example, looking at the proportion of cells from a sample in each cluster.\n\n# Barplot of proportion of cells in each cluster by sample\nggplot(seurat_integrated@meta.data) +\n    geom_bar(aes(x=integrated_snn_res.0.8, fill=sample), \n             position=position_fill())  +\n    theme_classic()\n\n\n\n\nGenerally, we expect to see the majority of the cell type clusters to be present in all conditions; however, depending on the experiment we might expect to see some condition-specific cell types present. These clusters look pretty similar between conditions, which is good since we expected similar cell types to be present in both control and stimulated conditions.\n\n\nSegregation of clusters by cell cycle phase\nNext, we can explore whether the cells cluster by the different cell cycle phases. We did not regress out variation due to cell cycle phase when we performed the SCTransform normalization and regression of uninteresting sources of variation. If our cell clusters showed large differences in cell cycle expression, this would be an indication we would want to re-run the SCTransform and add the S.Score and G2M.Score to our variables to regress, then re-run the rest of the steps.\n\n# Explore whether clusters segregate by cell cycle phase\nDimPlot(seurat_integrated,\n        label = TRUE, \n        split.by = \"Phase\")  + NoLegend()\n\n\n\n\nWe do not see much clustering by cell cycle score, so we can proceed with the QC.\n\n\nSegregation of clusters by various sources of uninteresting variation\nNext we will explore additional metrics, such as the number of UMIs and genes per cell, S-phase and G2M-phase markers, and mitochondrial gene expression by UMAP. Looking at the individual S and G2M scores can give us additional information to checking the phase as we did previously.\n\n# Determine metrics to plot present in seurat_integrated@meta.data\nmetrics &lt;-  c(\"nUMI\", \"nGene\", \"S.Score\", \"G2M.Score\", \"mitoRatio\")\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = metrics,\n            pt.size = 0.4, \n            order = TRUE,\n            min.cutoff = 'q10',\n            label = TRUE)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe order argument will plot the positive cells above the negative cells, while the min.cutoff argument will determine the threshold for shading. A min.cutoff of q10 translates to the 10% of cells with the lowest expression of the gene will not exhibit any purple shading (completely gray).\n\n\nThe metrics seem to be relatively even across the clusters, with the exception of nGene exhibiting slightly higher values in clusters to the left of the plot. This can be more clearly seen when we look at the distribution as a boxplot. We can keep an eye on these clusters to see whether the cell types may explain the increase.\n\n# Boxplot of nGene per cluster\nggplot(seurat_integrated@meta.data) +\n    geom_boxplot(aes(x=integrated_snn_res.0.8, y=nGene, \n                     fill=integrated_snn_res.0.8)) +\n    theme_classic() +\n    NoLegend()\n\n\n\n\nIf we see differences corresponding to any of these metrics at this point in time, then we will often note them and then decide after identifying the cell type identities whether to take any further action.\n\n\nExploration of the PCs driving the different clusters\nWe can also explore how well our clusters separate by the different PCs; we hope that the defined PCs separate the cell types well. To visualize this information, we need to extract the UMAP coordinate information for the cells along with their corresponding scores for each of the PCs to view by UMAP.\nFirst, we identify the information we would like to extract from the Seurat object, then, we can use the FetchData() function to extract it.\n\n# Defining the information in the seurat object of interest\ncolumns &lt;- c(paste0(\"PC_\", 1:16),\n            \"ident\",\n            \"UMAP_1\", \"UMAP_2\")\n\n# Extracting this data from the seurat object\npc_data &lt;- FetchData(seurat_integrated, \n                     vars = columns)\nhead(pc_data)\n\n                             PC_1      PC_2        PC_3       PC_4        PC_5\nctrl_AAACATACAATGCC-1 -14.9778236 -2.879193 -5.05935118  -1.602766   0.8728779\nctrl_AAACATACATTTCC-1  22.3923271 -5.296913  4.95195846   3.112632   0.3379874\nctrl_AAACATACCAGAAA-1  28.9847264  1.203408 -5.94799284  -1.042701  -7.5690434\nctrl_AAACATACCAGCTA-1  20.1284164  2.826128 -5.26506094  -3.620790 -11.3740400\nctrl_AAACATACCATGCA-1  -0.4713399  1.122713  5.19520893 -23.884004  -2.2996247\nctrl_AAACATACCTCGCT-1  22.8011154 -3.431699 -0.06811772   3.248048  -2.9509455\n                           PC_6        PC_7       PC_8       PC_9      PC_10\nctrl_AAACATACAATGCC-1 -1.501420   0.5327841 -0.5855545  0.8866479  0.8223524\nctrl_AAACATACATTTCC-1 -7.873002   2.2740054 -5.8362430 -0.9666741  0.2170141\nctrl_AAACATACCAGAAA-1  5.477813 -10.7953185 19.5052392 -1.8312647  2.1803084\nctrl_AAACATACCAGCTA-1  2.339693  -4.3977231 -0.9173702 -2.2846928  6.1691837\nctrl_AAACATACCATGCA-1  2.013001  -1.2188812 -6.0930183 -4.4226968 -5.7635449\nctrl_AAACATACCTCGCT-1 -3.990378   3.7467244  0.5165570  1.9615799 -1.5014139\n                           PC_11      PC_12      PC_13       PC_14      PC_15\nctrl_AAACATACAATGCC-1 -1.7228802 -0.1832132  0.2985759 -0.04539058  1.2609419\nctrl_AAACATACATTTCC-1  3.1051321 -0.7964707  2.8982516  0.04362601 -3.1899372\nctrl_AAACATACCAGAAA-1 -7.7965824 -1.3324607 -2.3117140  3.06677862  1.6633818\nctrl_AAACATACCAGCTA-1 -1.6511025 -2.4827588  3.1481454  0.29120133  1.2874378\nctrl_AAACATACCATGCA-1  2.6080354 -6.7093986 -5.2829855  6.68742950  0.4564602\nctrl_AAACATACCTCGCT-1 -0.1431181 -0.6372477 -4.6625496  6.11468471 -2.1451294\n                           PC_16 ident     UMAP_1     UMAP_2\nctrl_AAACATACAATGCC-1  0.1993319     2   7.270473  0.9072988\nctrl_AAACATACATTTCC-1  5.3805322     1  -8.742020  1.5622634\nctrl_AAACATACCAGAAA-1 -3.0593032     3 -10.032904  4.7139827\nctrl_AAACATACCAGCTA-1  0.3093775     3  -8.363044  5.0377137\nctrl_AAACATACCATGCA-1  0.4905686     4   6.875784 -4.6442526\nctrl_AAACATACCTCGCT-1  2.3744525     1  -9.338899  2.2808882\n\n\n\n\n\n\n\n\nNote 1\n\n\n\nHow did we know in the FetchData() function to include UMAP_1 to obtain the UMAP coordinates? The Seurat cheatsheet describes the function as being able to pull any data from the expression matrices, cell embeddings, or metadata.\nFor instance, if you explore the seurat_integrated@reductions list object, the first component is for PCA, and includes a slot for cell.embeddings. We can use the column names (PC_1, PC_2, PC_3, etc.) to pull out the coordinates or PC scores corresponding to each cell for each of the PCs.\nWe could do the same thing for UMAP:\n\n# Extract the UMAP coordinates for the first 10 cells\nseurat_integrated@reductions$umap@cell.embeddings[1:10, 1:2]\n\n                          UMAP_1     UMAP_2\nctrl_AAACATACAATGCC-1   7.270473  0.9072988\nctrl_AAACATACATTTCC-1  -8.742020  1.5622634\nctrl_AAACATACCAGAAA-1 -10.032904  4.7139827\nctrl_AAACATACCAGCTA-1  -8.363044  5.0377137\nctrl_AAACATACCATGCA-1   6.875784 -4.6442526\nctrl_AAACATACCTCGCT-1  -9.338899  2.2808882\nctrl_AAACATACCTGGTA-1 -10.030569 -5.2654685\nctrl_AAACATACGATGAA-1   5.792516  1.9372119\nctrl_AAACATACGCCAAT-1  -8.717156  3.0439993\nctrl_AAACATACGCTTCC-1   8.764771  4.2027954\n\n\nThe FetchData() function just allows us to extract the data more easily.\n\n\n\n\n\n\n\n\nNote 2\n\n\n\nThe pre-existing seurat_integrated loaded in previously was created using an older version of Seurat. As such the columns we Fetch() are in upper case (i.e UMAP_1). If you are using your own seurat object using a newer version of Seurat you will need to change the column names as shown below. Alternatively, explore your Seurat object to see how they have been stored.\n\n# Defining the information in the seurat object of interest\ncolumns &lt;- c(paste0(\"PC_\", 1:16),\n         \"ident\",\n         \"umap_1\", \"umap_2\")\ncolumns\n\n [1] \"PC_1\"   \"PC_2\"   \"PC_3\"   \"PC_4\"   \"PC_5\"   \"PC_6\"   \"PC_7\"   \"PC_8\"  \n [9] \"PC_9\"   \"PC_10\"  \"PC_11\"  \"PC_12\"  \"PC_13\"  \"PC_14\"  \"PC_15\"  \"PC_16\" \n[17] \"ident\"  \"umap_1\" \"umap_2\"\n\n\n\n\nIn the UMAP plots below, the cells are colored by their PC score for each respective principal component.\nLet’s take a quick look at the top 16 PCs:\n\n# Adding cluster label to center of cluster on UMAP\numap_label &lt;- FetchData(seurat_integrated, \n                        vars = c(\"ident\", \"UMAP_1\", \"UMAP_2\"))  %&gt;%\n  group_by(ident) %&gt;%\n  dplyr::summarise(x=mean(UMAP_1), y=mean(UMAP_2))\n  \n# Plotting a UMAP plot for each of the PCs\nmap(paste0(\"PC_\", 1:16), function(pc){\n        ggplot(pc_data, \n               aes(UMAP_1, UMAP_2)) +\n                geom_point(aes_string(color=pc), \n                           alpha = 0.7) +\n                scale_color_gradient(guide = FALSE, \n                                     low = \"grey90\", \n                                     high = \"blue\")  +\n                geom_text(data=umap_label, \n                          aes(label=ident, x, y)) +\n                ggtitle(pc)\n}) %&gt;% \n        plot_grid(plotlist = .)\n\n\n\n\nWe can see how the clusters are represented by the different PCs. For instance, the genes driving PC_2 exhibit higher expression in clusters 8 and 12. We could look back at our genes driving this PC to get an idea of what the cell types might be:\n\n# Examine PCA results \nprint(seurat_integrated[[\"pca\"]], dims = 1:5, nfeatures = 5)\n\nPC_ 1 \nPositive:  FTL, TIMP1, FTH1, C15orf48, CXCL8 \nNegative:  RPL3, RPL13, RPS6, RPS18, RPL10 \nPC_ 2 \nPositive:  GNLY, CCL5, NKG7, GZMB, FGFBP2 \nNegative:  CD74, IGHM, IGKC, HLA-DRA, CD79A \nPC_ 3 \nPositive:  CD74, IGKC, HLA-DRA, IGHM, HLA-DRB1 \nNegative:  TRAC, FTL, CCL2, PABPC1, S100A8 \nPC_ 4 \nPositive:  CD74, IGHM, CCL5, GNLY, IGKC \nNegative:  HSPB1, CACYBP, HSPH1, HSP90AB1, HSPA8 \nPC_ 5 \nPositive:  VMO1, FCGR3A, MS4A7, TIMP1, TNFSF10 \nNegative:  CCL2, FTL, CXCL8, S100A8, S100A9 \n\n\nWith the GNLY and NKG7 genes as positive markers of PC_2, we can hypothesize that clusters 8 and 12 correspond to NK cells. This just hints at what the clusters identity could be, with the identities of the clusters being determined through a combination of the PCs.\nTo truly determine the identity of the clusters and whether the resolution is appropriate, it is helpful to explore a handful of known gene markers for the cell types expected."
  },
  {
    "objectID": "lessons/08_SC_clustering_quality_control.html#exploring-known-cell-type-markers",
    "href": "lessons/08_SC_clustering_quality_control.html#exploring-known-cell-type-markers",
    "title": "Clustering QC",
    "section": "Exploring known cell type markers",
    "text": "Exploring known cell type markers\nWith the cells clustered, we can explore the cell type identities by looking for known markers. The UMAP plot with clusters marked is shown, followed by the different cell types expected.\n\nDimPlot(object = seurat_integrated, \n        reduction = \"umap\", \n        label = TRUE) + NoLegend()\n\n\n\n\n\n\n\nCell Type\nMarker\n\n\n\n\nCD14+ monocytes\nCD14, LYZ\n\n\nFCGR3A+ monocytes\nFCGR3A, MS4A7\n\n\nConventional dendritic cells\nFCER1A, CST3\n\n\nPlasmacytoid dendritic cells\nIL3RA, GZMB, SERPINF1, ITM2C\n\n\nB cells\nCD79A, MS4A1\n\n\nT cells\nCD3D\n\n\nCD4+ T cells\nCD3D, IL7R, CCR7\n\n\nCD8+ T cells\nCD3D, CD8A\n\n\nNK cells\nGNLY, NKG7\n\n\nMegakaryocytes\nPPBP\n\n\nErythrocytes\nHBB, HBA2\n\n\n\nThe FeaturePlot() function from seurat makes it easy to visualize a handful of genes using the gene IDs stored in the Seurat object. We can easily explore the expression of known gene markers on top of our UMAP visualizations. Let’s go through and determine the identities of the clusters. To access the normalized expression levels of all genes, we can use the normalized count data stored in the RNA assay slot.\n\n\n\n\n\n\nNote\n\n\n\nThe SCTransform normalization was performed only on the 3000 most variable genes, so many of our genes of interest may not be present in this data.\n\n\n\n# Select the RNA counts slot to be the default assay\nDefaultAssay(seurat_integrated) &lt;- \"RNA\"\n\n# Normalize RNA data for visualization purposes\nseurat_integrated &lt;- NormalizeData(seurat_integrated, verbose = FALSE)\nseurat_integrated\n\nAn object of class Seurat \n31130 features across 29629 samples within 3 assays \nActive assay: RNA (14065 features, 0 variable features)\n 2 layers present: counts, data\n 2 other assays present: SCT, integrated\n 2 dimensional reductions calculated: pca, umap\n\n\n\n\n\n\n\n\nNote\n\n\n\nAssay is a slot defined in the Seurat object, it has multiple slots within it. In a given assay, the counts slot stores non-normalized raw counts, and the data slot stores normalized expression data. Therefore, when we run the NormalizeData() function in the above code, the normalized data will be stored in the data slot of the RNA assay while the counts slot will remain unaltered.\n\n\nDepending on our markers of interest, they could be positive or negative markers for a particular cell type. The combined expression of our chosen handful of markers should give us an idea on whether a cluster corresponds to that particular cell type.\nFor the markers used here, we are looking for positive markers and consistency of expression of the markers across the clusters. For example, if there are two markers for a cell type and only one of them is expressed in a cluster - then we cannot reliably assign that cluster to the cell type.\nCD14+ monocyte markers\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = c(\"CD14\", \"LYZ\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\nCD14+ monocytes appear to correspond to clusters 1, and 3. We wouldn’t include clusters 14 and 10 because they do not highly express both of these markers.\nFCGR3A+ monocyte markers\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = c(\"FCGR3A\", \"MS4A7\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\nFCGR3A+ monocytes markers distinctly highlight cluster 10, although we do see some decent expression in clusters 1 and 3 We would like to see additional markers for FCGR3A+ cells show up when we perform the marker identification.\nMacrophages\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = c(\"MARCO\", \"ITGAM\", \"ADGRE1\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\nWe don’t see much overlap of our markers, so no clusters appear to correspond to macrophages; perhaps cell culture conditions negatively selected for macrophages (more highly adherent).\nConventional dendritic cell markers\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = c(\"FCER1A\", \"CST3\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\nThe markers corresponding to conventional dendritic cells identify cluster 14 (both markers consistently show expression).\nPlasmacytoid dendritic cell markers\n\nFeaturePlot(seurat_integrated, \n            reduction = \"umap\", \n            features = c(\"IL3RA\", \"GZMB\", \"SERPINF1\", \"ITM2C\"), \n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE)\n\n\n\n\nPlasmacytoid dendritic cells represent cluster 16. While there are a lot of differences in the expression of these markers, we see cluster 16 (though small) is consistently strongly expressed.\n\nSeurat also has a built in visualization tool which allows us to view the average expression of genes across clusters called DotPlot(). This function additionally shows us how many cells within the cluster have expression of one gene. As input, we supply a list of genes - note that we cannot use the same gene twice or an error will be thrown.\n\n# List of known celltype markers\nmarkers &lt;- list()\nmarkers[[\"CD14+ monocytes\"]] &lt;- c(\"CD14\", \"LYZ\")\nmarkers[[\"FCGR3A+ monocyte\"]] &lt;- c(\"FCGR3A\", \"MS4A7\")\nmarkers[[\"Macrophages\"]] &lt;- c(\"MARCO\", \"ITGAM\", \"ADGRE1\")\nmarkers[[\"Conventional dendritic\"]] &lt;- c(\"FCER1A\", \"CST3\")\nmarkers[[\"Plasmacytoid dendritic\"]] &lt;- c(\"IL3RA\", \"GZMB\", \"SERPINF1\", \"ITM2C\")\n\n# Create dotplot based on RNA expression\nDotPlot(seurat_integrated, markers, assay=\"RNA\")\n\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\nHypothesize the clusters corresponding to each of the different clusters in the table:\n\n\n\nCell Type\nClusters\n\n\n\n\nCD14+ monocytes\n1, 3\n\n\nFCGR3A+ monocytes\n10\n\n\nConventional dendritic cells\n14\n\n\nPlasmacytoid dendritic cells\n16\n\n\nMarcrophages\n-\n\n\nB cells\n?\n\n\nT cells\n?\n\n\nCD4+ T cells\n?\n\n\nCD8+ T cells\n?\n\n\nNK cells\n?\n\n\nMegakaryocytes\n?\n\n\nErythrocytes\n?\n\n\nUnknown\n?\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf any cluster appears to contain two separate cell types, it’s helpful to increase our clustering resolution to properly subset the clusters. Alternatively, if we still can’t separate out the clusters using increased resolution, then it’s possible that we had used too few principal components such that we are just not separating out these cell types of interest. To inform our choice of PCs, we could look at our PC gene expression overlapping the UMAP plots and determine whether our cell populations are separating by the PCs included.\n\n\nNow we have a decent idea as to the cell types corresponding to the majority of the clusters, but some questions remain:\n\nT cell markers appear to be highly expressed in may clusters. How can we differentiate and subset the larger group into smaller subset of cells?\nDo the clusters corresponding to the same cell types have biologically meaningful differences? Are there subpopulations of these cell types?\nCan we acquire higher confidence in these cell type identities by identifying other marker genes for these clusters?\n\nMarker identification analysis can help us address all of these questions!!\nThe next step will be to perform marker identification analysis, which will output the genes that significantly differ in expression between clusters. Using these genes we can determine or improve confidence in the identities of the clusters/subclusters."
  },
  {
    "objectID": "lessons/scRNAseq_workflow.html",
    "href": "lessons/scRNAseq_workflow.html",
    "title": "Workflow Overview",
    "section": "",
    "text": "Approximate time: 20 minutes"
  },
  {
    "objectID": "lessons/scRNAseq_workflow.html#learning-objectives",
    "href": "lessons/scRNAseq_workflow.html#learning-objectives",
    "title": "Workflow Overview",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nDescribe the workflow for single-cell RNA-seq analysis"
  },
  {
    "objectID": "lessons/scRNAseq_workflow.html#filtering-data",
    "href": "lessons/scRNAseq_workflow.html#filtering-data",
    "title": "Workflow Overview",
    "section": "Filtering data",
    "text": "Filtering data\nThe first step is to take the raw count data and use various metrics to identify true cells that are of high quality, so that when we cluster our cells it is easier to identify distinct cell type populations. Visualizing metrics with plots allows us to evaluate all samples within a dataset and isolate any problematic samples. Additionally, we can more easily decide on suitable thresholds for cell-level filtering. We want to be able to keep as many high quality cells as possible without removing biologically relevant cell types. Gene-level filtering is also applied at this stage."
  },
  {
    "objectID": "lessons/scRNAseq_workflow.html#clustering-workflow",
    "href": "lessons/scRNAseq_workflow.html#clustering-workflow",
    "title": "Workflow Overview",
    "section": "Clustering workflow",
    "text": "Clustering workflow\nFor something to be informative, it needs to exhibit variation, but not all variation is informative. The goal of our clustering analysis is to keep the major sources of variation in our dataset that should define our cell types, while restricting the variation due to uninteresting sources of variation (sequencing depth, cell cycle differences, mitochondrial expression, batch effects, etc.). Then, to determine the cell types present, we will perform a clustering analysis using the most variable genes to define the major sources of variation in the dataset.\nThe workflow for this analysis is adapted from the following sources:\n\nSatija Lab: Seurat v3 Guided Integration Tutorial\nPaul Hoffman: Cell-Cycle Scoring and Regression\n\nTo identify clusters, the following steps are performed:\n\n1. Explore sources of unwanted variation\nThe first step in the workflow is to see if our data contains any unwanted variability. The most common biological effect that is evaluated in single-cell RNA-seq data is the effect of cell cycle on the transcriptome. Another known biological effect is mitochondrial gene expression, which is interpreted as an indication of cell stress. This step of the workflow involves exploring our data to identify which covariates we would like to regress out.\n\n\n2. Normalization and regressing out sources of unwanted variation\nNormalization is required to scale the raw count data to obtain correct relative gene expression abundances between cells. The sctransform function implements an advanced normalization and variance stabilization of the data. The sctransform function also regresses out sources of unwanted variation in our data. In the previous step, we had identified these sources of variability, and here we specify what those covariates are.\n\n\n3. Integration\nOften with single cell RNA-seq we are working with multiple samples which correspond to different sample groups, multiple experiments or different modalities. If we want to ultimately compare celltype expression between groups it is recommended to integrate the data. Integration is a powerful method that uses these shared sources of greatest variation to identify shared sub-populations across conditions or datasets [Stuart and Butler et al. (2018)]. There are several steps involved in performing intergration in Seurat. Once complete, we use visualization methods to ensure a good integration before we proceed to cluster cells.\n\n\n\n\n\n\nNote\n\n\n\nIntegration is optional. We recommend going through the workflow without integration to decide whether or not it is necessary for your data.\n\n\n\n\n4. Clustering cells\nClusters of cells are obtained by grouping cells based on the similarity of their gene expression profiles. Expression profile similarity is determined via distance metrics, which often take dimensionality‐reduced representations as input. Seurat assigns cells to clusters based on their PCA scores derived from the expression of the integrated most variable genes.\n\n\n5. Cluster quality evaluation\nThe clusters identified in our data represent groups of cells that presumably belong to a similar cell type. Before we can confirm the celltype of a group of member cells, the following steps are taken:\n\na. Check to see that clusters are not influenced by sources of uninteresting variation.\nb. Check to see whether the major principal components are driving the different clusters.\nc. Explore the cell type identities by looking at the expression for known markers across the clusters."
  },
  {
    "objectID": "lessons/scRNAseq_workflow.html#marker-identification-and-celltype-assignment",
    "href": "lessons/scRNAseq_workflow.html#marker-identification-and-celltype-assignment",
    "title": "Workflow Overview",
    "section": "Marker Identification and Celltype Assignment",
    "text": "Marker Identification and Celltype Assignment\nOften the known marker expression evaluation gives us some hints as to which celltype is represented within a cluster, but sometimes it is not so obvious. In situations where there is uncertainty of the cell type assignment it is good practice to check which genes exhibit a high expression profile among cells (i.e FindMarkers). The list of genes can provide insight on celltype and/or can be the impetus for removal of a group of cells. After this step we hope to obtain a fully annotated dataset that we can move forward with for downstream analysis."
  },
  {
    "objectID": "lessons/01_intro_to_scRNA-seq.html",
    "href": "lessons/01_intro_to_scRNA-seq.html",
    "title": "Introduction to single-cell RNA-seq",
    "section": "",
    "text": "Across human tissues there is an incredible diversity of cell types, states, and interactions. To better understand these tissues and the cell types present, single-cell RNA-seq (scRNA-seq) offers a glimpse into what genes are being expressed at the level of individual cells.\n\nImage credit: courtesy of Dr. Ayshwarya Subramanian\nThis exciting and cutting-edge method can be used to:\n\nExplore which cell types are present in a tissue\nIdentify unknown/rare cell types or states\nElucidate the changes in gene expression during differentiation processes or across time or states\nIdentify genes that are differentially expressed in particular cell types between conditions (e.g. treatment or disease)\nExplore changes in expression among a cell type while incorporating spatial, regulatory, and/or protein information\n\nPopular methods to address some of the more common investigations include:\n\n\n\n\nPrior to scRNA-seq, transcriptome analysis was performed using bulk RNA-seq, which is a method for comparing the averages of cellular expression. This method can be a good choice if looking at comparative transcriptomics (e.g. samples of the same tissue from different species), and for quantifying expression signatures in disease studies. It also has potential for the discovery of disease biomarkers if you are not expecting or not concerned about cellular heterogeneity in the sample.\nWhile bulk RNA-seq can explore differences in gene expression between conditions (e.g. treatment or disease), the differences at the cellular level are not adequately captured. For instance, in the images below, if analyzed in bulk (left) we would not detect the correct association between the expression of gene A and gene B. However, if we properly group the cells by cell type or cell state, we can see the correct correlation between the genes.\n\nImage credit: Trapnell, C. Defining cell types and states with single-cell genomics, Genome Research 2015 (doi: https://dx.doi.org/10.1101/gr.190595.115)\nDespite scRNA-seq being able to capture expression at the cellular level, sample generation and library preparation is more expensive and the analysis is much more complicated and more difficult to interpret. The complexity of analysis of scRNA-seq data involves:\n\nLarge volume of data\nLow depth of sequencing per cell\nTechnical variability across cells/samples\nBiological variability across cells/samples\n\nWe will explore each of these complexities in more detail below:\n\n\nExpression data from scRNA-seq experiments represent tens or hundreds of thousands of reads for thousands of cells. The data output is much larger, requiring higher amounts of memory to analyze, larger storage requirements, and more time to run the analyses.\n\n\n\nFor the droplet-based methods of scRNA-seq, the depth of sequencing is shallow, often detecting only 10-50% of the transcriptome per cell. This results in cells showing zero counts for many of the genes. However, in a particular cell, a zero count for a gene could either mean that the gene was not being expressed or the transcripts were just not detected. Across cells, genes with higher levels of expression tend to have fewer zeros. Due to this feature, many genes will not be detected in any cell and gene expression will be highly variable between cells.\n\n\n\n\n\n\nZero-inflated?\n\n\n\nscRNA-seq data is often referred to as zero-inflated; however, recent analyses suggest that it does not contain more zeros than what would be expected given the sequencing depth [Valentine Svensson’s blog post]. A more recent paper discussing modeling of scRNA-seq data is also available.\n\n\n\n\n\nUninteresting sources of biological variation can result in gene expression between cells being more similar/different than the actual biological cell types/states, which can obscure the cell type identities. Uninteresting sources of biological variation (unless part of the experiment’s study) include:\n\nTranscriptional bursting: Gene transcription is not turned on all of the time for all genes. Time of harvest will determine whether gene is on or off in each cell.\nVarying rates of RNA processing: Different RNAs are processed at different rates.\nContinuous or discrete cell identities (e.g. the pro-inflammatory potential of each individual T cell): Continuous phenotypes are by definition variable in gene expression, and separating the continuous from the discrete can sometimes be difficult.\nEnvironmental stimuli: The local environment of the cell can influence the gene expression depending on spatial position, signaling molecules, etc.\nTemporal changes: Fundamental fluxuating cellular processes, such as cell cycle, can affect the gene expression profiles of individual cells.\n\n\nImage credit: Wagner, A, et al. Revealing the vectors of cellular identity with single-cell genomics, Nat Biotechnol. 2016 (doi:https://dx.doi.org/10.1038%2Fnbt.3711)\n\n\n\nTechnical sources of variation can result in gene expression between cells being more similar/different based on technical sources instead of biological cell types/states, which can obscure the cell type identities. Technical sources of variation include:\n\nCell-specific capture efficiency: Different cells will have differing numbers of transcripts captured resulting in differences in sequencing depth (e.g. 10-50% of transcriptome).\nLibrary quality: Degraded RNA, low viability/dying cells, lots of free floating RNA, poorly dissociated cells, and inaccurate quantitation of cells can result in low quality metrics\nAmplification bias: During the amplification step of library preparation, not all transcripts are amplified to the same level.\nBatch effects: Batch effects are a significant issue for scRNA-Seq analyses, since you can see significant differences in expression due solely to the batch effect.\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\nTo explore the issues generated by poor batch study design, they are highlighted nicely in this paper.\nHow to know whether you have batches?\n\nWere all RNA isolations performed on the same day?\nWere all library preparations performed on the same day?\nDid the same person perform the RNA isolation/library preparation for all samples?\nDid you use the same reagents for all samples?\nDid you perform the RNA isolation/library preparation in the same location?\n\nIf any of the answers is ‘No’, then you have batches.\nBest practices regarding batches:\n\nDesign the experiment in a way to avoid batches, if possible.\nIf unable to avoid batches:\n\nDo NOT confound your experiment by batch:\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\nDO split replicates of the different sample groups across batches. The more replicates the better (definitely more than 2), if doing DE across conditions or making conclusions at the population level. If using inDrops, which prepares a single library at a time, alternate the sample groups (e.g. don’t prepare all control libraries first, then prepare all treatment libraries).\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\nDO include batch information in your experimental metadata. During the analysis, we can regress out variation due to batch or integrate across batches, so it doesn’t affect our results if we have that information.\n\n\n\n\n\n\n\nWhile scRNA-seq is a powerful and insightful method for the analysis of gene expression with single-cell resolution, there are many challenges and sources of variation that can make the analysis of the data complex or limited. Throughout the analysis of scRNA-seq data, we will try to account for or regress out variation due to the various sources of uninteresting variation in our data.\nOverall, we recommend the following:\n\nDo not perform single-cell RNA-seq unless it is necessary for the experimental question of interest. Could you answer the question using bulk sequencing, which is simpler and less costly? Perhaps FACS sorting the samples could allow for bulk analysis?\nUnderstand the details of the experimental question you wish to address. The recommended library preparation method and analysis workflow can vary based on the specific experiment.\nAvoid technical sources of variability, if possible:\n\nDiscuss experimental design with experts prior to the initiation of the experiment\nIsolate RNA from samples at same time\nPrepare libraries at same time or alternate sample groups to avoid batch confounding\nDo not confound sample groups by sex, age, or batch\n\n\n\n\n\n\n\n\n\nHow does single-nucleus RNA-seq (snRNA-seq) compare to single-cell RNA-seq?\n\n\n\nWe will not be covering snRNA-seq in this workshop! Below is a brief overview of snRNA-seq.\nsnRNA-seq analyzes the expression profiles from nuclei, instead of intact cells. As you may expect, fewer transcripts are detected from the nuclei (~7,000 genes), compared to intact cells (~11,000 genes). In some situations (depending on your research materials and goals), snRNA-seq can be the preferred method as opposed to scRNA-seq.\nSome advantages of snRNA-seq include: * Works well with hard-to-isolate samples (for example, adipocytes), as well as frozen tissues * Reduces transcriptional artifacts from the isolation process * Provides less biased cellular coverage"
  },
  {
    "objectID": "lessons/01_intro_to_scRNA-seq.html#why-single-cell-rna-seq",
    "href": "lessons/01_intro_to_scRNA-seq.html#why-single-cell-rna-seq",
    "title": "Introduction to single-cell RNA-seq",
    "section": "",
    "text": "Across human tissues there is an incredible diversity of cell types, states, and interactions. To better understand these tissues and the cell types present, single-cell RNA-seq (scRNA-seq) offers a glimpse into what genes are being expressed at the level of individual cells.\n\nImage credit: courtesy of Dr. Ayshwarya Subramanian\nThis exciting and cutting-edge method can be used to:\n\nExplore which cell types are present in a tissue\nIdentify unknown/rare cell types or states\nElucidate the changes in gene expression during differentiation processes or across time or states\nIdentify genes that are differentially expressed in particular cell types between conditions (e.g. treatment or disease)\nExplore changes in expression among a cell type while incorporating spatial, regulatory, and/or protein information\n\nPopular methods to address some of the more common investigations include:"
  },
  {
    "objectID": "lessons/01_intro_to_scRNA-seq.html#challenges-of-scrna-seq-analysis",
    "href": "lessons/01_intro_to_scRNA-seq.html#challenges-of-scrna-seq-analysis",
    "title": "Introduction to single-cell RNA-seq",
    "section": "",
    "text": "Prior to scRNA-seq, transcriptome analysis was performed using bulk RNA-seq, which is a method for comparing the averages of cellular expression. This method can be a good choice if looking at comparative transcriptomics (e.g. samples of the same tissue from different species), and for quantifying expression signatures in disease studies. It also has potential for the discovery of disease biomarkers if you are not expecting or not concerned about cellular heterogeneity in the sample.\nWhile bulk RNA-seq can explore differences in gene expression between conditions (e.g. treatment or disease), the differences at the cellular level are not adequately captured. For instance, in the images below, if analyzed in bulk (left) we would not detect the correct association between the expression of gene A and gene B. However, if we properly group the cells by cell type or cell state, we can see the correct correlation between the genes.\n\nImage credit: Trapnell, C. Defining cell types and states with single-cell genomics, Genome Research 2015 (doi: https://dx.doi.org/10.1101/gr.190595.115)\nDespite scRNA-seq being able to capture expression at the cellular level, sample generation and library preparation is more expensive and the analysis is much more complicated and more difficult to interpret. The complexity of analysis of scRNA-seq data involves:\n\nLarge volume of data\nLow depth of sequencing per cell\nTechnical variability across cells/samples\nBiological variability across cells/samples\n\nWe will explore each of these complexities in more detail below:\n\n\nExpression data from scRNA-seq experiments represent tens or hundreds of thousands of reads for thousands of cells. The data output is much larger, requiring higher amounts of memory to analyze, larger storage requirements, and more time to run the analyses.\n\n\n\nFor the droplet-based methods of scRNA-seq, the depth of sequencing is shallow, often detecting only 10-50% of the transcriptome per cell. This results in cells showing zero counts for many of the genes. However, in a particular cell, a zero count for a gene could either mean that the gene was not being expressed or the transcripts were just not detected. Across cells, genes with higher levels of expression tend to have fewer zeros. Due to this feature, many genes will not be detected in any cell and gene expression will be highly variable between cells.\n\n\n\n\n\n\nZero-inflated?\n\n\n\nscRNA-seq data is often referred to as zero-inflated; however, recent analyses suggest that it does not contain more zeros than what would be expected given the sequencing depth [Valentine Svensson’s blog post]. A more recent paper discussing modeling of scRNA-seq data is also available.\n\n\n\n\n\nUninteresting sources of biological variation can result in gene expression between cells being more similar/different than the actual biological cell types/states, which can obscure the cell type identities. Uninteresting sources of biological variation (unless part of the experiment’s study) include:\n\nTranscriptional bursting: Gene transcription is not turned on all of the time for all genes. Time of harvest will determine whether gene is on or off in each cell.\nVarying rates of RNA processing: Different RNAs are processed at different rates.\nContinuous or discrete cell identities (e.g. the pro-inflammatory potential of each individual T cell): Continuous phenotypes are by definition variable in gene expression, and separating the continuous from the discrete can sometimes be difficult.\nEnvironmental stimuli: The local environment of the cell can influence the gene expression depending on spatial position, signaling molecules, etc.\nTemporal changes: Fundamental fluxuating cellular processes, such as cell cycle, can affect the gene expression profiles of individual cells.\n\n\nImage credit: Wagner, A, et al. Revealing the vectors of cellular identity with single-cell genomics, Nat Biotechnol. 2016 (doi:https://dx.doi.org/10.1038%2Fnbt.3711)\n\n\n\nTechnical sources of variation can result in gene expression between cells being more similar/different based on technical sources instead of biological cell types/states, which can obscure the cell type identities. Technical sources of variation include:\n\nCell-specific capture efficiency: Different cells will have differing numbers of transcripts captured resulting in differences in sequencing depth (e.g. 10-50% of transcriptome).\nLibrary quality: Degraded RNA, low viability/dying cells, lots of free floating RNA, poorly dissociated cells, and inaccurate quantitation of cells can result in low quality metrics\nAmplification bias: During the amplification step of library preparation, not all transcripts are amplified to the same level.\nBatch effects: Batch effects are a significant issue for scRNA-Seq analyses, since you can see significant differences in expression due solely to the batch effect.\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\nTo explore the issues generated by poor batch study design, they are highlighted nicely in this paper.\nHow to know whether you have batches?\n\nWere all RNA isolations performed on the same day?\nWere all library preparations performed on the same day?\nDid the same person perform the RNA isolation/library preparation for all samples?\nDid you use the same reagents for all samples?\nDid you perform the RNA isolation/library preparation in the same location?\n\nIf any of the answers is ‘No’, then you have batches.\nBest practices regarding batches:\n\nDesign the experiment in a way to avoid batches, if possible.\nIf unable to avoid batches:\n\nDo NOT confound your experiment by batch:\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\nDO split replicates of the different sample groups across batches. The more replicates the better (definitely more than 2), if doing DE across conditions or making conclusions at the population level. If using inDrops, which prepares a single library at a time, alternate the sample groups (e.g. don’t prepare all control libraries first, then prepare all treatment libraries).\n\nImage credit: Hicks SC, et al., bioRxiv (2015)\nDO include batch information in your experimental metadata. During the analysis, we can regress out variation due to batch or integrate across batches, so it doesn’t affect our results if we have that information."
  },
  {
    "objectID": "lessons/01_intro_to_scRNA-seq.html#conclusions",
    "href": "lessons/01_intro_to_scRNA-seq.html#conclusions",
    "title": "Introduction to single-cell RNA-seq",
    "section": "",
    "text": "While scRNA-seq is a powerful and insightful method for the analysis of gene expression with single-cell resolution, there are many challenges and sources of variation that can make the analysis of the data complex or limited. Throughout the analysis of scRNA-seq data, we will try to account for or regress out variation due to the various sources of uninteresting variation in our data.\nOverall, we recommend the following:\n\nDo not perform single-cell RNA-seq unless it is necessary for the experimental question of interest. Could you answer the question using bulk sequencing, which is simpler and less costly? Perhaps FACS sorting the samples could allow for bulk analysis?\nUnderstand the details of the experimental question you wish to address. The recommended library preparation method and analysis workflow can vary based on the specific experiment.\nAvoid technical sources of variability, if possible:\n\nDiscuss experimental design with experts prior to the initiation of the experiment\nIsolate RNA from samples at same time\nPrepare libraries at same time or alternate sample groups to avoid batch confounding\nDo not confound sample groups by sex, age, or batch\n\n\n\n\n\n\n\n\n\nHow does single-nucleus RNA-seq (snRNA-seq) compare to single-cell RNA-seq?\n\n\n\nWe will not be covering snRNA-seq in this workshop! Below is a brief overview of snRNA-seq.\nsnRNA-seq analyzes the expression profiles from nuclei, instead of intact cells. As you may expect, fewer transcripts are detected from the nuclei (~7,000 genes), compared to intact cells (~11,000 genes). In some situations (depending on your research materials and goals), snRNA-seq can be the preferred method as opposed to scRNA-seq.\nSome advantages of snRNA-seq include: * Works well with hard-to-isolate samples (for example, adipocytes), as well as frozen tissues * Reduces transcriptional artifacts from the isolation process * Provides less biased cellular coverage"
  },
  {
    "objectID": "lessons/readMM_loadData.html",
    "href": "lessons/readMM_loadData.html",
    "title": "Seurat Object from Counts File",
    "section": "",
    "text": "Creating count data object\nGenerally, all single-cell RNA-seq datasets, regardless of technology or pipeline, will contain three files:\n\na file with the gene IDs, representing all genes quantified\na file with the cell IDs, representing all cells quantified\na matrix of counts per gene for every cell\n\nWe can explore these files by clicking on the data/ctrl_raw_feature_bc_matrix folder:\n\nbarcodes.tsv: cellular barcodes present in dataset\n\n\n\nfeatures.tsv: IDs of quantified genes\n\n\n\nmatrix.mtx: a matrix of count values, where rows are associated with the gene IDs above and columns correspond to the cellular barcodes. Note that there are many zero values in this matrix.\n\n\nWe can create a count matrix using these files. However, instead of creating a standard count matrix, we will create a sparse matrix to improve the amount of space, memory and CPU required to work with our huge count matrix.\n\nlibrary(Matrix)\nlibrary(readr)\n\nWe will use readMM() function from the Matrix package to turn our standard matrix into a sparse matrix. The genes.tsv file should correspond to the genes or row names of the matrix, while barcodes.tsv corresponds to the cells or columns.\n\n# Read in `matrix.mtx`\ncounts &lt;- readMM(\"../data/ctrl_raw_feature_bc_matrix/matrix.mtx.gz\")\n\n# Read in `genes.tsv`\ngenes &lt;- read_tsv(\"../data/ctrl_raw_feature_bc_matrix/features.tsv.gz\",\n                  col_names = FALSE)\ngene_ids &lt;- genes$X1\n\n# Read in `barcodes.tsv`\ncell_ids &lt;- read_tsv(\"../data/ctrl_raw_feature_bc_matrix/barcodes.tsv.gz\",\n                     col_names = FALSE)\ncell_ids &lt;- cell_ids$X1\n\nThen we can add row names to the count matrix to be the gene IDs and the column names of the count matrix to be the cell IDs.\n\n# Make the column names as the cell IDs and the row names as the gene IDs\nrownames(counts) &lt;- gene_ids\ncolnames(counts) &lt;- cell_ids\n\nWe could use this data for downstream QC analysis. However, this would take a long time if we had multiple samples. A quicker way to load multiple samples is to use the Seurat R package, which has a specific function for reading in 10X data, called read10X().\n\n\n\n\n\n\nNote\n\n\n\nIf using other droplet-based methods for library preparation, the above method would be needed to perform the QC. We have additional materials available based on creation of the count matrix in this way."
  },
  {
    "objectID": "lessons/09_merged_SC_marker_identification.html",
    "href": "lessons/09_merged_SC_marker_identification.html",
    "title": "Marker identification",
    "section": "",
    "text": "Approximate time: 75 minutes"
  },
  {
    "objectID": "lessons/09_merged_SC_marker_identification.html#learning-objectives",
    "href": "lessons/09_merged_SC_marker_identification.html#learning-objectives",
    "title": "Marker identification",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nDescribe how to determine markers of individual clusters\nDiscuss the iterative processes of clustering and marker identification"
  },
  {
    "objectID": "lessons/09_merged_SC_marker_identification.html#identification-of-all-markers-for-each-cluster",
    "href": "lessons/09_merged_SC_marker_identification.html#identification-of-all-markers-for-each-cluster",
    "title": "Marker identification",
    "section": "Identification of all markers for each cluster",
    "text": "Identification of all markers for each cluster\nThis type of analysis is typically recommended for when evaluating a single sample group/condition. With the FindAllMarkers() function we are comparing each cluster against all other clusters to identify potential marker genes. The cells in each cluster are treated as replicates, and essentially a differential expression analysis is performed with some statistical test.\n\n\n\n\n\n\nNote\n\n\n\nThe default is a Wilcoxon Rank Sum test, but there are other options available.\n\n\n\n\n\nThe FindAllMarkers() function has three important arguments which provide thresholds for determining whether a gene is a marker:\n\nlogfc.threshold: minimum log2 fold change for average expression of gene in cluster relative to the average expression in all other clusters combined. Default is 0.25.\n\nCons:\n\ncould miss those cell markers that are expressed in a small fraction of cells within the cluster of interest, but not in the other clusters, if the average logfc doesn’t meet the threshold\ncould return a lot of metabolic/ribosomal genes due to slight differences in metabolic output by different cell types, which are not as useful to distinguish cell type identities\n\n\nmin.diff.pct: minimum percent difference between the percent of cells expressing the gene in the cluster and the percent of cells expressing gene in all other clusters combined.\n\nCons: could miss those cell markers that are expressed in all cells, but are highly up-regulated in this specific cell type\n\nmin.pct: only test genes that are detected in a minimum fraction of cells in either of the two populations. Meant to speed up the function by not testing genes that are very infrequently expressed. Default is 0.1.\n\nCons: if set to a very high value could incur many false negatives due to the fact that not all genes are detected in all cells (even if it is expressed)\n\n\nYou could use any combination of these arguments depending on how stringent/lenient you want to be. Also, by default this function will return to you genes that exhibit both positive and negative expression changes. Typically, we add an argument only.pos to opt for keeping only the positive changes. The code to find markers for each cluster is shown below. We will not run this code.\n\n## DO NOT RUN THIS CODE ##\n\n# Find markers for every cluster compared to all remaining cells, report only the positive ones\nmarkers &lt;- FindAllMarkers(object = seurat_integrated, \n                          only.pos = TRUE,\n                          logfc.threshold = 0.25)                     \n\n\n\n\n\n\n\nNote\n\n\n\nThis command can take quite long to run, as it is processing each individual cluster against all other cells."
  },
  {
    "objectID": "lessons/09_merged_SC_marker_identification.html#identification-of-conserved-markers-in-all-conditions",
    "href": "lessons/09_merged_SC_marker_identification.html#identification-of-conserved-markers-in-all-conditions",
    "title": "Marker identification",
    "section": "Identification of conserved markers in all conditions",
    "text": "Identification of conserved markers in all conditions\nSince we have samples representing different conditions in our dataset, our best option is to find conserved markers. This function internally separates out cells by sample group/condition, and then performs differential gene expression testing for a single specified cluster against all other clusters (or a second cluster, if specified). Gene-level p-values are computed for each condition and then combined across groups using meta-analysis methods from the MetaDE R package.\n\n\n\nBefore we start our marker identification we will explicitly set our default assay, we want to use the normalized data, but not the integrated data.\n\nDefaultAssay(seurat_integrated) &lt;- \"RNA\"\n\nThe default assay should have already been RNA, because we set it up in the previous clustering quality control lesson. But we encourage you to run this line of code above to be absolutely sure in case the active slot was changed somewhere upstream in your analysis.\n\n\n\n\n\n\nWhy don’t we use SCT normalized data?\n\n\n\nNote that the raw and normalized counts are stored in the counts and data slots of RNA assay, respectively. By default, the functions for finding markers will use normalized data if RNA is the DefaultAssay. The number of features in the RNA assay corresponds to all genes in our dataset.\nNow if we consider the SCT assay, functions for finding markers would use the scale.data slot which is the pearson residuals that come out of regularized NB regression. Differential expression on these values can be difficult interpret. Additionally, only the variable features are represented in this assay and so we may not have data for some of our marker genes.\n\n\nThe function FindConservedMarkers(), has the following structure:\nFindConservedMarkers() syntax:\n\n## DO NOT RUN ##\nFindConservedMarkers(seurat_integrated,\n                      ident.1 = cluster,\n                      grouping.var = \"sample\",\n                      only.pos = TRUE,\n                      min.diff.pct = 0.25,\n                      min.pct = 0.25,\n                      logfc.threshold = 0.25)\n\nYou will recognize some of the arguments we described previously for the FindAllMarkers() function; this is because internally it is using that function to first find markers within each group. Here, we list some additional arguments which provide for when using FindConservedMarkers():\n\nident.1: this function only evaluates one cluster at a time; here you would specify the cluster of interest.\ngrouping.var: the variable (column header) in your metadata which specifies the separation of cells into groups\n\nFor our analysis we will be fairly lenient and use only the log fold change threshold greater than 0.25. We will also specify to return only the positive markers for each cluster.\nLet’s test it out on one cluster to see how it works:\n\ncluster0_conserved_markers &lt;- FindConservedMarkers(seurat_integrated,\n                                                    ident.1 = 0,\n                                                    grouping.var = \"sample\",\n                                                    only.pos = TRUE,\n                                                    logfc.threshold = 0.25)\n\n\nThe output from the FindConservedMarkers() function, is a matrix containing a ranked list of putative markers listed by gene ID for the cluster we specified, and associated statistics. Note that the same set of statistics are computed for each group (in our case, Ctrl and Stim) and the last two columns correspond to the combined p-value across the two groups. We describe some of these columns below:\n\ngene: gene symbol\ncondition_p_val: p-value not adjusted for multiple test correction for condition\ncondition_avg_logFC: average log fold change for condition. Positive values indicate that the gene is more highly expressed in the cluster.\n\ncondition_pct.1: percentage of cells where the gene is detected in the cluster for condition\n\ncondition_pct.2: percentage of cells where the gene is detected on average in the other clusters for condition\ncondition_p_val_adj: adjusted p-value for condition, based on bonferroni correction using all genes in the dataset, used to determine significance\nmax_pval: largest p value of p value calculated by each group/condition\nminimump_p_val: combined p value\n\n\n\n\n\n\n\nNote\n\n\n\nSince each cell is being treated as a replicate this will result in inflated p-values within each group! A gene may have an incredibly low p-value &lt; 1e-50 but that doesn’t translate as a highly reliable marker gene.\n\n\nWhen looking at the output, we suggest looking for markers with large differences in expression between pct.1 and pct.2 and larger fold changes. For instance if pct.1 = 0.90 and pct.2 = 0.80, it may not be as exciting of a marker. However, if pct.2 = 0.1 instead, the bigger difference would be more convincing. Also, of interest is if the majority of cells expressing the marker is in my cluster of interest. If pct.1 is low, such as 0.3, it may not be as interesting. Both of these are also possible parameters to include when running the function, as described above.\n\nAdding Gene Annotations\nIt can be helpful to add columns with gene annotation information. In order to do that we will load in an annotation file located in your data folder, using the code provided below:\n\nannotations &lt;- read.csv(\"../data/annotation.csv\")\n\n\n\n\n\n\n\nNote\n\n\n\nIf you are interested in knowing how we obtained this annotation file, take a look at the linked materials.\n\n\nFirst, we will turn the row names with gene identifiers into its own columns. Then we will merge this annotation file with our results from the FindConservedMarkers():\n\n# Combine markers with gene descriptions \ncluster0_ann_markers &lt;- cluster0_conserved_markers %&gt;% \n                rownames_to_column(var=\"gene\") %&gt;% \n                left_join(y = unique(annotations[, c(\"gene_name\", \"description\")]),\n                          by = c(\"gene\" = \"gene_name\"))\n\nhead(cluster0_ann_markers)\n\n    gene stim_p_val stim_avg_log2FC stim_pct.1 stim_pct.2 stim_p_val_adj\n1   CCR7          0       1.2798175      0.927      0.430              0\n2   SELL          0       1.4023434      0.832      0.370              0\n3   LDHB          0       1.4447683      0.732      0.304              0\n4 GIMAP7          0       1.1120136      0.934      0.507              0\n5    LTB          0       1.3746583      0.702      0.295              0\n6 RPL10A          0       0.7947952      0.966      0.664              0\n     ctrl_p_val ctrl_avg_log2FC ctrl_pct.1 ctrl_pct.2 ctrl_p_val_adj\n1  0.000000e+00       1.3185064      0.839      0.368   0.000000e+00\n2  0.000000e+00       1.8564100      0.610      0.186   0.000000e+00\n3 2.056415e-293       1.2074798      0.734      0.356  2.892347e-289\n4  0.000000e+00       1.2337458      0.804      0.380   0.000000e+00\n5  0.000000e+00       1.3920719      0.770      0.327   0.000000e+00\n6  0.000000e+00       0.5195068      0.969      0.809   0.000000e+00\n       max_pval minimump_p_val\n1  0.000000e+00              0\n2  0.000000e+00              0\n3 2.056415e-293              0\n4  0.000000e+00              0\n5  0.000000e+00              0\n6  0.000000e+00              0\n                                                        description\n1 C-C motif chemokine receptor 7 [Source:HGNC Symbol;Acc:HGNC:1608]\n2                    selectin L [Source:HGNC Symbol;Acc:HGNC:10720]\n3        lactate dehydrogenase B [Source:HGNC Symbol;Acc:HGNC:6541]\n4  GTPase, IMAP family member 7 [Source:HGNC Symbol;Acc:HGNC:22404]\n5               lymphotoxin beta [Source:HGNC Symbol;Acc:HGNC:6711]\n6        ribosomal protein L10a [Source:HGNC Symbol;Acc:HGNC:10299]\n\n\n\n\n\n\n\n\n\nExercises\n\n\n\n\nIn the previous lesson, we identified cluster 10 as FCGR3A+ monocytes by inspecting the expression of known cell markers FCGR3A and MS4A7. Use FindConservedMarkers() function to find conserved markers for cluster 10. What do you observe? Do you see FCGR3A and MS4A7 as highly expressed genes in cluster 10?\n\n\n\n\n\n\nRunning on multiple samples\nThe function FindConservedMarkers() accepts a single cluster at a time, and we could run this function as many times as we have clusters. However, this is not very efficient. Instead we will first create a function to find the conserved markers including all the parameters we want to include. We will also add a few lines of code to modify the output. Our function will:\n\nRun the FindConservedMarkers() function\nTransfer row names to a column using rownames_to_column() function\nMerge in annotations\nCreate the column of cluster IDs using the cbind() function\n\n\n# Create function to get conserved markers for any given cluster\nget_conserved &lt;- function(cluster){\n  FindConservedMarkers(seurat_integrated,\n                       ident.1 = cluster,\n                       grouping.var = \"sample\",\n                       only.pos = TRUE) %&gt;%\n    rownames_to_column(var = \"gene\") %&gt;%\n    left_join(y = unique(annotations[, c(\"gene_name\", \"description\")]),\n               by = c(\"gene\" = \"gene_name\")) %&gt;%\n    cbind(cluster_id = cluster, .)\n  }\n\nNow that we have this function created we can use it as an argument to the appropriate map function. We want the output of the map family of functions to be a dataframe with each cluster output bound together by rows, we will use the map_dfr() function.\nmap family syntax:\n\n## DO NOT RUN ##\nmap_dfr(inputs_to_function, name_of_function)\n\nNow, let’s try this function to find the conserved markers for the clusters that were identified as CD4+ T cells (4,0,6,2) from our use of known marker genes. Let’s see what genes we identify and of there are overlaps or obvious differences that can help us tease this apart a bit more.\n\n# Iterate function across desired clusters\nconserved_markers &lt;- map_dfr(c(4,0,6,2), get_conserved)\nhead(conserved_markers)\n\n  cluster_id       gene    stim_p_val stim_avg_log2FC stim_pct.1 stim_pct.2\n1          4       EIF1  0.000000e+00       0.4723411      0.992      0.926\n2          4 AC026979.2 7.026043e-238       4.4271681      0.157      0.010\n3          4      SRSF2 7.842593e-260       2.1962219      0.543      0.161\n4          4       BTG1 9.918923e-225       0.7148641      0.936      0.726\n5          4      HSPH1 2.191992e-151       2.4007275      0.333      0.091\n6          4      NR4A2 2.914853e-115       3.2800433      0.126      0.016\n  stim_p_val_adj    ctrl_p_val ctrl_avg_log2FC ctrl_pct.1 ctrl_pct.2\n1   0.000000e+00 3.178029e-271       0.4172717      0.976      0.912\n2  9.882129e-234 4.082678e-291       4.6142429      0.177      0.010\n3  1.103061e-255 2.348094e-234       2.0261441      0.537      0.181\n4  1.395097e-220 3.139357e-250       0.5747494      0.952      0.827\n5  3.083036e-147 1.587155e-245       2.9187251      0.359      0.073\n6  4.099741e-111 1.877585e-229       3.6920102      0.197      0.019\n  ctrl_p_val_adj      max_pval minimump_p_val\n1  4.469898e-267 3.178029e-271   0.000000e+00\n2  5.742287e-287 7.026043e-238  8.165357e-291\n3  3.302594e-230 2.348094e-234  1.568519e-259\n4  4.415506e-246 9.918923e-225  6.278715e-250\n5  2.232333e-241 2.191992e-151  3.174310e-245\n6  2.640824e-225 2.914853e-115  3.755170e-229\n                                                                        description\n1     eukaryotic translation initiation factor 1 [Source:HGNC Symbol;Acc:HGNC:3249]\n2                                                                  novel transcript\n3    serine and arginine rich splicing factor 2 [Source:HGNC Symbol;Acc:HGNC:10783]\n4                BTG anti-proliferation factor 1 [Source:HGNC Symbol;Acc:HGNC:1130]\n5 heat shock protein family H (Hsp110) member 1 [Source:HGNC Symbol;Acc:HGNC:16969]\n6  nuclear receptor subfamily 4 group A member 2 [Source:HGNC Symbol;Acc:HGNC:7981]\n\n\n\n\n\n\n\n\nFinding markers for all clusters\n\n\n\nFor your data, you may want to run this function on all clusters, in which case you could input 0:20 instead of c(4,0,6,2); however, it would take quite a while to run. Also, it is possible that when you run this function on all clusters, in some cases you will have clusters that do not have enough cells for a particular group - and your function will fail. For these clusters you will need to use FindAllMarkers().\n\n\n\n\nEvaluating marker genes\nWe would like to use these gene lists to see of we can identify which celltypes these clusters identify with. Let’s take a look at the top genes for each of the clusters and see if that gives us any hints. We can view the top 10 markers by average fold change across the two groups, for each cluster for a quick perusal:\n\n# Extract top 10 markers per cluster\ntop10 &lt;- conserved_markers %&gt;% \n  mutate(avg_fc = (ctrl_avg_log2FC + stim_avg_log2FC) /2) %&gt;% \n  group_by(cluster_id) %&gt;% \n  top_n(n = 10, \n        wt = avg_fc)\n\n\n# Visualize top 10 markers per cluster\nView(top10)\n\n\n\n\nWhen we look at the entire list, we see clusters 0 and 6 have some overlapping genes, like CCR7 and SELL which correspond to markers of memory T cells. It is possible that these two clusters are more similar to one another and could be merged together as naive T cells. On the other hand, with cluster 2 we observe CREM as one of our top genes; a marker gene of activation. This suggests that perhaps cluster 2 represents activated T cells.\n\n\n\nCell State\nMarker\n\n\n\n\nNaive T cells\nCCR7, SELL\n\n\nActivated T cells\nCREM, CD69\n\n\n\nFor cluster 4, we see a lot of heat shock and DNA damage genes appear in the top gene list. Based on these markers, it is likely that these are stressed or dying cells. However, if we explore the quality metrics for these cells in more detail (i.e. mitoRatio and nUMI overlayed on the cluster) we don’t really support for this argument. There is a breadth of research supporting the association of heat shock proteins with reactive T cells in the induction of anti‐inflammatory cytokines in chronic inflammation. This is a cluster for which we would need a deeper understanding of immune cells to really tease apart the results and make a final conclusion.\n\n\nVisualizing marker genes\nTo get a better idea of cell type identity for cluster 4 we can explore the expression of different identified markers by cluster using the FeaturePlot() function. We see that only a subset of cluster 4 are highly expressing these genes.\n\n# Plot interesting marker gene expression for cluster 4\nFeaturePlot(object = seurat_integrated, \n            features = c(\"HSPH1\", \"HSPE1\", \"DNAJB1\"),\n            order = TRUE,\n            min.cutoff = 'q10', \n            label = TRUE,\n            repel = TRUE)\n\n\n\n\nWe can also explore the range in expression of specific markers by using violin plots:\n\n\n\n\n\n\nViolin plots\n\n\n\nViolin plots are similar to box plots, except that they also show the probability density of the data at different values, usually smoothed by a kernel density estimator. A violin plot is more informative than a plain box plot. While a box plot only shows summary statistics such as mean/median and interquartile ranges, the violin plot shows the full distribution of the data. The difference is particularly useful when the data distribution is multimodal (more than one peak). In this case a violin plot shows the presence of different peaks, their position and relative amplitude.\n\n\n\n# Vln plot - cluster 4\nVlnPlot(object = seurat_integrated, \n        features = c(\"HSPH1\", \"HSPE1\", \"DNAJB1\"))\n\n\n\n\nThese results and plots can help us determine the identity of these clusters or verify what we hypothesize the identity to be after exploring the canonical markers of expected cell types previously."
  },
  {
    "objectID": "lessons/09_merged_SC_marker_identification.html#identifying-gene-markers-for-each-cluster",
    "href": "lessons/09_merged_SC_marker_identification.html#identifying-gene-markers-for-each-cluster",
    "title": "Marker identification",
    "section": "Identifying gene markers for each cluster",
    "text": "Identifying gene markers for each cluster\nSometimes the list of markers returned don’t sufficiently separate some of the clusters. For instance, we had previously identified clusters 0, 4, 6 and 2 as CD4+ T cells, but when looking at marker gene lists we identfied markers to help us further subset cells. We were lucky and the signal observed from FindAllMarkers() helped us differentiate between naive and activated cells. Another option to identify biologically meaningful differences would be to use the FindMarkers() function to determine the genes that are differentially expressed between two specific clusters.\n\n\n\nWe can try all combinations of comparisons, but we’ll start with cluster 2 versus all other CD4+ T cell clusters:\n\n# Determine differentiating markers for CD4+ T cell\ncd4_tcells &lt;- FindMarkers(seurat_integrated,\n                          ident.1 = 2,\n                          ident.2 = c(0,4,6))                  \n\n# Add gene symbols to the DE table\ncd4_tcells &lt;- cd4_tcells %&gt;%\n  rownames_to_column(var = \"gene\") %&gt;%\n  left_join(y = unique(annotations[, c(\"gene_name\", \"description\")]),\n             by = c(\"gene\" = \"gene_name\"))\n\n# Reorder columns and sort by padj      \ncd4_tcells &lt;- cd4_tcells[, c(1, 3:5,2,6:7)]\n\ncd4_tcells &lt;- cd4_tcells %&gt;%\n  dplyr::arrange(p_val_adj) \n\n\n# View data\nView(cd4_tcells)\n\n\n\n\nOf these top genes the CREM gene stands out as a marker of activation with a positive fold change. We also see markers of naive or memory cells include the SELL and CCR7 genes with negative fold changes, which is in line with previous results.\nAs markers for the naive and activated states both showed up in the marker list, it is helpful to visualize expression. Based on these plots it seems as though clusters 0 and 2 are reliably the naive T cells. However, for the activated T cells it is hard to tell. We might say that clusters 4 and 18 are activated T cells, but the CD69 expression is not as apparent as CREM. We will label the naive cells and leave the remaining clusters labeled as CD4+ T cells.\nNow taking all of this information, we can surmise the cell types of the different clusters and plot the cells with cell type labels.\n\n\n\nCluster ID\nCell Type\n\n\n\n\n0\nNaive or memory CD4+ T cells\n\n\n1\nCD14+ monocytes\n\n\n2\nActivated T cells\n\n\n3\nCD14+ monocytes\n\n\n4\nStressed cells / Unknown\n\n\n5\nCD8+ T cells\n\n\n6\nNaive or memory CD4+ T cells\n\n\n7\nB cells\n\n\n8\nNK cells\n\n\n9\nCD8+ T cells\n\n\n10\nFCGR3A+ monocytes\n\n\n11\nB cells\n\n\n12\nNK cells\n\n\n13\nB cells\n\n\n14\nConventional dendritic cells\n\n\n15\nMegakaryocytes\n\n\n16\nPlasmacytoid dendritic cells\n\n\n\nWe can then reassign the identity of the clusters to these cell types:\n\n# Rename all identities\nseurat_integrated &lt;- RenameIdents(object = seurat_integrated, \n                               \"0\" = \"Naive or memory CD4+ T cells\",\n                               \"1\" = \"CD14+ monocytes\",\n                               \"2\" = \"Activated T cells\",\n                               \"3\" = \"CD14+ monocytes\",\n                               \"4\" = \"Stressed cells / Unknown\",\n                               \"5\" = \"CD8+ T cells\",\n                               \"6\" = \"Naive or memory CD4+ T cells\",\n                               \"7\" = \"B cells\",\n                               \"8\" = \"NK cells\",\n                               \"9\" = \"CD8+ T cells\",\n                               \"10\" = \"FCGR3A+ monocytes\",\n                               \"11\" = \"B cells\",\n                               \"12\" = \"NK cells\",\n                               \"13\" = \"B cells\",\n                               \"14\" = \"Conventional dendritic cells\",\n                               \"15\" = \"Megakaryocytes\",\n                   \"16\" = \"Plasmacytoid dendritic cells\")\n\n\n# Plot the UMAP\nDimPlot(object = seurat_integrated, \n        reduction = \"umap\", \n        label = TRUE,\n        label.size = 3,\n        repel = TRUE)\n\n\n\n\nIf we wanted to remove the potentially stressed cells, we could use the subset() function:\n\n# Remove the stressed or dying cells\nseurat_subset_labeled &lt;- subset(seurat_integrated,\n                               idents = \"Stressed cells / Unknown\", invert = TRUE)\n\n# Re-visualize the clusters\nDimPlot(object = seurat_subset_labeled, \n        reduction = \"umap\", \n        label = TRUE,\n        label.size = 3,\n    repel = TRUE)\n\n\n\n\nNow we would want to save our final labelled Seurat object and the output of sessionInfo():\n\n# Save final R object\nwrite_rds(seurat_integrated,\n          file = \"../results/seurat_labelled.rds\")\n\n# Create and save a text file with sessionInfo\nsink(\"../results/sessionInfo_scrnaseq_Feb2023.txt\")\nsessionInfo()\nsink()\n\n\n\n\n\n\n\nNote\n\n\n\nYou can find out more about the sink() function at this link.\n\n\n\nNow that we have our clusters defined and the markers for each of our clusters, we have a few different questions we can answer:\n\nDetermine if there is a shift in cell populations between ctrl and stim. Ideally this would be done with replicates to determine if the changes are significant.\n\n\n# Add celltype annotation as a column in meta.data \nseurat_subset_labeled$celltype &lt;- Idents(seurat_subset_labeled)\n\n# Compute number of cells per celltype\nn_cells &lt;- FetchData(seurat_subset_labeled, \n                     vars = c(\"celltype\", \"sample\")) %&gt;%\n        dplyr::count(celltype, sample)\n\n# Barplot of number of cells per celltype by sample\nggplot(n_cells, aes(x=celltype, y=n, fill=sample)) +\n    geom_bar(position=position_dodge(), stat=\"identity\") +\n    theme_classic() +\n    geom_text(aes(label=n), vjust = -.2, position=position_dodge(1))\n\n\n\n\n\nPerform differential expression analysis between conditions ctrl and stim\n\nBiological replicates are necessary to proceed with this analysis, and we have additional materials to help walk through this analysis.\nFor a first pass look, we can use the FindMarkers() function we have been using to do a simple wilcox test to see the difference in gene expression between conditions for the B cells\n\n\n\n# Subset seurat object to just B cells\nseurat_b_cells &lt;- subset(seurat_subset_labeled, subset = (celltype == \"B cells\"))\n\n# Run a wilcox test to compare ctrl vs stim\nIdents(seurat_b_cells) &lt;- \"sample\"\nb_markers &lt;- FindMarkers(seurat_b_cells,\n                          ident.1 = \"ctrl\",\n                          ident.2 = \"stim\",\n                          grouping.var = \"sample\",\n                          only.pos = FALSE,\n                          logfc.threshold = 0.25)\nhead(b_markers)\n\n      p_val avg_log2FC pct.1 pct.2 p_val_adj\nIFIT3     0  -5.311956 0.036 0.927         0\nIFI6      0  -4.340583 0.067 0.931         0\nIFIT1     0  -5.611324 0.023 0.845         0\nISG15     0  -3.433947 0.174 0.995         0\nMX1       0  -3.682686 0.089 0.857         0\nLY6E      0  -3.232020 0.126 0.848         0\n\n\n\nFor added visualization, we can used the EnhancedVolcano() function to see how the genes fall on a volcano plot.\n\n\nlibrary(EnhancedVolcano)\nEnhancedVolcano(b_markers,\n    row.names(b_markers),\n    x=\"avg_log2FC\",\n    y=\"p_val_adj\",\n    title=\"B Cells\",\n    subtitle=\"Stim vs. Ctrl\"\n)\n\n\n\n\n\nExperimentally validate intriguing markers for our identified cell types.\nExplore a subset of the cell types to discover subclusters of cells as described here\nTrajectory analysis, or lineage tracing, could be performed if trying to determine the progression between cell types or cell states. For example, we could explore any of the following using this type of analysis:\n\nDifferentiation processes\nExpression changes over time\nCell state changes in expression"
  },
  {
    "objectID": "lessons/04_cellranger_QC.html",
    "href": "lessons/04_cellranger_QC.html",
    "title": "Quality Control of Cellranger Output",
    "section": "",
    "text": "Approximate time: 30 minutes"
  },
  {
    "objectID": "lessons/04_cellranger_QC.html#learning-objectives",
    "href": "lessons/04_cellranger_QC.html#learning-objectives",
    "title": "Quality Control of Cellranger Output",
    "section": "Learning Objectives:",
    "text": "Learning Objectives:\n\nDescribe how cellranger is run and what the ouputs are\nReview the cellranger generated QC report (web summary HTML)\nCreate plots with cellranger metrics"
  },
  {
    "objectID": "lessons/04_cellranger_QC.html#cellranger",
    "href": "lessons/04_cellranger_QC.html#cellranger",
    "title": "Quality Control of Cellranger Output",
    "section": "Cellranger",
    "text": "Cellranger\nCellranger is a tool created by the company 10x to process single-cell sequencing experiments that were processed with their kits.\nThe algorithm for the single-cell RNA-seq (scRNA) version of cellranger is described by 10x as follows:\n\nImage credit: 10x\nThe main elements of this pipeline are as follows:\n\nAlign FASTQ reads against a reference genome\nFilter low quailty reads and correct cell barcodes/UMIs\nCollapse on PCR duplicates using UMIs\nGenerate raw counts matrix\nIdentify low quality cells to generate a filtered counts matrix\n\nWhile the focus of this workshop is scRNA, we also want to point out that there are other cellranger softwares and modes for different types of single-cell experiments.\n\n\n\nExperiment\nExperiment description\n10x tool\n\n\n\n\nRNA\nRNA\ncellranger count\n\n\nATAC\nATAC\ncellranger-atac count\n\n\nMultiome\nRNA + ATAC\ncellranger-arc count\n\n\nV(D)J\nClonotyping of T and B cells\ncellranger vdj\n\n\nHashtagging\nAntibody/oligo tags to differentiate cells after pooling\ncellranger multi"
  },
  {
    "objectID": "lessons/04_cellranger_QC.html#running-cellranger-on-o2",
    "href": "lessons/04_cellranger_QC.html#running-cellranger-on-o2",
    "title": "Quality Control of Cellranger Output",
    "section": "Running Cellranger on O2",
    "text": "Running Cellranger on O2\nRunning cellranger requires a lot of time and computational resources in order to process a single sample. Therefore, having access to a High Performance Computing (HPC) cluster is necessary to run it. Some sequencing cores will automatically process samples with cellranger and provide the outputs to you.\nNote that prior to this step, you must have a cellranger compatible reference genome generated. If you are working with mouse or human, 10x has pre-generated the reference which can be downloaded from their website for use. If you are using another organism, cellranger has a mode called mkref which will generate everything needed for a reference from the files you supply (GTF and fasta).\nHere we are showing an example of how to run cellranger count on Harvard’s O2 HPC using SLURM. To run this script, you will have add additional information, such as:\n\nThe name of the project (the results will be placed in a folder of the same name)\nPath to the FASTQ files from your experiment\nPath to the reference genome\n\nIn the following example script, you would just have to change the variable specified in the “Inputs for cellranger” section on eth 10x support site. We have already provided some optimal parameters in terms of runtime and memory for running cellranger count.\nYou do not need to run this script.\n\n#!/bin/bash\n\n#SBATCH --partition=short               # Partition name\n#SBATCH --time=0-06:00                  # Runtime in D-HH:MM format\n#SBATCH --nodes=1                       # Number of nodes (keep at 1)\n#SBATCH --ntasks=1                      # Number of tasks per node (keep at 1)\n#SBATCH --cpus-per-task=16              # CPU cores requested per task (change for threaded jobs)\n#SBATCH --mem=64G                       # Memory needed per node (total)\n#SBATCH --error=jobid_%j.err            # File to which STDERR will be written, including job ID\n#SBATCH --output=jobid_%j.out           # File to which STDOUT will be written, including job ID\n#SBATCH --mail-type=ALL                 # Type of email notification (BEGIN, END, FAIL, ALL)\n\nmodule load gcc\nmodule load cellranger/7.1.0\n\nlocal_cores=16\nlocal_mem=64\n\n# Inputs for cellranger\nproject_name=\"\"                         # Name of output\npath_fastq=\"/path/to/fastq/\"             # Path to folder with FASTQ files for one sample\npath_ref=\"/path/to/reference/\"           # Path to cellranger compatible reference\n\n\ncellranger count \\\n    --id=${project_name} \\\n    --fastqs=${path_fastq} \\\n    --transcriptome=${path_ref} \\\n    --localcores=${local_cores} \\\n    --localmem=${local_mem}"
  },
  {
    "objectID": "lessons/04_cellranger_QC.html#cellranger-outs",
    "href": "lessons/04_cellranger_QC.html#cellranger-outs",
    "title": "Quality Control of Cellranger Output",
    "section": "Cellranger outs",
    "text": "Cellranger outs\nOnce cellranger has finished running, there will be a folder titled outs/ in a directory named after the project_name variable set above. Generation of all the following files is expected from a succesful completion of the cellranger counts pipeline:\n\n├── cloupe.cloupe\n├── filtered_feature_bc_matrix\n│   ├── barcodes.tsv.gz\n│   ├── features.tsv.gz\n│   └── matrix.mtx.gz\n├── filtered_feature_bc_matrix.h5\n├── metrics_summary.csv\n├── molecule_info.h5\n├── possorted_genome_bam.bam\n├── possorted_genome_bam.bam.bai\n├── raw_feature_bc_matrix\n│   ├── barcodes.tsv.gz\n│   ├── features.tsv.gz\n│   └── matrix.mtx.gz\n├── raw_feature_bc_matrix.h5\n└── web_summary.html"
  },
  {
    "objectID": "lessons/04_cellranger_QC.html#web-summary-html-report",
    "href": "lessons/04_cellranger_QC.html#web-summary-html-report",
    "title": "Quality Control of Cellranger Output",
    "section": "Web summary HTML Report",
    "text": "Web summary HTML Report\nThe Web Summary HTML file is a great resource for looking at the basic quality of your sample before starting on an analysis. 10x has a page describing each metric in depth. There are two pages/tabs included in a scRNA report titled “Summary” and “Gene Expression”.\nWe have included these Web Summary files for the control and stimulated samples as links below. You can download each, and move the HTML to your project data folder:\n\nControl sample report\nStimulated sample report\n\n\n\n\n\n\n\nNote\n\n\n\nSome of the values in these reports will be slightly different from current standards, as these samples were generated using the version 1 chemistry kit and optimization have been made since then.\n\n\n\nSummary\nAt the top of the “Summary” tab, under the “Alerts” header, will be a list of warnings and messages on the quality/important information about the sample. These messages are very informative on what may have gone wrong with the sample or other flags that can be set in the cellranger count run to gain better results.\nUnderneath the “Alerts” header, in green text, are the estimated number of high quality cells in the sample, average reads per cells, and median genes per cell. The number of cells will vary depending on how many were loaded in sample preparation, but some general recommendations are provided below:\n\n500 cells is the lower limit for a good quality sample.\n10x also recommends a minimum of 20,000 reads per cell on average.\nThe median genes per cell varies widely across samples as it depends on sequencing depth and cell type, making it difficult to establish a good minimal value.\n\nThe remaining 4 sections include various metrics that describe the overall quality of the sample. Note that clicking on the grey question mark will show more detailed explanations.\nSequencing\nIncludes information such as the total number of reads and how many of those reads did not meet the length requirements. Additionally, since all barcodes and UMIs are known values (from the kit used to prep scRNA experiments), we can evaluate what percentage of the barcodes and UMIs belong to that whitelist and are valid.\n\nIdeally, you would like to see &gt;75% for almost all of these values since lower values are indicative of a low quality sequencing run or bad sample quality.\nMapping\nPercentage of reads that map to different regions of the reference genome as reported by STAR.\n\nThe percent of reads mapped to the genome should be on the higher end, around 85% or higher. Values that are very low could indicate that the reference genome supplied was incorrect or that the sample was problematic. Otherwise, the expectation for a scRNA runs is that the majority of reads will belong to exonic regions. If nuclei were used instead of whole cells, the percentage of reads mapping to intronic regions will be higher (~45%).\nCells\nHere we can see what an ideal representation of the Barcode Rank Plot looks like. The cells are sorted by the number of UMIs found in the cell to differentiate empty droplets/low quality cells (background) from actual cells.\n\nImage credit: 10x\nThe shape of these plots can indicate a few different things about the sample:\n\nTypical: Clear cliff and knee with separation between cells and background.\nHeterogeneous: Bimodal plot with 2 cliffs and knees, with a clear divide between cells and background.\nCompromised: Round curve with a steep drop-off at the end whih indicated low quality due to many factors.\nCompromised: Defined cliff and knee, but with few barcodes detected could be due to inaccurate cell count or clogging.\n\nThis section additionally describes averages and medians for number of genes and reads in the sample.\nSample\nThe sample section contains important metadata used by cellranger, such as what the Sample ID and the path used for the reference. The chemistry version (which 10x kit was used) and intron flags are also stored here. This information is useful for reproducibility reasons, as the version of cellranger used is also kept.\n\n\n\nGene Expression\nThe “Gene Expression” table contains information downstream of the basic QC, such as:\nt-SNE Projection\nDotplot showing the t-SNE projection of filtered cells colored by UMI counts and clusters. The report allows you select various values of K for the K-means clustering, showing different groupings that can be generated from the data.\n\nLater in the workshop we will spend more time on the intricacies of clustering. The requirements for this QC report would be to see clear separation of cells into groups with defined clusters - representing different cell types.\nTop Features by Cluster\nThis table shows the log2 fold-change and p-value for each gene and cluster after a differential expression analysis is run.\n\nThese top genes per cluster can give a brief peek into the cell type distribution of the sample. If no expected cell type marker genes appear or mitochondrial/ribosomal genes show up frequently, this can be indicative of something wrong with the sample.\nSequencing Saturation and Median Genes per Cell\nThe sequencing saturation plot is a measure of library complexity. In scRNA, more genes can be detected with higher sequencing depth. At a point, you reach sequencing saturation where you do not gain any more meaningful insights which is what the dotted line represents here.\nSimilar to the sequencing saturation plot, looking at the median gene per cells against mean reads per cell will indicate if your have over or under-sequenced. The slope near the endpoint can be used to determine how much benefit would be gained from sequencing more deeply."
  },
  {
    "objectID": "lessons/04_cellranger_QC.html#metrics-evaluation",
    "href": "lessons/04_cellranger_QC.html#metrics-evaluation",
    "title": "Quality Control of Cellranger Output",
    "section": "Metrics evaluation",
    "text": "Metrics evaluation\nMany of the core pieces of information from the web summary are stored in the metrics_summary.csv. As this is a csv file, we can read it into R and generate plots to include in reports on the general quality of the samples.\nWe have included these csv files for the control and stimulated samples as links below. You can right-click on the link and “Save as…” into your project data folder:\n\n[Control sample]https://www.dropbox.com/scl/fi/qnz44ng51ojmhu44acc8g/ctrl_metrics_summary.csv?rlkey=8zx5g1mtn6mrlwpv0syoz3bv4&st=9d0okyhf&dl=1) metrics.csv file\nStimulated sample metrics.csv file\n\nFirst, to read the files in:\n\nlibrary(tidyverse)\nlibrary(reshape2)\nlibrary(plyr)\n\n# Names of samples (same name as folders stored in data)\nsamples &lt;- c(\"ctrl\", \"stim\")\n\n# Loop over each sample and read the metrics summary in\nmetrics &lt;- list()\nfor (sample in samples) {\n    path_csv &lt;- paste0(\"../data/\", sample, \"_metrics_summary.csv\")\n    df &lt;- read.csv(path_csv)\n    rownames(df) &lt;- sample\n    metrics[[sample]] &lt;- df\n}\n# Concatenate each sample metrics together\nmetrics &lt;- ldply(metrics, rbind)\n# Remove periods and percentags to make the values numeric\nmetrics &lt;- metrics %&gt;%\n    column_to_rownames(\".id\") %&gt;%\n    mutate_all(funs(parse_number(str_replace(., \",\", \"\")))) %&gt;%\n    mutate_all(funs(parse_number(str_replace(., \"%\", \"\"))))\nmetrics$sample &lt;- rownames(metrics)\n\nThe information available in this file include:\n\ncolnames(metrics)\n\n [1] \"Estimated.Number.of.Cells\"                     \n [2] \"Mean.Reads.per.Cell\"                           \n [3] \"Median.Genes.per.Cell\"                         \n [4] \"Number.of.Reads\"                               \n [5] \"Valid.Barcodes\"                                \n [6] \"Sequencing.Saturation\"                         \n [7] \"Q30.Bases.in.Barcode\"                          \n [8] \"Q30.Bases.in.RNA.Read\"                         \n [9] \"Q30.Bases.in.UMI\"                              \n[10] \"Reads.Mapped.to.Genome\"                        \n[11] \"Reads.Mapped.Confidently.to.Genome\"            \n[12] \"Reads.Mapped.Confidently.to.Intergenic.Regions\"\n[13] \"Reads.Mapped.Confidently.to.Intronic.Regions\"  \n[14] \"Reads.Mapped.Confidently.to.Exonic.Regions\"    \n[15] \"Reads.Mapped.Confidently.to.Transcriptome\"     \n[16] \"Reads.Mapped.Antisense.to.Gene\"                \n[17] \"Fraction.Reads.in.Cells\"                       \n[18] \"Total.Genes.Detected\"                          \n[19] \"Median.UMI.Counts.per.Cell\"                    \n[20] \"sample\"                                        \n\n\nWith all of this information available as a dataframe, we can use ggplot to visualize these values. As an example of how this information can be used, we can display what percentage of reads map to the various parts of the genome (Intergentic, Intronic, and Exonic).\n\n# Columns of interest\ncols &lt;- c(\"Reads.Mapped.Confidently.to.Intergenic.Regions\",\n          \"Reads.Mapped.Confidently.to.Intronic.Regions\",\n          \"Reads.Mapped.Confidently.to.Exonic.Regions\",\n          \"sample\")\n\n# Data wrangling to sculpt dataframe in a ggplot friendly manner\ndf &lt;- metrics %&gt;%\n    select(cols) %&gt;%\n    melt() %&gt;%\n    mutate(variable = str_replace_all(variable, \"Reads.Mapped.Confidently.to.\", \"\")) %&gt;%\n    mutate(variable = str_replace_all(variable, \".Regions\", \"\"))\n\n# ggplot code to make a barplot\ndf %&gt;% ggplot() +\n    geom_bar(\n        aes(x = sample, y = value, fill = variable),\n        position = \"stack\",\n        stat = \"identity\") +\n    coord_flip() +\n    labs(\n        x = \"Sample\",\n        y = \"Percentage of Reads\",\n        title = \"Percent of Reads Mapped to Each Region\",\n        fill = \"Region\")"
  },
  {
    "objectID": "lessons/04_cellranger_QC.html#matrix-folders",
    "href": "lessons/04_cellranger_QC.html#matrix-folders",
    "title": "Quality Control of Cellranger Output",
    "section": "Matrix folders",
    "text": "Matrix folders\nThe most important files that are generated during this cellranger run are the two matrix folders, which contain the count matrices from the experiment:\n\nraw_feature_bc_matrix\nfiltered_feature_bc_matrix\n\nIn the previous lesson, we used raw_feature_bc_matrix to load the counts into Seurat. You can similarly do the same with filtered_feature_bc_matrix, the difference being that the filtered matrix has removed cells that cellranger determined as low quality using a variety of different tools. We chose to start with the raw counts matrix in this lesson so that you can better see what metrics are used to determine which cells are considered high quality."
  },
  {
    "objectID": "lessons/cell_cycle_scoring.html",
    "href": "lessons/cell_cycle_scoring.html",
    "title": "Cell Cycle Scoring",
    "section": "",
    "text": "Cell cycle scoring\nCell cycle variation is a common source of uninteresting variation in single-cell RNA-seq data. To examine cell cycle variation in our data, we assign each cell a score, based on its expression of G2/M and S phase markers.\n\nAn overview of the cell cycle phases is given in the image below:\n\n\n\nAdapted from Wikipedia (Image License is CC BY-SA 3.0)\n\nG0: Quiescence or resting phase. The cell is not actively dividing, which is common for cells that are fully differentiated. Some types of cells enter G0 for long periods of time (many neuronal cells), while other cell types never enter G0 by continuously dividing (epithelial cells).\nG1: Gap 1 phase represents the beginning of interphase. During G1 there is growth of the non-chromosomal components of the cells. From this phase, the cell may enter G0 or S phase.\nS: Synthesis phase for the replication of the chromosomes (also part of interphase).\nG2: Gap 2 phase represents the end of interphase, prior to entering the mitotic phase. During this phase th cell grows in preparation for mitosis and the spindle forms.\nM: M phase is the nuclear division of the cell (consisting of prophase, metaphase, anaphase and telophase).\n\n\nThe Cell-Cycle Scoring and Regression tutorial from Seurat makes available a list of cell cycle phase marker genes for humans and performs phase scoring based on the paper from Tirosh, I. et al.. We have used this list to perform orthology searches to create compiled cell cycle gene lists for other organisms, as well.\nAfter scoring each gene for cell cycle phase, we can perform PCA using the expression of cell cycle genes. If the cells group by cell cycle in the PCA, then we would want to regress out cell cycle variation, unless cells are differentiating.\n\n\n\n\n\n\nNote\n\n\n\nIf cells are known to be differentiating and there is clear clustering differences between G2M and S phases, then you may want to regress out by the difference between the G2M and S phase scores as described in the Seurat tutorial, thereby still differentiating the cycling from the non-cycling cells.\n\n\nThe code in this lesson relies on these libraries:\n\nlibrary(RCurl)\nlibrary(AnnotationHub)\nlibrary(ensembldb)\n\n\n# Download cell cycle genes for organism at https://github.com/hbc/tinyatlas/tree/master/cell_cycle. Read it in with:\n\ncc_file &lt;- getURL(\"https://raw.githubusercontent.com/hbc/tinyatlas/master/cell_cycle/Homo_sapiens.csv\") \ncell_cycle_genes &lt;- read.csv(text = cc_file)\nhead(cell_cycle_genes)\n\n  phase          geneID modified\n1  G2/M ENSG00000010292  9/13/17\n2  G2/M ENSG00000011426  9/13/17\n3  G2/M ENSG00000013810  9/13/17\n4  G2/M ENSG00000072571  9/13/17\n5  G2/M ENSG00000075218  9/13/17\n6  G2/M ENSG00000080986  9/13/17\n\n\nAll of the cell cycle genes are Ensembl IDs, but our gene IDs are the gene names. To score the genes in our count matrix for cell cycle, we need to obtain the gene names for the cell cycle genes.\nWe can use annotation databases to acquire these IDs. While there are many different options, including BioMart, AnnotationDBI, and AnnotationHub. We will use the AnnotationHub R package to query Ensembl using the ensembldb R package.\n\n# Connect to AnnotationHub\nah &lt;- AnnotationHub()\n\n# Access the Ensembl database for organism\nahDb &lt;- query(ah, \n              pattern = c(\"Homo sapiens\", \"EnsDb\"), \n              ignore.case = TRUE)\n\n# Acquire the latest annotation files\nid &lt;- ahDb %&gt;%\n        mcols() %&gt;%\n        rownames() %&gt;%\n        tail(n = 1)\n\n# Download the appropriate Ensembldb database\nedb &lt;- ah[[id]]\n\n# Extract gene-level information from database\nannotations &lt;- genes(edb, \n                     return.type = \"data.frame\")\n\n# Select annotations of interest\nannotations &lt;- annotations %&gt;%\n        dplyr::select(gene_id, gene_name, \n                      seq_name, gene_biotype, \n                      description)\nhead(annotations)\n\n           gene_id   gene_name seq_name                       gene_biotype\n1  ENSG00000290825     DDX11L2        1                             lncRNA\n6  ENSG00000223972     DDX11L1        1 transcribed_unprocessed_pseudogene\n7  ENSG00000227232      WASH7P        1             unprocessed_pseudogene\n8  ENSG00000278267   MIR6859-1        1                              miRNA\n9  ENSG00000243485 MIR1302-2HG        1                             lncRNA\n10 ENSG00000284332   MIR1302-2        1                              miRNA\n                                                                                     description\n1  DEAD/H-box helicase 11 like 2 (pseudogene) [Source:NCBI gene (formerly Entrezgene);Acc:84771]\n6                 DEAD/H-box helicase 11 like 1 (pseudogene) [Source:HGNC Symbol;Acc:HGNC:37102]\n7                          WASP family homolog 7, pseudogene [Source:HGNC Symbol;Acc:HGNC:38034]\n8                                            microRNA 6859-1 [Source:HGNC Symbol;Acc:HGNC:50039]\n9                                        MIR1302-2 host gene [Source:HGNC Symbol;Acc:HGNC:52482]\n10                                           microRNA 1302-2 [Source:HGNC Symbol;Acc:HGNC:35294]\n\n\nNow we can use these annotations to get the corresponding gene names for the Ensembl IDs of the cell cycle genes.\n\n# Get gene names for Ensembl IDs for each gene\ncell_cycle_markers &lt;- dplyr::left_join(cell_cycle_genes, \n                                       annotations, \n                                       by = c(\"geneID\" = \"gene_id\"))\n\n# Acquire the S phase genes\ns_genes &lt;- cell_cycle_markers %&gt;%\n        dplyr::filter(phase == \"S\") %&gt;%\n        pull(\"gene_name\")\n        \n# Acquire the G2M phase genes        \ng2m_genes &lt;- cell_cycle_markers %&gt;%\n        dplyr::filter(phase == \"G2/M\") %&gt;%\n        pull(\"gene_name\")\n\ns_genes\n\n [1] \"UBR7\"     \"RFC2\"     \"RAD51\"    \"MCM2\"     \"TIPIN\"    \"MCM6\"    \n [7] \"UNG\"      \"POLD3\"    \"WDR76\"    \"CLSPN\"    \"CDC45\"    \"CDC6\"    \n[13] \"MSH2\"     \"MCM5\"     \"POLA1\"    \"MCM4\"     \"RAD51AP1\" \"GMNN\"    \n[19] \"RPA2\"     \"CASP8AP2\" \"HELLS\"    \"E2F8\"     \"GINS2\"    \"PCNA\"    \n[25] \"NASP\"     \"BRIP1\"    \"DSCC1\"    \"DTL\"      \"CDCA7\"    \"CENPU\"   \n[31] \"ATAD2\"    \"CHAF1B\"   \"USP1\"     \"SLBP\"     \"RRM1\"     \"FEN1\"    \n[37] \"RRM2\"     \"EXO1\"     \"CCNE2\"    \"TYMS\"     \"BLM\"      \"PRIM1\"   \n[43] \"UHRF1\"   \n\ng2m_genes\n\n [1] \"NCAPD2\"  \"ANLN\"    \"TACC3\"   \"HMMR\"    \"GTSE1\"   \"NDC80\"   \"AURKA\"  \n [8] \"TPX2\"    \"BIRC5\"   \"G2E3\"    \"CBX5\"    \"RANGAP1\" \"CTCF\"    \"CDCA3\"  \n[15] \"TTK\"     \"SMC4\"    \"ECT2\"    \"CENPA\"   \"CDC20\"   \"NEK2\"    \"CENPF\"  \n[22] \"TMPO\"    \"HJURP\"   \"CKS2\"    \"DLGAP5\"  \"PIMREG\"  \"TOP2A\"   \"PSRC1\"  \n[29] \"CDCA8\"   \"CKAP2\"   \"NUSAP1\"  \"KIF23\"   \"KIF11\"   \"KIF20B\"  \"CENPE\"  \n[36] \"GAS2L3\"  \"KIF2C\"   \"NUF2\"    \"ANP32E\"  \"LBR\"     \"MKI67\"   \"CCNB2\"  \n[43] \"CDC25C\"  \"HMGB2\"   \"CKAP2L\"  \"BUB1\"    \"CDK1\"    \"CKS1B\"   \"UBE2C\"  \n[50] \"CKAP5\"   \"AURKB\"   \"CDCA2\"   \"TUBB4B\"  \"JPT1\"   \n\n\nTaking the gene names for the cell cycle genes we can score each cell based which stage of the cell cycle it is most likely to be in.\n\n# Perform cell cycle scoring\nseurat_phase &lt;- CellCycleScoring(seurat_phase,\n                                   g2m.features = g2m_genes,\n                                   s.features = s_genes)\nseurat_phase\n\nAn object of class Seurat \n14065 features across 29629 samples within 1 assay \nActive assay: RNA (14065 features, 0 variable features)\n 2 layers present: counts, data\n\n\nBy default, the PCA is run only using the most variable features. If identified previously, there is no need to run FindVariableFeatures() again. The output of the PCA returns the correlated gene sets associated with the different principal components (PCs).\n\n# Identify the most variable genes if it hasn't been run\nseurat_phase &lt;- FindVariableFeatures(seurat_phase, \n                     selection.method = \"vst\",\n                     nfeatures = 2000, \n                     verbose = FALSE)\n             \n# Scale the counts\nseurat_phase &lt;- ScaleData(seurat_phase)\n\n# Perform PCA and color by cell cycle phase\nseurat_phase &lt;- RunPCA(seurat_phase)\n\n# Visualize the PCA, grouping by cell cycle phase\nDimPlot(seurat_phase,\n        reduction = \"pca\",\n        group.by= \"Phase\")\n\n\n\n\nWe do see differences on PC1, with the G1 cells to the left of the other cells on PC1. Based on this plot, we would regress out the variation due to cell cycle.\n\n\n\n\n\n\nNote\n\n\n\nAlternatively, we could wait and perform the clustering without regression and see if we have clusters separated by cell cycle phase. If we do, then we could come back and perform the regression."
  },
  {
    "objectID": "lessons/schedule.html",
    "href": "lessons/schedule.html",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Introduction to scRNA-seq\nRaw data to count matrix\nDownload this project\n\n\n\n\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n09:30 - 09:45\nWorkshop introduction\nWill\n\n\n09:45 - 10:35\nIntroduction to Single Cell RNA-sequencing: a practical guide\nDr. Arpita Kulkarni\n\n\n10:35 - 10:40\nBreak\n\n\n\n10:40 - 11:00\nscRNA-seq pre-reading discussion\nAll\n\n\n11:00 - 11:45\nQuality control set-up\nNoor\n\n\n11:45 - 12:00\nOverview of self-learning materials and homework submission\nWill\n\n\n\n\n\nI. Please study the contents and work through all the code within the following lessons:\n\nQuality control of cellranger counts\n\n\nClick here for a preview of this lesson\n\nBefore you start any analysis, it’s important to know whether or not you have good quality cells. At these early stages you can flag or remove samples that could produce erroneous results downstream. In this lesson you will: - Discuss the outputs of cellranger and how to run it  - Review web summary HTML report - Create plots from metrics_summary.csv file \n\nQuality control with additional metrics\n\n\nClick here for a preview of this lesson\n\nIn addition to the QC generated by cellranger, we can also compute some of our own metrics based on the raw data we have loaded into our Seurat object. In this lesson you will: - Compute essential QC metrics for each sample - Create plots to visualize metrics across cells per sample - Critically evaluate each plot and learn what each QC metric means\n\nTheory of PCA\n\n\nClick here for a preview of this lesson\n\nBefore we can begin the next steps of the workflow, we need to make sure you have a good understanding of Principal Components Analysis (PCA). This method will be utilized in the scRNA-seq analysis workflow, and this foundation will help you better navigate those steps and interpretation of results.\n\n\n\nSubmit your work:\n\n\nEach lesson above contains exercises; please go through each of them.\nSubmit your answers to the exercises using this Google form on the day before the next class.\n\n\n\n\n\nIf you get stuck due to an error while runnning code in the lesson, email us\n\n\n\n\n\n\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n09:30 - 10:15\nSelf-learning lessons discussion\nAll\n\n\n10:15 - 11:15\nNormalization and regressing out unwanted variation\nNoor\n\n\n11:15 - 11:25\nBreak\n\n\n\n11:25 - 12:00\nA brief introduction to Integration\nWill\n\n\n\n\n\nI. Please study the contents and work through all the code within the following lessons:\n\nRunning CCA integration and complex integration tasks\n\n\nClick here for a preview of this lesson\n\nIn class, we described the theory of integration and in what situations we would implement it. In this lesson you will: - Run the code to implement CCA integration  - Evaluate the effect of integration on the UMAP  - Learn about methods for complex integration tasks (Harmonizing samples) \n\nClustering\n\n\nClick here for a preview of this lesson\n\nFrom the UMAP visualization of our data we can see that the cells are positioned into groups. Our next task is to isolate clusters of cells that are most similar to one another based on gene expression. In this lesson you will: - Learn the theory behind clustering and how it is performed in Seurat - Cluster cells and visualize them on the UMAP\n\nClustering quality control\n\n\nClick here for a preview of this lesson\n\nAfter separating cells into clusters, it is crtical to evaluate whether they are biologically meaningful or not. At this point we can also decide if we need to re-cluster and/or potentialy go back to a previous QC step. In this lesson you will: - Check to see that clusters are not influenced by uninteresting sources of variation - Check to see whether the major principal components are driving the different clusters - Explore the cell type identities by looking at the expression for known markers across the clusters.\n\nSeurat Cheatsheet\n\n\nClick here for a preview of this lesson\n\nAt this point, we have populated our seurat object with many different pieces of information. Knowing how to access different values will allow you to interact more efficiently with your dataset. In this lesson you will: - Explore the different parts of a seurat object. - Use the built-in functions from the Seurat package for visualizations and grabbing data.\n\n\n\nSubmit your work:\n\n\nEach lesson above contains exercises; please go through each of them.\nSubmit your answers to the exercises using this Google form on the day before the next class.\n\n\n\n\n\nIf you get stuck due to an error while runnning code in the lesson, email us\n\n\n\n\n\n\n\n\n\nTime\nTopic\nInstructor\n\n\n\n\n9:30 - 10:00\nSelf-learning lessons discussion\nAll\n\n\n10:00 - 11:00\nMarker identification\nNoor\n\n\n11:00 - 11:10\nBreak\n\n\n\n11:10 - 11:30\nWorkflow summary\nWill\n\n\n11:30 - 11:45\nOverview and Final Q & A\nAll\n\n\n11:45- 12:00\nWrap up\nWill\n\n\n\n\n\n\n\n\nAnswer key - assignment #1\nAnswer key - assignment #2\n\n\n\n\n\nDifferential expression between conditions\n\n\n\n\n\nWe have covered the analysis steps in quite a bit of detail for scRNA-seq exploration of cellular heterogeneity using the Seurat package. For more information on topics covered, we encourage you to take a look at the following resources:\n\n\n\nSeurat vignettes\nSeurat cheatsheet\nSatija Lab: Single Cell Genomics Day\nAdditional information about cell cycle scoring\nA nice explanation on CCA and cell label transfer in Seurat\n\n\n\n\n\nUsing RStudio on O2\n\nHMSRC wiki page\nHBC RStudio on O2 tutorial\n\n\n\n\n\n\nDatabases with markers for manual annotation\n\nCellMarker 2.0\nCell type signature gene sets from MSigDb\nCELL x GENE from CZI\n\nReference-based automated celltype annotation\n\nAzimuth\nCelltypist\n\n\n\n\n\n\n“Sampling time-dependent artifacts in single-cell genomics studies.” Massoni-Badosa et al. 2019\n“Dissociation of solid tumor tissues with cold active protease for single-cell RNA-seq minimizes conserved collagenase-associated stress responses.” O’Flanagan et al. 2020\n“Systematic assessment of tissue dissociation and storage biases in single-cell and single-nucleus RNA-seq workflows.” Denisenko et al. 2020\n“Confronting false discoveries in single-cell differential expression”, Nature Communications 2021\nSingle-nucleus and single-cell transcriptomes compared in matched cortical cell types\nA single-cell and single-nucleus RNA-Seq toolbox for fresh and frozen human tumors\nLigand-receptor analysis with CellphoneDB\nBest practices for single-cell analysis across modalities\n\n\n\n\n\nOSCA with Bioconductor\nDFCI/Shirley Liu\nWellcome Sanger Institute/Hemmberg Lab\nISCB Workshop\nBroad workshop\nSciLifeLab workshop"
  },
  {
    "objectID": "lessons/schedule.html#pre-reading",
    "href": "lessons/schedule.html#pre-reading",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Introduction to scRNA-seq\nRaw data to count matrix\nDownload this project"
  },
  {
    "objectID": "lessons/schedule.html#day-1",
    "href": "lessons/schedule.html#day-1",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Time\nTopic\nInstructor\n\n\n\n\n09:30 - 09:45\nWorkshop introduction\nWill\n\n\n09:45 - 10:35\nIntroduction to Single Cell RNA-sequencing: a practical guide\nDr. Arpita Kulkarni\n\n\n10:35 - 10:40\nBreak\n\n\n\n10:40 - 11:00\nscRNA-seq pre-reading discussion\nAll\n\n\n11:00 - 11:45\nQuality control set-up\nNoor\n\n\n11:45 - 12:00\nOverview of self-learning materials and homework submission\nWill\n\n\n\n\n\nI. Please study the contents and work through all the code within the following lessons:\n\nQuality control of cellranger counts\n\n\nClick here for a preview of this lesson\n\nBefore you start any analysis, it’s important to know whether or not you have good quality cells. At these early stages you can flag or remove samples that could produce erroneous results downstream. In this lesson you will: - Discuss the outputs of cellranger and how to run it  - Review web summary HTML report - Create plots from metrics_summary.csv file \n\nQuality control with additional metrics\n\n\nClick here for a preview of this lesson\n\nIn addition to the QC generated by cellranger, we can also compute some of our own metrics based on the raw data we have loaded into our Seurat object. In this lesson you will: - Compute essential QC metrics for each sample - Create plots to visualize metrics across cells per sample - Critically evaluate each plot and learn what each QC metric means\n\nTheory of PCA\n\n\nClick here for a preview of this lesson\n\nBefore we can begin the next steps of the workflow, we need to make sure you have a good understanding of Principal Components Analysis (PCA). This method will be utilized in the scRNA-seq analysis workflow, and this foundation will help you better navigate those steps and interpretation of results.\n\n\n\nSubmit your work:\n\n\nEach lesson above contains exercises; please go through each of them.\nSubmit your answers to the exercises using this Google form on the day before the next class.\n\n\n\n\n\nIf you get stuck due to an error while runnning code in the lesson, email us"
  },
  {
    "objectID": "lessons/schedule.html#day-2",
    "href": "lessons/schedule.html#day-2",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Time\nTopic\nInstructor\n\n\n\n\n09:30 - 10:15\nSelf-learning lessons discussion\nAll\n\n\n10:15 - 11:15\nNormalization and regressing out unwanted variation\nNoor\n\n\n11:15 - 11:25\nBreak\n\n\n\n11:25 - 12:00\nA brief introduction to Integration\nWill\n\n\n\n\n\nI. Please study the contents and work through all the code within the following lessons:\n\nRunning CCA integration and complex integration tasks\n\n\nClick here for a preview of this lesson\n\nIn class, we described the theory of integration and in what situations we would implement it. In this lesson you will: - Run the code to implement CCA integration  - Evaluate the effect of integration on the UMAP  - Learn about methods for complex integration tasks (Harmonizing samples) \n\nClustering\n\n\nClick here for a preview of this lesson\n\nFrom the UMAP visualization of our data we can see that the cells are positioned into groups. Our next task is to isolate clusters of cells that are most similar to one another based on gene expression. In this lesson you will: - Learn the theory behind clustering and how it is performed in Seurat - Cluster cells and visualize them on the UMAP\n\nClustering quality control\n\n\nClick here for a preview of this lesson\n\nAfter separating cells into clusters, it is crtical to evaluate whether they are biologically meaningful or not. At this point we can also decide if we need to re-cluster and/or potentialy go back to a previous QC step. In this lesson you will: - Check to see that clusters are not influenced by uninteresting sources of variation - Check to see whether the major principal components are driving the different clusters - Explore the cell type identities by looking at the expression for known markers across the clusters.\n\nSeurat Cheatsheet\n\n\nClick here for a preview of this lesson\n\nAt this point, we have populated our seurat object with many different pieces of information. Knowing how to access different values will allow you to interact more efficiently with your dataset. In this lesson you will: - Explore the different parts of a seurat object. - Use the built-in functions from the Seurat package for visualizations and grabbing data.\n\n\n\nSubmit your work:\n\n\nEach lesson above contains exercises; please go through each of them.\nSubmit your answers to the exercises using this Google form on the day before the next class.\n\n\n\n\n\nIf you get stuck due to an error while runnning code in the lesson, email us"
  },
  {
    "objectID": "lessons/schedule.html#day-3",
    "href": "lessons/schedule.html#day-3",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Time\nTopic\nInstructor\n\n\n\n\n9:30 - 10:00\nSelf-learning lessons discussion\nAll\n\n\n10:00 - 11:00\nMarker identification\nNoor\n\n\n11:00 - 11:10\nBreak\n\n\n\n11:10 - 11:30\nWorkflow summary\nWill\n\n\n11:30 - 11:45\nOverview and Final Q & A\nAll\n\n\n11:45- 12:00\nWrap up\nWill"
  },
  {
    "objectID": "lessons/schedule.html#answer-keys",
    "href": "lessons/schedule.html#answer-keys",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Answer key - assignment #1\nAnswer key - assignment #2"
  },
  {
    "objectID": "lessons/schedule.html#downstream-analyses",
    "href": "lessons/schedule.html#downstream-analyses",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "Differential expression between conditions"
  },
  {
    "objectID": "lessons/schedule.html#resources",
    "href": "lessons/schedule.html#resources",
    "title": "Introduction to Single-cell RNA-seq Schedule",
    "section": "",
    "text": "We have covered the analysis steps in quite a bit of detail for scRNA-seq exploration of cellular heterogeneity using the Seurat package. For more information on topics covered, we encourage you to take a look at the following resources:\n\n\n\nSeurat vignettes\nSeurat cheatsheet\nSatija Lab: Single Cell Genomics Day\nAdditional information about cell cycle scoring\nA nice explanation on CCA and cell label transfer in Seurat\n\n\n\n\n\nUsing RStudio on O2\n\nHMSRC wiki page\nHBC RStudio on O2 tutorial\n\n\n\n\n\n\nDatabases with markers for manual annotation\n\nCellMarker 2.0\nCell type signature gene sets from MSigDb\nCELL x GENE from CZI\n\nReference-based automated celltype annotation\n\nAzimuth\nCelltypist\n\n\n\n\n\n\n“Sampling time-dependent artifacts in single-cell genomics studies.” Massoni-Badosa et al. 2019\n“Dissociation of solid tumor tissues with cold active protease for single-cell RNA-seq minimizes conserved collagenase-associated stress responses.” O’Flanagan et al. 2020\n“Systematic assessment of tissue dissociation and storage biases in single-cell and single-nucleus RNA-seq workflows.” Denisenko et al. 2020\n“Confronting false discoveries in single-cell differential expression”, Nature Communications 2021\nSingle-nucleus and single-cell transcriptomes compared in matched cortical cell types\nA single-cell and single-nucleus RNA-Seq toolbox for fresh and frozen human tumors\nLigand-receptor analysis with CellphoneDB\nBest practices for single-cell analysis across modalities\n\n\n\n\n\nOSCA with Bioconductor\nDFCI/Shirley Liu\nWellcome Sanger Institute/Hemmberg Lab\nISCB Workshop\nBroad workshop\nSciLifeLab workshop"
  }
]